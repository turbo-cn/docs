{"/blog":{"title":"博客","data":{"":"Blog\n\n\nThe latest updates and releases from the Turbo team at Vercel."}},"/":{"data":{"":""}},"/blog/joining-vercel":{"title":"Joining Vercel","data":{"":"Turborepo has been acquired by Vercel and the Turborepo CLI is now open-source! Also, Turborepo now provides zero-config remote caching through Vercel!beta.turborepo.com and its remote caching service will be shut down on January 15th, 2022 and older versions of the turbo CLI will not be installable. Learn more about how to upgrade your CLI and migrate to Vercel here.This is a milestone moment for the project and for all of you who have supported and adopted Turborepo. With Vercel's infrastructure and team backing, I'll expand on the capabilities of Turborepo and build out a team focused on improving their world-class build system. I can't wait to bring you along for this next chapter.Join me this Friday, December 10 at 4:00 p.m. ET | 9:00 p.m GMT for a livestream Q&A with Vercel's Head of Developer Relations, Lee Robinson. We'll go over what's in store for Turborepo and Vercel as we work toward improving the developer experience together.This is just the beginning. We're about to embark on a world of even faster builds, even more flexibility, and even better workflows. Thanks for joining us on this amazing journey."}},"/blog/saml-sso-now-available":{"title":"SAML SSO now available","data":{"":"Thanks to our friends over at WorkOS, in addition to GitHub, Gitlab, and Passwordless auth, Turborepo now supports Single Sign-on (SSO) from the following SAML providers for enterprise customers:\nAD FS SAML\nAuth0 SAML\nAzure AD SAML\nCyberArk SAML\nGeneric SAML\nG Suite OAuth\nG Suite SAML\nJumpCloud SAML\nMicrosoft OAuth\nOkta SAML\nOneLogin SAML\nOpenID Connect\nPingFederate SAML\nPingOne SAML\nShibboleth\nVMWare SAML\n\nWe also support SCIM (a.k.a. \"Directory Sync\") via:\nAzure AD SCIM\nBambooHR\nG Suite\nGusto\nHibob\nOkta SCIM v1.1\nOkta SCIM v2.0\nRippling\nSCIM v1.1\nSCIM v2.0\nWorkday\n\nIf you're team in interested in activating SAML SSO, please contact us turborepo@vercel.com.","whats-next#What's next?":"We take security extremely seriously. And while SSO is certainly a must in 2021, we are also currently undergoing a third-party SOC 2 Type 2 examination as well. Last but not least, we are adding biometric/U2F access controls and audit logs this fall. Stay tuned for updates."}},"/blog/turbo-0-4-0":{"title":"Turborepo 0.4.0","data":{"":"I'm excited to announce the release of Turborepo v0.4.0!\n10x faster: turbo has been rewritten from the ground up in Go to make it even more blazing fast\nSmarter hashing: Improved hashing algorithm now considers resolved dependencies instead of just the contents of the entire root lockfile\nPartial lockfiles / sparse installs: Generate a pruned subset of your root lockfile and monorepo that includes only the necessary packages needed for a given target\nFine-grained scheduling: Improved task orchestration and options via pipeline configuration\nBetter cache control: You can now specify cache outputs on a per-task basis","rewritten-in-go#Rewritten in Go":"Although I initially prototyped turbo in TypeScript, it became clear that certain items on the roadmap would require better performance. After around a month or so of work, I'm excited to finally release Go version of the turbo CLI. Not only does it boot in a milliseconds, but the new Go implementation is somewhere between 10x and 100x faster at hashing than the Node.js implementation. With this new foundation (and some features you're about to read about), Turborepo can now scale to intergalactic sized projects while remaining blazing fast all thanks to Go's awesome concurrency controls.","better-hashing#Better Hashing":"Not only is hashing faster in v0.4.0, but also a lot smarter.The major change is that turbo no longer includes the hash of the contents of the root lockfile in its hasher (the algorithm responsible for determining if a given task exists in the cache or needs to be executed). Instead, turbo now hashes the set of the resolved versions of a package's dependencies and devDependencies based on the root lockfile.The old behavior would explode the cache whenever the root lockfile changed in any way. With this new behavior, changing the lockfile will only bust the cache for those package's impacted by the added/changed/removed dependencies. While this sounds complicated, again all it means is that when you install/remove/update dependencies from npm, only those packages that are actually impacted by the changes will need to be rebuilt.","experimental-pruned-workspaces#Experimental: Pruned Workspaces":"One of our biggest customer pain points/requests has been improving Docker build times when working with large Yarn Workspaces (or really any workspace implementation). The core issue is that workspaces' best feature--reducing your monorepo to a single lockfile--is also its worst when it comes to Docker layer caching.To help articulate the problem and how turbo now solves it, let's look at an example.Say we have a monorepo with Yarn workspaces that includes a set of packages called frontend, admin, ui, and backend. Let's also assume that frontend and admin are Next.js applications that both depend on the same internal React component library package ui. Now let's also say that backend contains an Express TypeScript REST API that doesn't really share much code with any other part of our monorepo.Here's what the Dockerfile for the frontend Next.js app might look like:\nFROM node:alpine AS base\nRUN apk update\nWORKDIR /app\n\n# Add lockfile and package.jsons\nFROM base AS builder\nCOPY *.json yarn.lock ./\nCOPY packages/ui/*.json ./packages/ui/\nCOPY packages/frontend/*.json ./packages/frontend/\nRUN yarn install\n\n# Copy source files\nCOPY packages/ui/ ./packages/ui/\nCOPY packages/frontend/ ./packages/frontend/\n\n# Build\nRUN yarn --cwd=packages/ui/ build\nRUN yarn --cwd=packages/frontend/ build\n\n# Start the Frontend Next.js application\nEXPOSE 3000\nRUN ['yarn', '--cwd', 'packages/frontend', 'start']\nWhile this works, there are some things that could be a lot better:\nYou manually COPY in the internal packages and files needed to build the target app and need to remember which need to be built first.\nYou COPY the root yarn.lock lockfile into the correct position very early in the Dockerfile, but this lockfile is the lockfile for the entire monorepo.\n\nThis last issue is especially painful as your monorepo gets larger and larger because any change to this lockfile triggers a nearly full rebuild regardless of whether or not the app is actually impacted by the new/changed dependencies.....until now.With the all new turbo prune command, you can now fix this nightmare by deterministically generating a sparse/partial monorepo with a pruned lockfile for a target package--without installing your node_modules.Let's look at how to use turbo prune inside of Docker.\nFROM node:alpine AS base\nRUN apk update && apk add git\n\n## Globally install `turbo`\nRUN npm i -g turbo\n\n# Prune the workspace for the `frontend` app\nFROM base as pruner\nWORKDIR /app\nCOPY . .\nRUN turbo prune --scope=frontend --docker\n\n# Add pruned lockfile and package.json's of the pruned subworkspace\nFROM base AS installer\nWORKDIR /app\nCOPY --from=pruner /app/out/json/ .\nCOPY --from=pruner /app/out/yarn.lock ./yarn.lock\n# Install only the deps needed to build the target\nRUN yarn install\n\n# Copy source code of pruned subworkspace and build\nFROM base as builder\nWORKDIR /app\nCOPY --from=pruner /app/.git ./.git\nCOPY --from=pruner /app/out/full/ .\nCOPY --from=installer /app/ .\nRUN turbo run build --scope=frontend\n\n# Start the app\nFROM builder as runner\nEXPOSE 3000\nRUN ['yarn', '--cwd', 'packages/frontend', 'start']\nSo what exactly is the output of the turbo prune? A folder called out with the following inside of it:\nA folder json with the pruned workspace's package.jsons\nA folder full with the pruned workspace's full source code, but only including the internal packages that are needed to build the target\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the packages in the pruned workspace.\n\nThanks to the above, Docker can now be set up to only rebuild each application when there is a real reason to do so. So frontend will only rebuild when its source or dependencies (either internal or from npm) have actually changed. Same same for admin and backend. Changes to ui, either to its source code or dependencies, will trigger rebuilds of both frontend and admin, but not backend.While this example seems trivial, just imagine if each app takes up to 20 minutes to build and deploy. These savings really start to add up quickly, especially on large teams.","pipelines#Pipelines":"To give you even more control over your Turborepo, we've added pipeline to turbo's configuration. This new field in lets you specify how the npm scripts in your monorepo relate to each other as well as some additional per-task options. turbo then uses this information to optimally schedule your tasks in your monorepo, collapsing waterfalls that would otherwise exist.Here's how it works:\n// <root>/package.json\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// This `^` tells `turbo` that this pipeline target relies on a topological target being completed.\n// In english, this reads as: \"this package's `build` command depends on its dependencies' or\n// devDependencies' `build` command being completed\"\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n//  `dependsOn` without `^` can be used to express the relationships between tasks at the package level.\n// In English, this reads as: \"this package's `test` command depends on its `lint` and `build` command first being completed\"\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"lint\": {},\n\"dev\": {}\n}\n}\n}\nThe above config would then be interpreted by turbo to optimally schedule execution.What's that actually mean? In the past (like Lerna and Nx), turbo could only run tasks in topological order. With the addition of pipelines, turbo now constructs a topological \"action\" graph in addition to the actual dependency graph which it uses to determine the order in which tasks should be executed with maximum concurrency. The end result is that you no longer waste idle CPU time waiting around for stuff to finish (i.e. no more waterfalls).","improved-cache-control#Improved Cache Control":"Thanks to pipeline, we now have a great place to open up turbo's cache behavior on a per-task basis.Building on the example from above, you can now set cache output conventions across your entire monorepo like so:\n// <root>/package.json\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// Cache anything in dist or .next directories emitted by a `build` command\n\"outputs\": [\"dist/**\", \".next/**\"]\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// Cache the test coverage report\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"dev\": {\n// Never cache the `dev` command\n\"cache\": false\n},\n\"lint\": {},\n}\n}\n}\nNote: Right now, pipeline exists at the project level,\nbut in later releases these will be overridable on per-package basis.","whats-next#What's Next?":"I know this was a lot, but there's even more to come. Here's what's up next on the Turborepo roadmap.\nA landing page!\nRemote caching w/ @turborepo/server\nBuild scans, telemetry, and metrics and dependency and task graph visualization\nDesktop Console UI\nIntelligent watch mode\nOfficial build rules for TypeScript, React, Jest, Node.js, Docker, Kubernetes, and more","credits#Credits":"Iheanyi Ekechukwu for guiding me through the Go ecosystem\nMiguel Oller and the team from Makeswift for iterating on the new prune command"}},"/blog/turbo-1-1-0":{"title":"Turborepo 1.1","data":{"":"Since releasing Turborepo v1.0 in mid-December, we've seen incredible adoption:\n5.5k+ GitHub Stars\n70k+ weekly npm downloads\n65+ OSS contributors\nIn production at Vercel, AWS, PayPal, Twilio, Contentful, Miro, Framer, Discord.js, Rocket.chat, Astro.build\n585+ members of the Turborepo Community Discord\n\n\n\nWe're further improving build performance and caching with Turborepo v1.1, featuring:\nAutomatic Migrations: Official idempotent migration scripts to assist with upgrading.\nturbo.json Support: Turborepo configuration now lives in its own file.\nFaster Package Manager Detection: Turborepo now respects the packageManager key in the root package.json.\nEnvironment Variable Dependencies: Define how environment variables impact global and task-specific caching.\nPartial Support for Yarn v2+: Support for yarn v2+ with nodeLinker: \"node-modules\".\n\nUpdate today by running npm install turbo@latest. After running turbo, you'll see instructions about how to use @turbo/codemod to run automatic migrations for v1.1.","automatic-migrations#Automatic Migrations":"Turborepo now provides idempotent code transformations and automatic migration scripts (a.k.a \"codemods\") to help upgrade your Turborepo codebase when a feature is deprecated or will be deprecated in the future.Codemods are transformations that run on your codebase programmatically. This saves you time by applying a large number of changes to your code automatically, without having to manually go through and edit every file.","usage#Usage":"npx @turbo/codemod <transform> <path>\n\ntransform - the name of transform, see available transforms in the docs.\npath - files or directory to transform.\n--dry - Do a dry run, no code will be edited.\n--print - Prints the changed output for comparison.\n\nFor more information about specific transforms, check out the new Codemods documentation.","turbojson-support#turbo.json Support":"Turborepo configuration is now defined in a turbo.json file in the root of your monorepo. This is an improvement over having a turbo key in package.json for those who want to quickly jump straight to their Turborepo configuration in their code editors.To automatically migrate from your current configuration in package.json, check out a new branch, navigate to the root of your monorepo and run the following codemod:\nnpx @turbo/codemod create-turbo-config .\nFor more information on this transformation, check out the documentation.","faster-package-manager-detection#Faster Package Manager Detection":"Turborepo now supports the recently established packageManager field in package.json for faster package manager detection. Previously, turbo would check for specific files to infer this information. To automatically set this field, check out a new branch, navigate to the root of your monorepo and run:\nnpx @turbo/codemod add-package-manager .\nFor more information on this transformation, check out the documentation.","environment-variable-dependencies#Environment Variable Dependencies":"When you use turbo with tools that inline environment variables at build time (e.g. Next.js or Create React App), it is important you tell turbo about it to avoid shipping a cached artifact with the wrong environment variables.You can now control turbo's cache fingerprinting (a.k.a. hashing) behavior based on the values of both environment variables and the contents of files:\nIncluding environment variables in a dependsOn in your pipeline definition prefixed by a $ will impact the cache fingerprint on a per-task or per-package-task basis.\nIncluding environment variables in globalDependencies list prefixed by a $ will impact the cache fingerprint of all tasks.\nIncluding files or globs of files in globalDependencies will impact the cache fingerprint of all tasks.\nThe value of any environment variable that includes THASH in its name will impact the cache fingerprint of all tasks.\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": {\n\"^build\"\n// env vars will impact hashes of all \"build\" tasks\n\"$SOME_ENV_VAR\"\n},\n\"outputs\": [\"dist/**\"]\n},\n\"web#build\": { // override settings for the \"build\" task for the \"web\" app\n\"dependsOn\": [\n\"^build\",\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"$STRIPE_SECRET_KEY\",\n\"$NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"$NEXT_PUBLIC_ANALYTICS_ID\",\n],\n\"outputs\": [\".next/**\"],\n},\n\"docs#build\": { // override settings for the \"build\" task for the \"docs\" app\n\"dependsOn\": [\n\"^build\",\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"$STRIPE_SECRET_KEY\",\n\"$NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"$NEXT_PUBLIC_ANALYTICS_ID\",\n],\n\"outputs\": [\".next/**\"],\n}\n},\n\"globalDependencies\": [\n\"$GITHUB_TOKEN\"// env var that will impact the hashes of all tasks,\n\"tsconfig.json\" // file contents will impact the hashes of all tasks,\n\".env.*\" // glob file contents will impact the hashes of all tasks,\n]\n}\nNote: In most monorepos, you don't often use environment variables in shared packages, but mostly in applications. Thus, to get higher cache hit rates, you should only include environment variables in the app-specific tasks where they are used/inlined.For more information, read the caching and hashing documentation.","partial-yarn-v2v3-support#Partial Yarn v2/v3 support":"In addition to Yarn v1, npm, and pnpm package managers, Turborepo now supports Yarn v2+ with nodeLinker: \"node-modules\" set in .yarnrc.yml. This key tells Yarn v2+ to mimic Yarn v1's node_modules installation behavior. Yarn v2+ Plug'n'Play (a.k.a. \"PnP\") is not currently supported.","whats-next#What's next?":"Since our launch, Turborepo has focused on seamless incremental adoption/migration and speeding up CI/CD. We are committed to both of those values, but now we'll also be focusing on improving Turborepo's day-to-day ergonomics for local development and observability. We're really excited about this next chapter and will be sharing more details soon.","were-hiring#We're hiring!":"The Turborepo team at Vercel is hiring! We're specifically looking for full time Senior Full Stack Software Engineers and Senior DevOps/Infrastructure Engineers to help us make Turborepo even better."}},"/blog/turbo-1-2-0":{"title":"Turborepo 1.2","data":{"":"Friday, April 8th, 2022\n\n\nSince releasing Turborepo v1.1 in late January, we've seen incredible adoption and community growth:\n6.5k+ GitHub Stars\n140k+ weekly npm downloads (doubling since our last blog post for v1.1)\n95+ OSS contributors\n900+ members of the Turborepo Community Discord\n1.6 years of Time Saved through Remote Caching on Vercel, saving more than 2.5 months every week\n\nWe've further improved ergonomics, observability, and security with Turborepo v1.2 featuring:\nNew Task Filtering API: --filter adds more powerful task filtering capabilities to turbo run\nHuman-readable and JSON dry runs: --dry-run flag can print out information about a turbo run without executing any tasks, in both human and JSON-parse friendly formats\nImproved Internal Scheduler and Graph: We refactored turbo 's internal scheduler and graph to be more ergonomic and predictable\nEnhanced Remote Cache Security: Cryptographically sign remote cache artifacts with your own secret key\n\nUpdate today by running npm install turbo@latest. After running turbo run for the first time, you'll see instructions about how to use @turbo/codemod to run automatic migrations for v1.2.","new-task-filtering-api#New Task Filtering API":"We are excited to release one of our most requested features: the ability to expressively filter tasks through a --filter flag. The --filter flag is the much more powerful successor to the current combination of --scope, --include-dependencies, --since, and --no-deps flags.With --filter you can tell turbo to restrict executing commands to a subset of matched packages in your monorepo based on name, folder, or even if it has changed since a git commit ref.Take a look at some examples of what you can accomplish with the new --filter command:\n--filter=<package_name> - match by exact package name or glob pattern\n--filter=...<package_name>- match by package name/glob and include all dependent packages of matches\n--filter=...^<package_name>- match by package name/glob and include all dependent packages of matches, but exclude the matches themselves\n--filter=<package_name>... - match by package name/glob and include all the matched packages' dependencies\n--filter=<package_name>^... - match by package name/glob and include all matched package dependencies, but exclude the matches themselves\n--filter={./path/to/package} - match by path or filesystem glob pattern\n--filter=[origin/main] - match by changed packages since a git commit ref\n\nYou can use multiple filters together to get even more granular filtering as well as combine each part of the above patterns {}, [] , ^ , and ... to express more complex behavior.For example, if you had an app located in ./apps/web directory with local packages used as dependencies, and a Turborepo pipeline where test depends on ^build topologically, running:\nturbo run test --filter={./apps/web}[HEAD^1]^...\nwould tell turbo to ensure dependencies are built and to run the test script in all of the local dependencies of the app located in ./apps/web, not including that app itself, if the app has changed since HEAD^1.For more details and examples, refer to the new filtering documentation.","debug-and-automate-with---dry-run#Debug and Automate with --dry-run":"You can now see the impact of turbo run without actually executing any commands by appending either --dry-run or --dry-run=json to any turbo run command. This will result in either human or JSON output.Dry runs are incredibly useful for two situations:\nDebugging and testing run options\nUsing turbo filtering and task graphs for building automations\n\n\n\n\n\n\n\nWe hope that this will improve visibility into what turbo is doing, speeding up debugging, and make it easier to leverage turbo in dynamic CI/CD systems.","improved-internal-scheduler-and-graph#Improved Internal Scheduler and Graph":"When using turbo run, every package.json task is added to an internal graph to map dependencies based on the inferred relationships defined in your Turborepo pipeline. This task graph allows Turborepo to efficiently schedule incremental concurrent task running and cache task outputs for later use.We have made major improvements to the internal task scheduler and resulting graph structure, resulting in better performance and a better developer experience. For example, in many cases, you will no longer need to use --include-dependencies. Instead, after specifying your task entry points, the new and improved graph will automatically handle this graph resolution on your behalf.","cache-outputs-integrity-and-signature-verification#Cache Outputs Integrity and Signature Verification":"You can now configure Turborepo to sign remote cache outputs using HMAC-SHA256 with a secret key before uploading them to the Remote Cache. When Turborepo downloads signed cache artifacts, it will now verify the artifact's integrity and authenticity. Any artifact that fails to verify will be ignored, discarded, and treated as a cache miss by Turborepo.To enable this feature, set the remoteCache options in your turbo.json config file to include signature: true. Then specify your secret key by declaring the TURBO_REMOTE_CACHE_SIGNATURE_KEY environment variable.\n{\n\"$schema\": \"[https://turborepo.org/schema.json](https://turborepo.org/schema.json)\",\n\"remoteCache\": {\n// Indicates if signature verification is enabled.\n\"signature\": true\n}\n}","other-bug-fixes-and-improvements#Other bug fixes and improvements":"--sso-team flag now enables teams with SAML tokens to log in through turbo login with correct team permissions\n--log-output flag allows you to control what logs are printed to the terminal, and when, allowing you to focus only on what's new\nFORCE_COLOR environment variable is now supported\nTURBO_FORCE=true environment variable will now force execution\n--remote-only and TURBO_REMOTE_ONLY=true will tell turbo to only use Remote Caching\nWe now show >>> FULL TURBO when there's at least one task attempted\nYarn v2+ with Plug'n'Play (PnP linker) is supported for the turbo run command, but turbo prune is still not fully supported\nFixed regression with chrome tracing if --profile is specified\nYou can now set concurrency by percentage of CPUs with --concurrency=50%","were-hiring#We're hiring!":"The Turborepo team at Vercel is hiring! We're up to five core team members already this year and are looking to hire even more. We're specifically looking for full-time Senior Build Systems Engineers.","whats-next#What's next?":"Along with seamless incremental adoption/migration and speeding up CI/CD, we've been focusing on improving Turborepo's day-to-day ergonomics, security, and observability. The new --filter flag, signed artifacts, and dry runs are important steps toward those goals.Next up, we'll be focusing an enhanced local development experience, codebase automations, and overall CLI performance.","thank-you-contributors#Thank you, contributors":"Turborepo is the result of the combined work of over 95 individual developers and our core team.This release was brought to you by the contributions of: @gsoltis09, @jaredpalmer, @gaspar09, @shuding, @rajatkulkarni95, @VanTanev, @Kikobeats, @tknickman, @thebanjomatic, @chelkyl, @elado, @finn-orsini, @becca, @weyert, @ekosz"}},"/blog/turbo-1-3-0":{"title":"Turborepo 1.3","data":{"":"Thursday, June 23rd, 2022\n\n\nWith Turborepo 1.3 we are bringing improved caching and flexibility which includes:\nRestricted hash inputs: Specify the files in a package folder that impact caching with inputs.\nRoot script running and caching: Run and cache package.json scripts from the root of the monorepo.\nNew CI/CD Recipes: We added recipes for using Turborepo with popular CI providers.\n\nUpdate today by running npm install turbo@latest.","pipeline-inputs#Pipeline inputs":"In addition to environment variables, dependencies, and pipeline configurations, turbo will consider all non-gitignored files in package folder when calculating each package.json script's hash fingerprint (the key that turbo uses to index its cache and to determine if a script needs to be re-executed). With Turborepo 1.3+, you can now specify globs of inputs in your turbo.json pipeline to control which files are relevant for a particular script for caching. This means that you can now express the following in turbo.json\nIgnore changes to all markdown files in a package or app's folder.\nDon't bother rebuilding an app if only its test files have changed.\nOnly re-run tests if either source files or test files have been changed in a package or folder.\nand more.\n\nLet's walk through a concrete example: imagine we have a monorepo with a Next.js application for a documentation website in ./apps/docs-site, some packages, and some markdown files in the root of the monorepo in a ./docs folder.\n.\n├── docs/\n│   ├── api-reference.md\n│   ├── getting-started.md\n│   └── intro.md\n├── apps/\n│   ├── docs-site/\n│   │   ├── components/\n│   │   ├── pages/\n│   │   │   └── [slug].js\n│   │   ├── README.md\n│   │   └── package.json\n│   └── web-site/\n│       ├── pages/\n│       ├── README.md\n│       └── package.json\n├── packages/\n│   ├── configs/\n│   └── ui/\n├── package.json\n└── turbo.json\nLet's assume that the Next.js docs-site renders the markdown files from the ./docs folder. We can now set up the build script in the app's package.json to use inputs in turbo.json to better specify exactly which files are relevant (and which should impact caching) as follows:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ... omitted for brevity\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\".next/**\", \"dist/**\"]\n},\n\"docs#build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\".next/**\"],\n// Define set of relevant globs which impact caching of docs site\n// builds\n\"inputs\": [\n\"../../docs/**/*.md\",\n\"pages/**\",\n\"components/**\",\n\"package.json\"\n]\n}\n}\n}\nNote: Like outputs, inputs are defined relative to the related package.json , but they can be outside of a given folder (e.g. ../../docs/**).","run-and-cache-scripts-from-the-root-of-your-monorepo#Run and cache scripts from the root of your monorepo":"As of 1.3, turbo can now run and cache scripts from the package.json file at the root of the monorepo, which will help significantly when migrating to Turborepo.To set this up, specify a root script in your pipeline configuration in your turbo.json using the form \"//#<script>\": {...}. The // tells turbo that the script is relative to the root of the monorepo and not each workspace package.There are 2 important things to note about root scripts and execution scope:\nIf you already have \"build\": {...} in your pipeline, but want to include the build script defined in the monorepo's root package.json file when running turbo run build, you may opt the root into the execution's scope by also including \"//#build\": {...} in your configuration as well.\nConversely, you do not need to define a generic \"my-script\": {...} entry if all you need is \"//#my-script\": {...}.\n\nA sample pipeline that defines the root script check-examples and opts the root into test might look like:\n{\n\"name\": \"my-turborepo\",\n\"private\": true,\n\"scripts\": {\n\"test\": \"echo 'test!'\",\n\"check-examples\": \"./check-examples.sh\"\n},\n\"devDependencies\": {\n\"turbo\": \"latest\"\n}\n}\n\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n// This will cause the \"test\" script from all workspace package.json's\n// AND the root package.json to be included when \"turbo run test\" is run\n\"//#test\": {\n\"dependsOn\": [],\n\"outputs\": []\n},\n// This will cause the \"check-examples\" script in the root package.json\n// to be run when \"turbo run check-examples\" is run. Since a general\n// \"check-examples\" script is not defined in the pipeline, only the root\n// package.json's \"check-examples\" script will be included\n// when \"turbo run check-examples\" is run\n\"//#check-examples\": {\n\"dependsOn\": [],\n\"outputs\": [],\n\"inputs\": [\n\"examples/**/*.ts\",\n\"examples/**/*.tsx\",\n\"examples/**/*.json\",\n\"examples/**/*.js\",\n\"examples/**/*.yaml\",\n\"cli/**/*.ts\",\n\"./scripts/run-example.sh\"\n]\n}\n}\n}\nNote: We suggest specifying inputs whenever declaring a root task in your pipeline to improve caching.","new-cicd-recipes#New CI/CD Recipes":"We added recipes for using Turborepo and Remote Caching with:\nCircleCI\nGitHub Actions\nGitlab CI\nTravis CI\n\nIf there are other recipes you would like to see here please let us know by opening up a GitHub Discussion.","other-bug-fixes-and-improvements#Other Bug Fixes and Improvements":"Improved git operations and hashing\nBetter cycle detection in dependency graph analysis\nAdded support for Windows ARM 64-bit architectures\nImproved Remote Cache error logging\nAdded Storybook to the Design System example","community#Community":"Since releasing Turborepo v1.2 in early April, we've seen incredible adoption and community growth:\n8.1k+ GitHub Stars\n275k+ weekly NPM downloads (up ~2x)\n1,200+ members of the Turborepo Community Discord\n5.8 years of compute time saved through Remote Caching on Vercel (up ~5x), saving +7 months per week now\n\nTurborepo is the result of the combined work of over 136 contributors including our core team.This release was brought to you by the contributions of: @gsoltis, @nathanhammond, @tknickman, @jaredpalmer, @zvictor, @ObliviousHarmony, @O4epegb, @rafaeltab, @mcmontseny, @bertspaan, @Jastor11, and @enBonnetThank you for your continued support, feedback, and collaboration with us to make Turborepo your build tool of choice."}},"/blog/turbo-1-4-0":{"title":"Turborepo 1.4","data":{"":"Tuesday, August 9th, 2022\n\n\nTurborepo 1.4 brings:\nAutomatic environment variable inclusion: We'll automatically infer popular framework environment variables for you. No need to declare them yourself in turbo.json.\neslint-config-turbo: Enhanced feedback with a new ESLint plugin.\nNew framework and library examples: New starters and examples requested by the community.\n\nUpdate today by running npm install turbo@latest.","automatic-environment-variable-inclusion#Automatic environment variable inclusion":"To help ensure correct caching across environments Turborepo will now automatically infer and include public environment variables when calculating cache keys for apps built with Astro, Create React App, Gatsby, Next.js, Nuxt, SvelteKit, Vite, Vue, and more. You can safely remove framework-specific public environment variables from turbo.json if you manually declared them.\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\n\"^build\"\n-       // Include build time public inlined environment variables that\n-       // are different in development and production, so that\n-       // Turborepo does not use the same cached build\n-       // across environments\n-       \"$NEXT_PUBLIC_EXAMPLE_ENV_VAR\"\n]\n}\n}\n}\nNote that this automatic detection and inclusion only works if Turborepo successfully infers the framework your apps are built with. Additionally, the environment variables will only be included in the cache key for tasks in workspaces where that framework is used. In other words, environment variables inferred for Next.js apps, will only be included in the cache key for workspaces detected as Next.js apps. Tasks in other workspaces in the monorepo will not be impacted.For example, consider a monorepo with three workspaces: a Next.js project, a Create React App project, and a TypeScript package. Each has a build script, and both apps depend on the TypeScript project. Let's say that this Turborepo has a standard turbo.json pipeline that builds them all in order:\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n}\n}\n}\nAs of 1.4, when you run turbo run build, Turborepo will not consider any build time environment variables relevant when building the TypeScript package. However, when building the Next.js app, Turborepo will infer that environment variables starting with NEXT_PUBLIC_ could alter the output of the .next folder and should thus be included when calculating the hash. Similarly, when calculating the hash of the Create React App's build script, all build time environment variables starting with REACT_APP_PUBLIC_ will be included.This improvement in hash specificity by framework is a significant step toward optimal, safe, and correct caching.","eslint-config-turbo#eslint-config-turbo":"We've also created a new ESLint config for further in-editor assistance to help ensure your Turborepo cache can be correctly shared across every environment. While our new hashing algorithm should cover most situations with most frameworks, this ESLint config will provide in-editor feedback for teams using other build time inlined environment variables that are not framework-prefixed but impact build outputs (i.e. caching), and teams using their own in-house frameworks that we cannot detect automatically.To get started, extend from eslint-config-turbo in your root eslintrc file:\n{\n// Automatically flag env vars missing from turbo.json\n\"extends\": [\"next/core-web-vitals\", \"turbo\"]\n}\nIf you prefer more control over the rules - use can install and configure the eslint-plugin-turbo plugin directly by first adding it to plugins and then configuring the desired rules:\n{\n\"extends\": [\"next/core-web-vitals\"],\n\"plugins\": [\"turbo\"],\n\"rules\": {\n// Automatically flag env vars missing from turbo.json\n\"turbo/no-undeclared-env-vars\": \"error\"\n}\n}\nThe plugin will warn you if you are using non-framework-related environment variables in your code that have not been declared in your turbo.json.As of 1.4.x, we now include eslint-config-turbo in all of our examples and in new projects generated via npx create-turbo.Learn more about ESLint configs and plugins in the ESLint docs.","new-framework-and-library-examples#New framework and library examples":"Based on your feedback and suggestions, we've created new examples to integrate Turborepo into your workflow:\nSvelte\nDocker\nCreate React App\nReact Native\nPrisma\nTailwind\n… and more!","other-bug-fixes-and-improvements#Other bug fixes and improvements":"Allow both sides of git comparison (#1442)\nProperly rebuild packages that share a name prefix (#1538)\nCache files with the correct file permissions (#1429)","community#Community":"Since releasing Turborepo v1.3 in June, we've seen incredible adoption and community growth:\n8.65k+ GitHub Stars\n365k weekly NPM downloads, up 2x since late April\n10 years of compute time saved through Remote Caching on Vercel, saving 10 months per week\n\nTurborepo is the result of the combined work of all of our contributors including our core team.This release was brought to you by the contributions of: @B2o5T, @chitchu, @elis, @gsoltis, @harshcut, @jaredpalmer, @kocisov, @nathanhammond, @neolivz, @NuroDev, @oneezy, @samouri, @shayc, @StevenMatchett, @tknickman, @trevorr, @zsoldosp, and more!Thank you for your continued support, feedback, and collaboration to make Turborepo your build tool of choice."}},"/blog/turbo-1-5-0":{"title":"Turborepo 1.5","data":{"":"Monday, September 19th, 2022\n\n\nTurborepo 1.5 is a huge leap forward for our documentation and DX, as well as bringing big improvements to turbo prune:\nThe Monorepo Handbook: We've built the missing manual for your monorepo - a guide on workspaces, code sharing, integrating common tools and much more.\nDrop the run: turbo run <task> can now be shortened to turbo <task>\nturbo prune now supports pnpm and yarn 2+: Pruning your monorepo is now supported in pnpm and yarn@berry.\nImproved environment variables in turbo.json: Environment variables are now first-class citizens in your Turborepo pipeline configuration.\nChanges to package.json hashing: We've improved how we hash package.json when running tasks.\n\nUpdate today by running npm install turbo@latest.","the-monorepo-handbook#The Monorepo Handbook":"Setting up a monorepo for the first time often means navigating a lot of new concepts. You'll need to understand workspaces, package installation, sharing code and dependency management - and a lot more.This often meant that folks who wanted to set up a monorepo from scratch had to piece information together from different documentation sites. First pnpm, then tsup, then back to changesets, then back to Turborepo for dessert.We want to fill this gap with the Monorepo Handbook. We've built guides on how to integrate all the tools you'll need to make ship happen with your monorepo, including guides on:\nInstalling Packages\nLinting\nDevelopment Tasks\nBuilding Apps\nPublishing Packages","drop-the-run#Drop the run":"You can now run tasks with the Turborepo CLI using turbo <task>.\n- turbo run build\n+ turbo build\n\n\n- turbo run lint build test\n+ turbo lint build test\nIf your task name conflicts with a built-in turbo subcommand, we'll run our subcommand instead. That means you shouldn't name your tasks things like prune, run, or login - since those are built-in subcommands.turbo run <task> will continue to work, and there are no plans to deprecate it.","prune-now-supported-on-pnpm-and-yarn-2#Prune now supported on pnpm and yarn 2+":"We're delighted to announce that turbo prune now supports in pnpm, yarn, and yarn 2+.You can use turbo prune to create a pruned subset of your monorepo with a dedicated lockfile--with the correct dependencies needed for a given target application and its dependencies. This is especially useful for using efficiently Turborepo within a Docker image.As part of the new handbook, we've also added a section on using turbo prune to build docker images.Check out our previous blog on prune to learn more.","environment-variables-in-turbojson#Environment variables in turbo.json":"We've introduced two new keys to turbo.json - env and globalEnv. These allow environment variables to be configured separately from tasks:\n{\n\"globalDependencies\": [\n-   \"$DATABASE_URL\"\n],\n+ \"globalEnv\": [\n+   \"DATABASE_URL\"\n+ ],\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\n-       \"$BUILD_ENV\"\n],\n+     \"env\": [\n+       \"BUILD_ENV\"\n+     ]\n}\n}\n}\nglobalEnv and env allow you to specify a list of environment variables without $ prefixes. This makes the configuration file significantly easier to read. Read more in our updated docs.To help migrate from the previous syntax, we've prepared a codemod. You can run npx @turbo/codemod migrate-env-var-dependencies.This work builds on the automatic env variable detection we added in 1.4.0.","changes-to-packagejson-hashing#Changes to package.json hashing":"The package.json file in each workspace is now always considered an input for tasks in that workspace. This means that if you change the definition for a task in package.json, we want to invalidate any caches from the previous definition.This also counts for the package.json in the root. Changes to the root package.json will invalidate tasks in the root workspace.This helps make Turborepo's cache a bit smarter, and less likely to trip up when task definitions change.","community#Community":"Since releasing Turborepo v1.4 in August, we've seen incredible adoption and community growth:\n9.5k+ GitHub Stars\n440k weekly NPM downloads\n15 years of compute time saved through Remote Caching on Vercel, saving over a 1 year per week, up 2x since July\n\nTurborepo is the result of the combined work of all of our contributors including our core team.This release was brought to you by the contributions of: @7flash, @afady, @alexander-young, @atilafassina, @bguedes-moz, @bobaaaaa, @brunojppb, @chris-olszewski, @DoctorJohn, @erj826, @futantan, @gsoltis, @HosseinAgha, @ivov, @jaredpalmer, @joelhooks, @knownasnaffy, @laurentlucian, @leerob, @MarceloAlves, @mattpocock, @mauricekleine, @mehulkar, @Misikir, @nareshbhatia, @nathanhammond, @pakaponk, @PhentomPT, @renovate, @ruisaraiva19, @samuelhorn, @shemayas, @shuding, @t-i-0414, @theurgi, @tknickman, @yanmao-cc, and more!Thank you for your continued support, feedback, and collaboration to make Turborepo your build tool of choice."}},"/blog/turbo-1-6-0":{"title":"Turborepo 1.6","data":{"":"Wednesday, October 19th, 2022\n\n\nTurborepo 1.6 changes the game for Turborepo - you can now use it in any project.\nTurborepo in non-monorepos: Seeing slow builds on your project? You can now use Turborepo to speed up builds in any codebase with a package.json.\nturbo prune now supports npm: Pruning your monorepo is now supported in monorepos using npm, completing support for all major workspace managers.\nFaster caching: We've improved the way we handle local file writes, meaning a big speed-up of Turborepo's cache.\n\nUpdate today by running npm install turbo@latest.","any-codebase-can-use-turborepo#Any codebase can use Turborepo":"Turborepo helps speed up tasks in your codebase. Until now, we'd built Turborepo specifically for monorepos - codebases which contain multiple applications and packages.Turborepo is fantastic in monorepos because they have so many tasks to handle. Each package and app needs to be built, linted, and tested.But we got to thinking: lots of codebases that aren't monorepos run plenty of tasks. Most CI/CD processes do a lot of duplicated work that would benefit from a cache.So we're excited to announce that any codebase can now use Turborepo. Try it out now:","add-turborepo-to-your-project#Add Turborepo to your project":"Install turbo:\n\n\n\n\nnpm install turbo --save-dev\n\n\n\nyarn add turbo --dev\n\n\n\npnpm install turbo --save-dev\n\n\n\nAdd a turbo.json file at the base of your new repository:\n\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nSome Vite starters ship with a package.json that looks like this:\n{\n\"scripts\": {\n\"build\": \"tsc && vite build\"\n}\n}\nWe recommend splitting these into a lint and build script.\n{\n\"scripts\": {\n\"build\": \"vite build\",\n\"lint\": \"tsc\"\n}\n}\nThis enables turbo to schedule them separately.\n\n\nTry running build and lint with turbo:\n\n\nturbo build lint\nCongratulations - you just ran your first build with turbo. You can try:\nRunning through the full Quickstart.\nCheck out our updated Core Concepts docs to understand what makes Turborepo special.","when-should-i-use-turborepo#When should I use Turborepo?":"Turborepo being available for non-monorepos opens up a lot of new use cases. But when is it at its best?","when-scripts-depend-on-each-other#When scripts depend on each other":"You should use turbo to run your package.json scripts. If you've got multiple scripts which all rely on each other, you can express them as Turborepo tasks:\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n},\n\"lint\": {\n// 'build' should be run before 'lint'\n\"dependsOn\": [\"build\"]\n},\n\"test\": {\n// 'build' should be run before 'test'\n\"dependsOn\": [\"build\"]\n}\n}\n}\nThen, you can run:\nturbo run lint test\nBecause you've said that build should be run before lint and test, it'll automatically run build for you when you run lint or test.Not only that, but it'll figure out the optimal schedule for you. Head to our core concepts doc on optimizing for speed.","when-you-want-to-run-tasks-in-parallel#When you want to run tasks in parallel":"Imagine you're running a Next.js app, and also running the Tailwind CLI. You might have two scripts - dev and dev:css:\n{\n\"scripts\": {\n\"dev\": \"next\",\n\"dev:css\": \"tailwindcss -i ./src/input.css -o ./dist/output.css --watch\"\n}\n}\nWithout anything being added to your turbo.json, you can run:\nturbo run dev dev:css\nJust like tools like concurrently, Turborepo will automatically run the two scripts in parallel.This is extremely useful for dev mode, but can also be used to speed up tasks on CI - imagine you have multiple scripts to run:\nturbo run lint unit:test e2e:test integration:test\nTurborepo will figure out the fastest possible way to run all your tasks in parallel.","prune-now-supported-on-npm#Prune now supported on npm":"Over the last several releases, we've been adding support for turbo prune on different workspace managers. This has been a challenge - turbo prune creates a subset of your monorepo, including pruning the dependencies in your lockfile. This means we've had to implement logic for each workspace manager separately.We're delighted to announce that turbo prune now works for npm, completing support for all major package managers. This means that if your monorepo uses npm, yarn, yarn 2+ or pnpm, you'll be able to deploy to Docker with ease.Check out our previous blog on turbo prune to learn more.","performance-improvements-in-the-cache#Performance improvements in the cache":"Before 1.6, Turborepo's local cache was a recursive copy of files on the system to another place on disk. This was slow. It meant that for every file that we needed to cache, we'd need to perform six system calls: open, read, and close on the source file; open, write, and close on the destination file.In 1.6, we've cut that nearly in half. Now, when creating a cache, we create a single .tar file (one open), we write to it in 1mb chunks (batched writes), and then close it (one close). The halving of system calls also happens on the way back out of cache.And we didn't stop there. Over the past month we've invested significantly in our build toolchain to enable CGO which unlocks usage of best-in-class libraries written in C. This enabled us to adopt Zstandard's libzstd for compression which gets us an algorithmic 3x performance improvement for compression.After all of these changes we're regularly seeing performance improvements of more than 2x on local cache creation and more than 3x on remote cache creation. This gets even better the bigger your repository is, or the slower your device is (looking at you, CI). This means we've been able to deliver performance wins precisely to those who needed it the most."}},"/blog/you-might-not-need-typescript-project-references":{"title":"You might not need TypeScript project references","data":{"":"If you've worked in a larger TypeScript codebase or monorepo, you are likely familiar with project references. They are indeed fairly powerful.When you reference a project in your tsconfig.json, new things happen:\nImporting modules from a referenced project will instead load its output declaration file (.d.ts)\nIf the referenced project produces an outFile, the output file .d.ts file’s declarations will be visible in this project\nRunning build mode (tsc -b) will automatically build the referenced project if it hasn't been built but is needed\nBy separating into multiple projects, you can greatly improve the speed of typechecking and compiling, reduce memory usage when using an editor, and improve enforcement of the logical groupings of your program.\n\nSounds awesome! Right?! Well...maybe. Once you add references to your project you now need to continuously update them whenever you add or remove packages. That kinda blows.Well...what if you didn't need to?","internal-typescript-packages#\"Internal\" TypeScript Packages":"As it turns out, you might not even need references or even an interim TypeScript build step with a pattern I am about to show you, which I dub \"internal packages.\"An \"internal package\" is a TypeScript package without a tsconfig.json with both its types and main fields in its package.json pointing to the package's untranspiled entry point (e.g. ./src/index.tsx).\n{\n\"name\": \"@sample/my-internal-package\"\n\"main\": \"./src/index.ts\"\n\"types\": \"./src/index.ts\", // yes, this works!\n\"dependencies\": {\n...\n},\n\"devDependencies\": {\n...\n}\n}\nAs it turns out, the TypeScript Language Server (in VSCode) and Type Checker can treat both a raw .ts or .tsx file as its own valid type declaration. This last sentence is obvious once you read it twice. What isn't so obvious, though, is that you can point the types field directly to raw source code.Once you do this, this package can then be used without project references or a TypeScript build step (either via tsc or esbuild etc) as long as you adhere to 2 rules:\nThe consuming application of an internal package must transpile and typecheck it.\nYou should never publish an internal package to npm.\n\nAs far as I can tell, this internal package pattern works with all yarn/npm/pnpm workspace implementations regardless of whether you are using Turborepo or some other tool. I have personally tested this pattern with several different meta frameworks (see below), but I'm sure that it works with others as well.","nextjs#Next.js":"If you use Next.js, you can satisfy these constraints with the next-transpile-modules plugin which will tell Next.js to run certain dependencies through its Webpack/Babel/TypeScript pipelines.","vite#Vite":"Internal packages just work. No extra config is needed.","react-native#React Native":"If you use Expo and use the expo-yarn-workspaces or @turborepo/adapter-expo package, you can use internal packages as long as you are targeting iOS or Android. When you run Expo for these platforms, all of node_modules are automatically transpiled with Metro. However, if you are targeting Expo for web, internal packages will not work because node_modules are oddly not transpiled for web.I reached out to the Expo team about this inconsistency. They are aware of it. It's a legacy wart I'm told.","the-beauty-of-this-pattern#The beauty of this pattern":"This pattern rocks because it saves you from extra needless or duplicative build steps. It also gives you all the editor benefits of project references, but without any configuration.","caveats#Caveats":"When you use an internal package, it's kind of like telling the consuming application that you have another source directory—which has pros and cons. As your consuming application(s) grow, adding more internal packages is identical to adding more source code to that consuming application. Thus, when you add more source code, there is more code to transpile/bundle/typecheck...so this can result in slower builds of the consuming application (as there is just more work to do) but potentially faster (and less complicated) overall build time. When/if overall build time begins to suffer, you might decide to convert your larger internal packages back into \"regular\" packages with .d.ts files and with normal TypeScript build steps.As previously mentioned, this pattern actually has very little to do with Turborepo. It's just super duper awesome and I think you should be aware of it. As we are actively working on preset package build rules (i.e. \"builders\") for Turborepo, we'll using the internal package pattern to skip build steps.","speaking-of-long-build-times#Speaking of long build times...":"Shameless plug here. If you are reading this post, and you're struggling with slow build and test times, I'd love to show you how Turborepo can help. I guarantee that Turborepo will cut your monorepo's build time by 50% or more. You can request a live demo right here."}},"/pack":{"data":{"":""}},"/pack/docs/benchmarks":{"title":"Benchmarks","data":{"":"To track our progress and validate our assumptions, we run benchmarks regularly on the Turbopack repo against Vite and previous versions of Next.js.","metrics#Metrics":"Let's break down exactly what each of these metrics mean, and how they'll impact your day-to-day developer experience.","cold-startup-time#Cold startup time":"This test measures how fast a dev server starts up on an application of various sizes.\n\nTo measure this, we run an end-to-end test which:\nGenerates an application with a set number of JS modules\nRuns the dev server on localhost:3000\nVisits localhost:3000 in Chrome\nWaits until the site has finished loading its last module.","file-updates#File updates":"We also measure how quickly your dev server updates when a source file changes. This helps us get a sense for how fast your dev server will respond to updates.\n\nThis uses a similar setup:\nGenerates an application with a set number of JS modules\nRuns the dev server on localhost:3000\nVisits localhost:3000 in Chrome\nChanges a module in the file system.\nWaits until the site has finished loading the new module."}},"/pack/docs/core-concepts":{"title":"Core Concepts","data":{"":"Let’s dive deep into the internals of Turbopack to figure out why it’s so fast.","the-turbo-engine#The Turbo engine":"Turbopack is so fast because it’s built on a reusable library for Rust which enables incremental computation known as the Turbo engine. Here’s how it works:","function-level-caching#Function-level caching":"In a Turbo engine-powered program, you can mark certain functions as ‘to be remembered’. When these functions are called, the Turbo engine will remember what they were called with, and what they returned. It’ll then save it in an in-memory cache.Here’s a simplified example of what this might look like in a bundler:\n\nWe start with calling readFile on two files, api.ts and sdk.ts. We then bundle those files, concat them together, and end up with the fullBundle at the end. The results of all of those function calls get saved in the cache for later.Let’s imagine that we’re running on a dev server. You save the sdk.ts file on your machine. Turbopack receives the file system event, and knows it needs to recompute readFile(\"sdk.ts\"):\n\nSince the result of sdk.ts has changed, we need to bundle it again, which then needs to be concatenated again.Crucially, api.ts hasn’t changed. We read its result from the cache and pass that to concat instead. So we save time by not reading it and re-bundling it again.Now imagine this in a real bundler, with thousands of files to read and transformations to execute. The mental model is the same. You can save enormous amounts of work by remembering the result of function calls and not re-doing work that’s been done before.","the-cache#The cache":"The Turbo engine currently stores its cache in memory. This means the cache will last as long as the process running it - which works well for a dev server. When you run next dev --turbo in Next v13, you’ll start a cache with the Turbo engine. When you cancel your dev server, the cache gets cleared.In the future, we’re planning to persist this cache - either to the filesystem, or to a remote cache like Turborepo’s. This will mean that Turbopack could remember work done across runs and machines.","how-does-it-help#How does it help?":"This approach makes Turbopack extremely fast at computing incremental updates to your apps. This optimizes Turbopack for handling updates in development, meaning your dev server will always respond snappily to changes.In the future, a persistent cache will open the door to much faster production builds. By remembering work done across runs, new production builds could only rebuild changed files - potentially leading to enormous time savings.","compiling-by-request#Compiling by Request":"The Turbo engine helps provide extremely fast updates on your dev server, but there’s another important metric to consider - startup time. The faster your dev server can start running, the faster you can get to work.There are two ways to make a process faster - work faster, or do less work. For starting up a dev server, the way to do less work is to compile only the code that’s needed to get started.","page-level-compilation#Page-level compilation":"Versions of Next.js from 2-3 years ago used to compile the entire application before showing your dev server. In Next.js [11], we began compiling only the code on the page you requested.That’s better, but it’s not perfect. When you navigate to /users, we’ll bundle all the client and server modules, dynamic-imported modules, and referenced CSS and images. That means if a large part of your page is hidden from view, or hidden behind tabs, we’ll still compile it anyway.","request-level-compilation#Request-level compilation":"Turbopack is smart enough to compile only the code you request. That means if a browser requests HTML, we compile only the HTML - not anything that is referenced by the HTML.If a browser wants some CSS, we’ll compile only that - without compiling referenced images. Got a big charting library behind next/dynamic? Doesn’t compile it until the tab showing the chart is shown. Turbopack even knows to not compile source maps unless your Chrome DevTools are open.If we were to use native ESM, we’d get similar behavior. Except that Native ESM produces a lot of requests to the server, as discussed in our Why Turbopack section. With request-level compilation, we get to both reduce the number of requests and use native speed to compile them. As you can see in our benchmarks, this provides significant performance improvements."}},"/pack/docs/features":{"title":"Features","data":{"":"The practice of building web applications is enormously diverse. In CSS alone, you have SCSS, Less, CSS Modules, PostCSS, and hundreds of other libraries. Frameworks like React, Vue and Svelte require custom setups.When building a bundler, we needed to consider which features would be:\nBuilt-in: they work out of the box, no config required\nAvailable via plugins: usually installed from a registry and configured\nUnavailable: not available at all\n\nTurbopack is in alpha, so very few of these decisions are set in stone. In its current state, Turbopack cannot yet be configured - so plugins are not available yet.Let's discuss which features are available out-of-the-box, in Turbopack's default configuration. We'll also touch on features which will be configurable via plugins."}},"/pack/docs":{"title":"Quickstart","data":{"":"Turbopack is an incremental bundler optimized for JavaScript and TypeScript, written in Rust by the creators of Webpack and Next.js at Vercel.On large applications Turbopack updates 10x faster than Vite and 700x faster than Webpack. For the biggest applications the difference grows even more stark with updates up to 20x faster than Vite.The secret to Turbopack's performance is twofold: highly optimized machine code and a low-level incremental computation engine that enables caching down to the level of individual functions. Once Turbopack performs a task it never does it again.Our team has taken the lessons from 10 years of Webpack, combined with the innovations in incremental computation from Turborepo and Google's Bazel, and created an architecture ready to support the coming decades of computing.\nTurbopack is currently in alpha. It is not yet ready for production use. We appreciate your support and feedback as we work to make it ready for everyone.","quickstart#Quickstart":"As of today, Turbopack can be used in Next.js v13. In the future we will be releasing a standalone CLI, plugin API, and support for other frameworks such as Svelte and Vue. For now, please follow these instructions to get started:\nCreate a Next.js v13 project with Turbopack:\n\n\nnpx create-next-app --example with-turbopack\n\nStart the Next.js development server (with Turbopack):\n\n\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm dev\n\n\nThe Next.js v13 development server is now powered by Turbopack! Startup and updates should both be near-instant. The larger the application, the larger the improvement will be.","next-steps#Next Steps":"Want to learn more about Turbopack? Here's a deep dive on what we think makes it special."}},"/pack/docs/migrating-from-webpack":{"title":"Migrating from Webpack","data":{"":"We're planning Turbopack as the successor to Webpack. In the future, we plan to give Turbopack all the tools needed to support your Webpack app.Currently, migrating to Turbopack from Webpack is not yet possible. In the future, we're planning to offer a smooth migration path for all Webpack users to join the Turbopack future.","will-it-be-compatible-with-webpacks-api#Will it be compatible with Webpack's API?":"Webpack has a huge API. It's extremely flexible and extensible, which is a big reason why it's so popular.We're planning on making Turbopack very flexible and extensible, but we're not planning 1:1 compatibility with Webpack. This lets us make choices which improve on Webpack's API, and lets us optimize for speed and efficiency.","will-we-be-able-to-use-webpack-plugins#Will we be able to use Webpack plugins?":"Webpack plugins are a crucial part of Webpack's ecosystem. They let you customize your toolchain, giving you low-level tools to maximize your productivity.Since we're not offering 1:1 API compatibility, most Webpack plugins won't work out of the box with Turbopack.However, we're working on porting several of the most popular Webpack plugins to Turbopack."}},"/pack/docs/roadmap":{"title":"Roadmap","data":{"":"We've got big plans for Turbopack. Here's what we're aiming for in the future:","nextjs#Next.js":"Right now, Turbopack is being used as an opt-in feature in Next.js's dev server. This is helping to create an extremely fast experience in local development that scales to big projects.Next, we want to use Turbopack to power production builds with Next.js. We think that this will result in a big boost in performance, especially when integrated with remote caching.","svelte#Svelte":"We're planning to build a first-class integration with Svelte to let Turbopack power the next generation of SvelteKit applications.","other-frameworks#Other Frameworks":"We are in active discussions with other frameworks to bring Turbopack to their users. We're excited to see what we can build together!","remote-caching-and-replication#Remote Caching and Replication":"Turbopack is built from the ground up to take advantage of caching. Currently, this cache is stored in-memory only. This lets us optimize for our current use case - making the Next.js dev server fast.In the future, we plan to persist this cache to the file system, to speed up Turbopack between runs. This will work similarly to Turborepo's cache - but at a much more granular level. Turborepo can currently only cache the results of entire builds. Turbopack, however, can cache the results of individual functions within those builds - saving much more time over subsequent runs.Once persisting to the file system is working, we can build the next logical step: persisting to a remote cache. With Turborepo, we've already built remote caching on Vercel. In the future, you'll be able to share Turbopack's hyper-granular cache across your whole team, using the Vercel Remote Cache.","migration-for-webpack-users#Migration for Webpack users":"To learn more about our future plans for Webpack integration, check out our Migrating from Webpack page.","fusion-with-turborepo#Fusion with Turborepo":"We are currently migrating/rewriting Turborepo in Rust. In the future, Turborepo and Turbopack will merge into a single toolchain--Turbo--that can be used as either a bundler or a build system or both."}},"/pack/docs/why-turbopack":{"title":"Why Turbopack?","data":{"":"When we set out to create Turbopack, we wanted to solve a problem. We had been working on speed improvements for Next.js. We migrated away from several JS-based tools. Babel, gone. Terser, gone. Our next target was another JS-based tool, Webpack.Replacing it became our goal. But with what?A new generation of native-speed bundlers were emerging, like esbuild and swc. But after assessing the bundlers on the market, we decided to build our own. Why?","bundling-vs-native-esm#Bundling vs Native ESM":"Frameworks like Vite use a technique where they don’t bundle application source code in development mode. Instead, they rely on the browser’s native ES Modules system. This approach results in incredibly responsive updates since they only have to transform a single file.However, Vite can hit scaling issues with large applications made up of many modules. A flood of cascading network requests in the browser can lead to a relatively slow startup time. For the browser, it’s faster if it can receive the code it needs in as few network requests as possible - even on a local server.That’s why we decided that, like Webpack, we wanted Turbopack to bundle the code in the development server. Turbopack can do it much faster, especially for larger applications, because it is written in Rust and skips optimization work that is only necessary for production.","incremental-computation#Incremental Computation":"There are two ways to make a process faster: do less work or do work in parallel. We knew if we wanted to make the fastest bundler possible, we’d need to pull hard on both levers.We decided to create a reusable Turbo build engine for distributed and incremental behavior. The Turbo engine works like a scheduler for function calls, allowing calls to functions to be parallelized across all available cores.The Turbo engine also caches the result of all the functions it schedules, meaning it never needs to do the same work twice. Put simply, it does the minimum work at maximum speed.","vite-and-esbuild#Vite and esbuild":"Other tools take a different attitude to ‘doing less work’. Vite minimizes work done by using Native ESM in development mode. We decided not to take this approach for the reasons listed above.Under the hood, Vite uses esbuild for many tasks. esbuild is a bundler - a superbly fast one. It doesn’t force you to use native ESM. But we decided not to adopt esbuild for a few reasons.esbuild’s code is hyper-optimized for one task - bundling fast. It doesn’t have HMR, which we don’t want to lose from our dev server.esbuild is an extremely fast bundler, but it doesn’t do much caching. This means you will end up doing the same work again and again, even if that work is at the speed of native.Evan Wallace refers to esbuild as a proof-of-concept for the next generation of bundlers. We think he’s right. We feel that a Rust-powered bundler with incremental computation could perform better at a larger scale than esbuild.","lazy-bundling#Lazy bundling":"Early versions of Next.js tried to bundle the entire web app in development mode. We quickly realized that this ‘eager’ approach was less than optimal. Modern versions of Next.js bundle only the pages requested by the dev server. For instance, if you go to localhost:3000, it’ll bundle only pages/index.jsx, and the modules it imports.This more ‘lazy’ approach (only bundling assets when absolutely necessary) is key for a fast dev server. Native ESM handles this without much magic - you request a module, which requests other modules. However, we wanted to build a bundler, for the reasons explained above.esbuild doesn’t have a concept of ‘lazy’ bundling - it’s all-or-nothing, unless you specifically target only certain entry points.Turbopack’s development mode builds a minimal graph of your app’s imports and exports based on received requests and only bundles the minimal code necessary. Learn more in the core concepts docs.This strategy makes Turbopack extremely fast when first starting up the dev server. We compute only the code necessary to render the page, then ship it to the browser in a single chunk. At large scale, this ends up being significantly faster than Native ESM.","summary#Summary":"We wanted to:\nBuild a bundler. Bundlers outperform Native ESM when working on large applications.\nUse incremental computation. The Turbo engine brings this into the core of Turbopack’s architecture - maximizing speed and minimizing work done.\nOptimize our dev server’s startup time. For that, we build a lazy asset graph to compute only the assets requested.\n\nThat’s why we chose to build Turbopack."}},"/pack/docs/comparisons/turbopack-vs-vite":{"title":"Turbopack vs. Vite","data":{"":"Vite is a development environment that uses Native ESM to deliver a snappy dev server. Before we built Turbopack, we considered Vite as one of several options to speed up Next's dev server.However, we decided that Vite's Native ESM architecture brought too many speed bottlenecks. To learn more about that decision, check out our docs on why we created Turbopack.","speed#Speed":"Turbopack can outperform Vite on several key metrics.","dev-server-startup-time#Dev server startup time":"Turbopack's dev server starts up much faster than Vite. On a 1,000 module application, Vite takes  to start up. Turbopack starts up in  -  faster.In large applications, this differential stays consistent. In a 30,000 module application, Turbopack starts up  faster than Vite.","code-updates#Code updates":"When a file changes, it needs to render the change to the browser. The faster it can do that, the tighter your feedback loop and the faster you'll ship.In a 1,000 module application, Turbopack can react to file changes  faster than Vite."}},"/pack/docs/comparisons/turbopack-vs-webpack":{"title":"Turbopack vs. Webpack","data":{"":"We've built Turbopack as the successor of Webpack - the bundler that's at the heart of many beloved frameworks. Any successor to Webpack would need to be faster and just as flexible and extensible.","speed#Speed":"Turbopack's incremental architecture outstrips Webpack's speed on several key metrics:","dev-server-startup-time#Dev server startup time":"Turbopack's dev server starts up much faster than Webpack. Next.js 12, which uses Webpack under the hood, can start up a build server on a 1,000 module application in . Turbopack starts up in  -  faster.","code-updates#Code updates":"The most common action you'll perform on a dev server is changing files. When a file changes, it needs to render the change to the browser. The faster it can do that, the tighter your feedback loop and the faster you'll ship.In a 1,000 module application, Turbopack can react to file changes  faster than Webpack:","extensibility#Extensibility":"Webpack has an extraordinary collection of plugins to customize its behavior. Composing plugins lets you create custom toolchains which can support a huge variety of bundler features.In its alpha state, Turbopack cannot currently be configured with plugins. In the future, we plan to make Turbopack just as extensible as Webpack - though likely with an altered API."}},"/pack/docs/features/css":{"title":"CSS","data":{"":"CSS bundling is handled by SWC, using a Rust crate called swc_css. We haven't yet documented swc_css separately, but it's integrated into Turbopack and supports several CSS features:","global-css#Global CSS":"Importing CSS into global scope is supported out-of-the-box in Turbopack.\nimport './globals.css';","css-modules#CSS Modules":"Turbopack handles CSS Modules out-of-the-box. Any file with a .module.css extension will be considered a CSS module, and you can import it into a JavaScript or TypeScript file:\nimport cssExports from './phone.module.css'\nThis follows the same rules set out by Next.js - letting you easily distinguish between global and scoped CSS.","postcss-nested#postcss-nested":"Turbopack handles postcss-nested syntax out-of-the-box. This useful library lets you nest CSS declarations inside each other:\n.phone {\n&_title {\nwidth: 500px;\n@media (max-width: 500px) {\nwidth: auto;\n}\nbody.is_dark & {\ncolor: white;\n}\n}\nimg {\ndisplay: block;\n}\n}","import-syntax#@import syntax":"Using the CSS @import syntax to import other CSS files works out-of-the-box. This gives you the ability to combine several CSS files together into a single module:\n@import './modal.css';\n@import './dark.css';","postcss#PostCSS":"PostCSS gives you the ability to use plugins to enhance your CSS toolchain. It's been an invaluable tool for integrating libraries like Tailwind and autoprefixer into applications.The most common pattern is adding a postcss.config.js file to the root of your application, where you can import and configure your plugins.We don't currently offer the ability to use PostCSS plugins. We may end up adding these out-of-the-box, or make them available via a plugin.","workaround-for-postcss#Workaround for PostCSS":"As a workaround, we recommend running the PostCSS CLI in a sidecar process.\nnpm install --save-dev postcss postcss-cli concurrently\n\n{\n\"scripts\": {\n\"dev\": \"concurrently \\\"next dev --turbo\\\" \\\"postcss input.css --output output.css --watch\\\"\",\n\"build\": \"postcss input.css --output output.css && next build\"\n}\n}","scss-and-less#SCSS and LESS":".scss and .less files let you utilize SCSS and LESS - languages which enhance CSS in various ways. These languages don't currently work out-of-the-box with Turbopack.These are likely to be available via plugins in the future.","tailwind-css#Tailwind CSS":"We currently don't support Tailwind CSS out of the box. Since it can be used as a PostCSS plugin, we'll likely support it through the plugin system.It can be used today by using a sidecar process:\nnpm install --save-dev tailwindcss autoprefixer concurrently\n\n{\n\"scripts\": {\n\"dev\": \"concurrently \\\"next dev --turbo\\\" \\\"tailwindcss --input input.css --output output.css --watch\\\"\",\n\"build\": \"tailwindcss input.css --output output.css && next build\"\n}\n}"}},"/pack/docs/features/dev-server":{"title":"Dev Server","data":{"":"Turbopack is optimized to give you an extremely fast development server. We considered these features indispensable.","hmr#HMR":"Hot Module Replacement (HMR) gives your dev server the ability to push file updates to the browser without triggering a full refresh. This works for most static assets (including JavaScript files) enabling a smooth and fast developer experience.Turbopack supports Hot Module Replacement out of the box. Because of our incremental architecture, we are hyper-optimized for delivering fast updates.","fast-refresh#Fast Refresh":"Fast Refresh builds on top of HMR by providing a framework-level integration to preserve state across updates. Changes to a <Count /> component, for instance, would preserve the component's internal count across changes.Turbopack supports Fast Refresh out of the box for React. Support for other frameworks will be added over time."}},"/pack/docs/features/environment-variables":{"title":"Environment Variables","data":{"":"","env-files#.env files":"Turbopack will parse and inject .env files out of the box.\nNEXT_PUBLIC_DEPLOYMENT_NAME=\"my-site\"\nDATABASE_URL=\"postgres://\"\nThis includes all the variations these files come in:\n.env\n.env.local\n.env.development\n.env.production.local","live-reloading#Live reloading":"Not only that, but Turbopack will live reload when these values change. Restarting your dev server just to inject a new environment variable can be extremely annoying - Turbopack does it for you.","processenv#process.env":"Environment variables will be injected into process.env. For instance, DATABASE_URL will be on process.env.DATABASE_URL.This follows the tradition of Node.js, Webpack 5 and Next.js 12, which each use process.env for variable injection."}},"/pack/docs/features/frameworks":{"title":"Frameworks","data":{"":"Turbopack plans to offer first-class support for multiple frameworks. No matter whether you're using Svelte, React, Vue.js, or another framework, we want to provide a great experience on Turbopack.","react#React":"","jsxtsx#JSX/TSX":".jsx and .tsx files are supported out of the box with Turbopack. We use SWC to compile your JavaScript and TypeScript code, which results in extremely fast compilation.Similar to Next.js, Turbopack doesn't require you to import React in order to use JSX:\n- import React from 'react';\n\nconst Component = () => {\nreturn <div />\n}","react-server-components#React Server Components":"React Server Components let you declare certain components as 'server' components, allowing you to run backend code inside an async function. Next.js 13 brings first-class support for them.React Server Components impose unusual constraints on your bundler. The mix of client and server code means you need to ensure that server code does not get compiled to the client, and vice versa.Turbopack has been built from the ground up to solve these problems - it works with React Server Components out of the box.","next#Next":"Turbopack's Alpha version has been focused on providing a great experience for Next.js's dev server. We're using this as our initial goal to show what Turbopack can do. In the future, we want Turbopack to act as a low-level engine for other frameworks.This means that Turbopack plans to support everything in Next.js.","nextdynamic#next/dynamic":"next/dynamic is not yet supported - however, we plan to support it out of the box soon.","vue-and-svelte#Vue and Svelte":"VueJS and Svelte are tremendously popular frameworks which deliver a world-class developer experience.Since Turbopack is in alpha, we're focusing our support on Next.js's dev server. That means that right now, Vue and Svelte don't work out of the box.In future versions, we'll be supporting Vue and Svelte via plugins."}},"/pack/docs/features/imports":{"title":"Imports","data":{"":"Turbopack supports CJS and ESM imports out of the box, and offers partial support for AMD.Turbopack bundles your application, so imports won't be resolved to native browser ESM. You can learn why in our bundling vs Native ESM section.","commonjs#CommonJS":"Turbopack supports the require syntax out-of-the-box:\nconst { add } = require('./math');\n\nadd(1, 2);\nWe also support dynamic require() syntax, for if you want to import a dynamically named asset:\nconst imgName = getRandomImgName();\n\nconst img = require(`./images/${imgName}.png`);","esm#ESM":"Importing via the import syntax is also supported out-of-the-box. This includes static assets, and import type:\nimport img from './img.png';\n\nimport type { User } from '../server/types';\n\nimport { z } from 'zod';","dynamic-imports#Dynamic Imports":"Turbopack supports dynamic imports via import():\nconst getFeatureFlags = () => {\nreturn import('/featureFlags').then(mod => {\nreturn mod.featureFlags;\n})\n}"}},"/pack/docs/features/javascript":{"title":"JavaScript","data":{"":"","ecmascript-support#ECMAScript Support":"Turbopack uses SWC to bundle JavaScript and TypeScript files. So, we match SWC's support for ECMAScript versions - anything that SWC supports, Turbopack will support.This means that by default we support all syntax in ESNext.","browserslist#Browserslist":"Browserslist has become an industry standard for defining which browsers you plan to target. To make use of it, you can add a browserslist field to your package.json:\n{\n\"browserslist\": [\n\"last 1 version\",\n\"> 1%\",\n\"not dead\"\n]\n}\nTurbopack supports Browserslist out-of-the-box. We pass the information we find in your package.json to SWC, which handles browserslist support for us.This means you can feel comfortable using Turbopack to target legacy browsers, or deciding to only ship code to modern browsers.\nTurbopack is available in alpha preview with a dev server, which uses a pre-set minimal browserslist to minimize transformation during development. In a future release, Turbopack will build apps for production targeting your defined browserslist.","babel#Babel":"Babel allows you to add custom transformations to your code to provide custom syntax, including support for early language proposals.Babel plugins are currently not supported on Turbopack. In our default configuration, we don't use Babel to compile JavaScript or TypeScript code.In the future, Babel support will be provided via plugins."}},"/pack/docs/features/static-assets":{"title":"Static Assets","data":{"":"Part of bundling for the web is handling all the asset types the web supports - images, videos, JSON, fonts, and much more. Turbopack offers familiar tools for these so you can immediately get productive.","import-static-assets#Import static assets":"Importing static assets works out of the box with Turbopack:\nimport img from './img.png'\nimport video from './video.mp4'\nimport audio from './audio.wav'","nextjs#Next.js":"In Webpack and some other frameworks, importing an image returns a string containing that image's URL.\nimport img from './img.png';\n\nconsole.log(img); // /assets/static/1uahwd98h123.png\nIn Next.js, importing an image actually returns an object, containing various metadata about the image. This is so it can be fed into Next.js's Image component.The behavior of extracting an object of metadata from the image is not yet supported. For now, imported images will resolve to strings.","public-directory#Public directory":"The /public directory lets you place assets which you want to be available on the root URL of the website. For instance, public/favicon.png will be available at https://example/favicon.png.In Turbopack, the /public directory is supported out of the box.","json#JSON":"Most frameworks allow you to import JSON directly into your application:\nimport fixtures from './fixtures.json';\nThis is supported out of the box with Turbopack, as is performing a named import on that JSON:\nimport { users, posts } from './fixtures.json';"}},"/pack/docs/features/typescript":{"title":"TypeScript","data":{"":"Turbopack supports TypeScript out of the box. This means you can import .ts files with Turbopack. We support all of TypeScript's feature set.Thanks to our JSX support, you can also import .tsx files too.","resolving-paths-and-baseurl#Resolving paths and baseUrl":"In TypeScript, you can use the paths property of tsconfig.json to let you import files from custom paths.\n{\n\"compilerOptions\": {\n\"baseUrl\": \"src\",\n\"paths\": {\n\"app/*\": [\"app/*\"],\n\"config/*\": [\"app/_config/*\"],\n\"shared/*\": [\"app/_shared/*\"],\n},\n}\nThis would let you import directly from app/* without needing to do a relative import:\n- import { add } from '../../../../../math';\n+ import { add } from 'app/math';\n\nadd();\nTurbopack reads the paths and baseUrl in tsconfig.json in order to resolve these paths, just like Next.js does.This means you only need to configure your absolute paths in one place.","type-checking#Type Checking":"Turbopack does not perform type checks on your application. We use SWC to compile TypeScript code, which also does not perform type checks.This means that in order to run your type checks, you'll need a sidecar process running tsc --watch. Or, you can rely on your IDE's TypeScript integration."}},"/repo":{"data":{"":""}},"/repo/docs/acknowledgements":{"title":"致谢","data":{"":"Turborepo was originally created by Jared Palmer as a closed-source enterprise software offering. In late 2021, Vercel acquired Turborepo and open sourced the codebase.Today, Turborepo has dedicated full-time team working on it as well as a growing list of open source contributors.","inspiration--prior-art#Inspiration / Prior Art":"At Vercel, we believe deeply in the open source movement and in the power of open collaboration. To that end, it's important to provide meaningful attribution to the projects and people that inspire(d) us and our work.We'd like to make a special shoutout to other build systems, monorepo tools, and prior art:\nBazel - https://bazel.build\nBuck - https://buck.build\nPlease - https://please.build\nPants - https://www.pantsbuild.org\nScoot - https://github.com/twitter/scoot\nTSDX - https://tsdx.io\nLerna - https://lerna.js.org\nLage - https://microsoft.github.io/lage\nBackfill - https://github.com/microsoft/backfill\nBolt - https://github.com/boltpkg/bolt\nRush - https://rushjs.io\nPreconstruct - https://preconstruct.tools\nNx - https://nx.dev\nYarn - https://yarnpkg.com\nnpm - https://www.npmjs.com\npnpm - https://pnpm.js.org\n\nThroughout the documentation, wherever applicable, we also provide inline callouts and links to the projects and people that have inspired us.","additional-thanks#Additional Thanks":"Additionally, we're grateful to:\nRick Button for donating the turbo package name on npm\nIheanyi Ekechukwu for helping Jared pick up Golang during the Pandemic!\nKenneth Chau for Lage's Scope and Pipeline API and docs\nMiguel Oller and MakeSwift.com for piloting Turborepo\nEric Koslow, Jack Hanford, and Lattice.com for piloting Turborepo"}},"/repo/docs/ci":{"title":"CI Recipes","data":{"":"Turborepo not only speeds up builds, but also your CI pipeline. Below are a few ways to use Turborepo with various Continuous Integration providers.\nCircleCI\nGitHub Actions\nGitLab CI\nTravis CI"}},"/repo/docs/faq":{"title":"FAQ","data":{"":"","do-i-have-to-use-remote-caching-to-use-turborepo#Do I have to use Remote Caching to use Turborepo?":"No. Remote Caching is optional. However, you'll find it very useful to speed up development on a team, speed up builds inside of Docker, and also save space on your own machine.","does-turborepo--remote-caching-store-my-source-code#Does Turborepo / Remote Caching store my source code?":"No. Turborepo does not store source code. Without Remote Caching, no code ever leaves your machine—it will only cache artifacts to local disk.With Turborepo's Remote Caching, you are responsible for configuring cache behavior and should only set up Turborepo to cache compiled artifacts. Please be aware that Turborepo treats all logs as artifacts and so these will be stored along with other cache artifacts.","do-i-have-to-use-vercel-to-use-turborepo#Do I have to use Vercel to use Turborepo?":"No. Turborepo is an open-source project and is not tied to any specific hosting provider or Remote Cache provider. The default Remote Cache provider is Vercel, should you opt-in to enable it. However, you can use any other provider you like if they support the same API. Several open-source community Remote Caches are compatible with Turborepo.","can-i-use-turborepo-with-a-different-remote-cache-provider-other-than-vercel#Can I use Turborepo with a different Remote Cache provider other than Vercel?":"Yes. As long as the Remote Cache provider you choose supports the same API, you can use Turborepo with it.","does-turborepo-collect-any-personally-identifiable-information#Does Turborepo collect any personally identifiable information?":"Due to the nature of Turborepo's functionality, no personal information is gathered when the open source binary is run locally. All cached artifacts are stored on your machine by default. Further, no log in information or contact details are collected by the turbo CLI, so Turborepo will never have access to any personally identifiable information. Thus, for any data privacy questions and concerns please refer to Turborepo's Privacy Policy.","does-turborepo-collect-any-personally-identifiable-information-when-using-remote-caching#Does Turborepo collect any personally identifiable information when using Remote Caching?":"When Remote Caching is enabled, by default Turborepo will utilize your Vercel account to cache artifacts in the cloud. Thus, for any data privacy questions and concerns, please refer to Turborepo's Privacy Policy and Vercel's Privacy Policy. If you use a different Remote Cache provider, please refer to the provider's privacy policy.","how-can-i-retain-fast-refresh-in-my-turborepo-when-using-multiple-nextjs-applications#How can I retain Fast Refresh in my Turborepo when using multiple Next.js applications?":"Fast Refresh gives you instantaneous feedback on edits made to your React components in Next.js applications. If your Turborepo has multiple Next.js applications, you can use next-transpile-modules to ensure that imports across workspaces will work with Fast Refresh when changes are made. Turborepo will effectively watch for any edits and the rebuild when saving. You can get started from this example which is set up to handle Fast Refresh."}},"/repo/docs/handbook":{"title":"Monorepo 手册","data":{"":"Now we've covered the core concepts, it's time to get practical. This handbook covers everything you need to know to set up and use your monorepo.","fundamentals#Fundamentals":"Learn about the fundamental building blocks of monorepos - workspaces, packages and dependencies.","tasks#Tasks":"Configure common tasks in your monorepo, like linting, testing, and building your apps and packages."}},"/repo/docs":{"title":"快速开始","data":{"":"Turborepo 是一个智能的 构建系统，针对 JavaScript 和 TypeScript 的项目进行了优化。你的项目任务，比如 lint，build 和 test 运行得还不够快， Turborepo 利用 缓存 来加速你得本地环境和 CI 环境。Turborepo 被设计成 渐进式，因此你可以在几分钟内将其添加到你的大多数项目中。","特性#特性":"Turborepo 利用先进的构建系统技术来加速开发，在您的本地机器和您的 CI/CD 上。","monorepos#Monorepos":"Turborepo 可与 npm、pnpm 和 yarn 等包管理工具一起使用。 如果你曾经觉得你的 monorepo 让你慢了下来，那么可能是时候使用 Turborepo 了。","示例#示例":"你还可以通过克隆 Turborepo 的入门示例代码以便快速开始您的 monorepo 项目， 更多的示例和入门教程，可以查看 GitHub 上的 Turborepo 示例文件夹下的示例."}},"/repo/docs/troubleshooting":{"title":"故障排除","data":{"":"This guide aims to help you debug issues with your Turborepo builds and configuration.","my-dependency-isnt-being-built-correctly#My dependency isn't being built correctly":"Are you properly bundling and transpiling the dependency before building the application?\nFor example, libraries like tsc, tsup, esbuild, babel, and swc will convert newer JavaScript features back to “pure” JavaScript.\nIf you are using Next.js, you might be using next-transpile-modules. Ensure you add the name of the dependency inside next.config.js (example).\n\n\nHave you listed files in the dependency's package.json to point to the correct files?","my-types-are-not-being-found#My types are not being found":"Did you specify types or typing inside the dependency's package.json to point to the .d.ts file?\nHave you altered or set custom tsconfig.json paths?\nDo they have the correct folder structure for your application?\nAre they properly configured for the meta framework, bundler, or transpilation tool?","im-not-seeing-any-cache-hits#I'm not seeing any cache hits":"Is any source code being generated during the build that isn't checked into git?\nThis would change the fingerprint Turborepo uses to store build outputs.\n\n\nAre cache outputs correctly specified in your Turborepo pipeline?\nPipeline settings are not inherited or merged, so they need to be re-specified in workspace-specific tasks (e.g. web#build does not inherit pipeline settings from build).\n\n\nAre relevant inlined environment variables accounted for?\nTo verify, run turbo in verbose mode by adding -vvv to turbo run <task> and look at which environment variables are included in the hashes.","im-seeing-cache-hits-but-my-build-is-broken#I'm seeing cache hits, but my build is broken":"Are cache outputs properly specified in your Turborepo pipeline?\nPipeline settings are not inherited or merged, so they need to be re-specified in workspace-specific tasks (e.g. web#build does not inherit pipeline settings from build).","my-build-is-caching-the-wrong-environment-variables#My build is caching the wrong environment variables":"Are relevant inlined environment variables accounted for?\nTo verify, run turbo in verbose mode by adding -vvv to turbo run <task> and look at which environment variables are included in the hashes."}},"/repo/docs/upgrading-to-v1":{"title":"升级到 v1","data":{"":"Turborepo has been acquired by Vercel! With this announcement, Vercel is open sourcing the turbo CLI and offering Remote Caching for free on all accounts during the transition period.Existing Turborepo customers should upgrade their turbo CLI to v1.x as soon as possible and migrate to Vercel (instructions below). Earlier versions of turbo CLI prior to 1.x will no longer be maintained going forward. New account creation on beta.turborepo.com has been disabled. The beta.turborepo.com dashboard and remote caching service will be shutdown on January 15th, 2022 and older versions will not be installable.All existing Remote Cache artifacts will also be deleted at this time.Below is a step-by-step migration guide for existing Turborepo users. If you get stuck, please reach out in the community Discord or file an issue on GitHub. Thank you again for your continued support as we begin this awesome new chapter of Turborepo together.","1-cleaning-up#1. Cleaning up":"For good hygiene, ensure you logout of turbo to remove old credentials:\nyarn turbo logout\nIf it exists, also delete the .turbo directory from the root of your monorepo:\nrm -rf .turbo","2-install-the-latest-release-of-turbo#2. Install the latest release of turbo":"Install the latest version version of turbo:\nyarn add turbo --save-dev --ignore-workspace-root-check","3-setup-remote-caching#3. Setup Remote Caching":"As mentioned, Turborepo now provides zero-config Remote Caching through Vercel. Remote Caching is free for all Vercel plans during this transition period. Each Vercel account has a shared Remote Cache. This cache is shared across all environments (Development, Preview, and Production).Important: turborepo.com allowed multiple caches (i.e. projects) per team (denoted through --project flag). With v1.x caching on Vercel, each Vercel account (user or team) has a single shared Remote Cache. If you were actively using multiple turborepo.com projects for your team, please let us know in Discord.Please note that we are not migrating cache artifacts to Vercel. We apologize for the slower builds during your migration as you rehydrate your remote cache on Vercel or custom cache infra.","4-local-development#4. Local Development":"If you were using Remote Caching for local development, upgrading will take a minute or two. To get started, login to the Vercel CLI:\nnpx turbo login\nNow we can set up Remote Caching through Vercel by running:\nnpx turbo link\nFollow the prompts and select the Vercel account (user or team) to wish to connect to.","on-vercel#On Vercel":"If you already used Turborepo and Vercel together, remove TURBO_TOKEN, TURBO_TEAM, and TURBO_PROJECT environment variables from all projects. These are now automatically set on your behalf by Vercel.\nRemove the usage of --team, --token, and --project CLI flags in your Vercel project settings and/or package.json scripts.","on-other-cicd#On other CI/CD":"Replace your turborepo.com personal access token with a new Vercel personal access token and update TURBO_TOKEN environment variable or equivalent usage of the --token CLI flag.\nRemove the TURBO_PROJECT environment variable and remove all usage of the --project CLI flag. This has been deprecated.\nUpdate the value of the TURBO_TEAM environment variable and --team CLI flag to be your Vercel account slug (i.e. https://vercel.com/<slug>).","getting-help#Getting Help":"If you are having difficulty upgrading please file an issue on GitHub. If you are having difficulty with your remote caching on Vercel, please reach out in Discord."}},"/repo/docs/ci/circleci":{"title":"CircleCI","data":{"":"The following example shows how to use Turborepo with CircleCI.For a given root package.json:\n{\n\"name\": \"my-turborepo\",\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\"\n},\n\"devDependencies\": {\n\"turbo\": \"1.2.5\"\n}\n}\nAnd a turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n}\n}\nCreate a file called .circleci/config.yml in your repository with the following contents:\n\n\nversion: 2.1\norbs:\nnode: circleci/node@5.0.2\nworkflows:\ntest:\njobs:\n- test\njobs:\ntest:\ndocker:\n- image: cimg/node:lts\nsteps:\n- checkout\n- node/install-packages\n- run:\ncommand: npm run build\n- run:\ncommand: npm run test\n\n\n\nversion: 2.1\norbs:\nnode: circleci/node@5.0.2\nworkflows:\ntest:\njobs:\n- test\njobs:\ntest:\ndocker:\n- image: cimg/node:lts\nsteps:\n- checkout\n- node/install-packages:\npkg-manager: yarn\n- run:\ncommand: yarn build\n- run:\ncommand: yarn test\n\n\n\nversion: 2.1\norbs:\nnode: circleci/node@5.0.2\nworkflows:\ntest:\njobs:\n- test\njobs:\ntest:\ndocker:\n- image: cimg/node:lts\nsteps:\n- checkout\n- node/install-packages:\n- run:\ncommand: npm i -g pnpm\n- run:\ncommand: pnpm build\n- run:\ncommand: pnpm test","remote-caching#Remote Caching":"To use Remote Caching with CircleCI, add the following environment variables to your CircleCI project\nto make them available to your turbo commands.\nTURBO_TOKEN - The Bearer token to access the Remote Cache\nTURBO_TEAM - The account to which the monorepo belongs\n\nTo use Vercel Remote Caching, you can get the value of these variables in a few steps:\nCreate a Scoped Access Token to your account in the Vercel Dashboard\n\n\n\n\n\n\nCopy the value to a safe place. You'll need it in a moment.\nGo to your CircleCI project settings and click on the Environment Variables tab. Create a new secret called TURBO_TOKEN and enter the value of your Scoped Access Token.\n\n\n\n\n\n\n\nMake a second secret called TURBO_TEAM and enter the value of your team's Vercel URL without the vercel.com/. Your Team URL can be found inside your team's general project settings from the dashboard.If you're using a Hobby Plan, you can use your username. Your username can be found in your Vercel Personal Account Settings\n\n\n\n\nCircleCI automatically loads environment variables stored in project settings into the CI environment. No modifications are necessary for the CI file."}},"/repo/docs/ci/github-actions":{"title":"GitHub Actions","data":{"":"The following example shows how to use Turborepo with GitHub Actions.For a given root package.json:\n{\n\"name\": \"my-turborepo\",\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\"\n},\n\"devDependencies\": {\n\"turbo\": \"1.2.5\"\n}\n}\nAnd a turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n}\n}\n}\nCreate file called .github/workflows/ci.yml in your repository with the following contents:\n\n\nname: CI\n\non:\npush:\nbranches: [\"main\"]\npull_request:\ntypes: [opened, synchronize]\n\njobs:\nbuild:\nname: Build and Test\ntimeout-minutes: 15\nruns-on: ubuntu-latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# env:\n#  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}\n#  TURBO_TEAM: ${{ secrets.TURBO_TEAM }}\n#  TURBO_REMOTE_ONLY: true\n\nsteps:\n- name: Check out code\nuses: actions/checkout@v3\nwith:\nfetch-depth: 2\n\n- name: Setup Node.js environment\nuses: actions/setup-node@v3\nwith:\nnode-version: 16\ncache: 'npm'\n\n- name: Install dependencies\nrun: npm install\n\n- name: Build\nrun: npm run build\n\n- name: Test\nrun: npm run test\n\n\n\nname: CI\n\non:\npush:\nbranches: [\"main\"]\npull_request:\ntypes: [opened, synchronize]\n\njobs:\nbuild:\nname: Build and Test\ntimeout-minutes: 15\nruns-on: ubuntu-latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# env:\n#  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}\n#  TURBO_TEAM: ${{ secrets.TURBO_TEAM }}\n\nsteps:\n- name: Check out code\nuses: actions/checkout@v3\nwith:\nfetch-depth: 2\n\n- name: Setup Node.js environment\nuses: actions/setup-node@v3\nwith:\nnode-version: 16\ncache: 'yarn'\n\n- name: Install dependencies\nrun: yarn\n\n- name: Build\nrun: yarn build\n\n- name: Test\nrun: yarn test\n\n\n\nname: CI\n\non:\npush:\nbranches: [\"main\"]\npull_request:\ntypes: [opened, synchronize]\n\njobs:\nbuild:\nname: Build and Test\ntimeout-minutes: 15\nruns-on: ubuntu-latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# env:\n#  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}\n#  TURBO_TEAM: ${{ secrets.TURBO_TEAM }}\n\nsteps:\n- name: Check out code\nuses: actions/checkout@v3\nwith:\nfetch-depth: 2\n\n- uses: pnpm/action-setup@v2.0.1\nwith:\nversion: 6.32.2\n\n- name: Setup Node.js environment\nuses: actions/setup-node@v3\nwith:\nnode-version: 16\ncache: 'pnpm'\n\n- name: Install dependencies\nrun: pnpm install\n\n- name: Build\nrun: pnpm build\n\n- name: Test\nrun: pnpm test","remote-caching#Remote Caching":"To use Remote Caching with GitHub Actions, add the following environment variables to your GitHub Actions workflow\nto make them available to your turbo commands.\nTURBO_TOKEN - The Bearer token to access the Remote Cache\nTURBO_TEAM - The account to which the monorepo belongs\n\nTo use Vercel Remote Caching, you can get the value of these variables in a few steps:\nCreate a Scoped Access Token to your account in the Vercel Dashboard\n\n\n\n\n\n\nCopy the value to a safe place. You'll need it in a moment.\nGo to your GitHub repository settings and click on the Secrets and then Actions tab. Create a new secret called TURBO_TOKEN and enter the value of your Scoped Access Token.\n\n\n\n\n\n\n\nMake a second secret called TURBO_TEAM and enter the value of your team's Vercel URL without the vercel.com/. Your Team URL can be found inside your team's general project settings from the dashboard.If you're using a Hobby Plan, you can use your username. Your username can be found in your Vercel Personal Account Settings\n\n\n\n\nAt the top of your GitHub Actions workflow, provide the following environment variables to jobs that use turbo:\n\n\n# ...\n\njobs:\nbuild:\nname: Build and Test\ntimeout-minutes: 15\nruns-on: ubuntu-latest\n# To use Turborepo Remote Caching, set the following environment variables for the job.\nenv:\nTURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}\nTURBO_TEAM: ${{ secrets.TURBO_TEAM }}\n\nsteps:\n- name: Check out code\nuses: actions/checkout@v2\nwith:\nfetch-depth: 2\n# ..."}},"/repo/docs/ci/gitlabci":{"title":"GitLab CI","data":{"":"The following example shows how to use Turborepo with GitLab CI.For a given root package.json:\n{\n\"name\": \"my-turborepo\",\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\"\n},\n\"devDependencies\": {\n\"turbo\": \"1.2.5\"\n}\n}\nAnd a turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n}\n}\nCreate a file called .gitlab-ci.yml in your repository with the following contents:\n\n\nimage: node:latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# variables:\n#   TURBO_TOKEN: $TURBO_TOKEN\n#   TURBO_TEAM: $TURBO_TEAM\nstages:\n- build\nbuild:\nstage: build\nscript:\n- npm install\n- npm run build\n- npm run test\n\n\n\nimage: node:latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# variables:\n#   TURBO_TOKEN: $TURBO_TOKEN\n#   TURBO_TEAM: $TURBO_TEAM\nstages:\n- build\nbuild:\nstage: build\nscript:\n- yarn install\n- yarn build\n- yarn test\ncache:\npaths:\n- node_modules/\n- .yarn\n\n\n\nimage: node:latest\n# To use Remote Caching, uncomment the next lines and follow the steps below.\n# variables:\n#   TURBO_TOKEN: $TURBO_TOKEN\n#   TURBO_TEAM: $TURBO_TEAM\nstages:\n- build\nbuild:\nstage: build\nbefore_script:\n- curl -f https://get.pnpm.io/v6.16.js | node - add --global pnpm@6.32.2\n- pnpm config set store-dir .pnpm-store\nscript:\n- pnpm install\n- pnpm build\n- pnpm test\ncache:\nkey: \"$CI_COMMIT_REF_SLUG\"\npaths:\n- .pnpm-store\n\nFor more information visit the pnpm documentation section on GitLab CI integration, view it here","remote-caching#Remote Caching":"To use Remote Caching with GitLab CI, add the following environment variables to your GitLab CI project.\nTURBO_TOKEN - The Bearer token to access the Remote Cache\nTURBO_TEAM - The account to which the monorepo belongs\n\nTo use Vercel Remote Caching, you can get the value of these variables in a few steps:\nCreate a Scoped Access Token to your account in the Vercel Dashboard\n\n\n\n\n\n\nCopy the value to a safe place. You'll need it in a moment.\nGo to your GitLab repository settings and click on the Settings and then CI/CD tab. Create a new variable called TURBO_TOKEN and enter the value of your Scoped Access Token.\n\n\n\n\n\n\n\nMake a second secret called TURBO_TEAM and enter the value of your team's Vercel URL without the vercel.com/. Your Team URL can be found inside your team's general project settings from the dashboard.If you're using a Hobby Plan, you can use your username. Your username can be found in your Vercel Personal Account Settings"}},"/repo/docs/ci/travisci":{"title":"Travis CI","data":{"":"The following example shows how to use Turborepo with Travis CI.For a given root package.json:\n{\n\"name\": \"my-turborepo\",\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\"\n},\n\"devDependencies\": {\n\"turbo\": \"1.2.5\"\n}\n}\nAnd a turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n}\n}\nCreate a file called .travis.yml in your repository with the following contents:\n\n\nlanguage: node_js\nnode_js:\n- lts/*\ninstall:\n- npm install\nscript:\n- npm run build\nscript:\n- npm run test\n\n\nTravis CI detects the use of Yarn by the presence of yarn.lock. It will automatically ensure it is installed.\nlanguage: node_js\nnode_js:\n- lts/*\ninstall:\n- yarn\nscript:\n- yarn build\nscript:\n- yarn test\n\n\n\nlanguage: node_js\nnode_js:\n- lts/*\ncache:\nnpm: false\ndirectories:\n- \"~/.pnpm-store\"\nbefore_install:\n- curl -f https://get.pnpm.io/v6.16.js | node - add --global pnpm@6.32.2\n- pnpm config set store-dir ~/.pnpm-store\ninstall:\n- pnpm install\nscript:\n- pnpm build\nscript:\n- pnpm test\n\nFor more information visit the pnpm documentation section on Travis CI integration, view it here","remote-caching#Remote Caching":"To use Remote Caching with Travis CI, add the following environment variables to your Travis CI project.\nTURBO_TOKEN - The Bearer token to access the Remote Cache\nTURBO_TEAM - The account to which the monorepo belongs\n\nTo use Vercel Remote Caching, you can get the value of these variables in a few steps:\nCreate a Scoped Access Token to your account in the Vercel Dashboard\n\n\n\n\n\n\nCopy the value to a safe place. You'll need it in a moment.\nGo to your Travis repository settings and scroll down to the Environment Variables section. Create a new variable called TURBO_TOKEN and enter the value of your Scoped Access Token.\n\n\n\n\nMake a second secret called TURBO_TEAM and enter the value of your team's Vercel URL without the vercel.com/. Your Team URL can be found inside your team's general project settings from the dashboard.If you're using a Hobby Plan, you can use your username. Your username can be found in your Vercel Personal Account Settings\n\n\n\n\nTravis CI automatically loads environment variables stored in project settings into the CI environment. No modifications are necessary for the CI file."}},"/repo/docs/core-concepts/caching":{"title":"Caching Tasks","data":{"":"Every JavaScript or TypeScript codebase will need to run package.json scripts, like build, test and lint. In Turborepo, we call these tasks.Turborepo can cache the results and logs of your tasks - leading to enormous speedups for slow tasks.","missing-the-cache#Missing the cache":"Each task in your codebase has inputs and outputs.\nA build task might have source files as inputs and outputs logs to stderr and stdout as well as bundled files.\nA lint or test task might have source files as inputs and outputs logs to stdout and stderr.\n\nLet's say you run a build task with Turborepo using turbo run build:\n\n\nTurborepo will evaluate the inputs to your task (by default all non-gitignored files in the workspace folder) and turn them into a hash (e.g. 78awdk123).\nCheck the local filesystem cache for a folder named with the hash (e.g../node_modules/.cache/turbo/78awdk123).\nIf Turborepo doesn't find any matching artifacts for the calculated hash, Turborepo will then execute the task.\nOnce the task is over, Turborepo saves all the outputs (including files and logs) into its cache under the hash.\n\n\nTurborepo takes a lot of information into account when creating the hash -\nsource files, environment variables, and even the source files of dependent\nworkspaces. Learn more below.","hitting-the-cache#Hitting the cache":"Let's say that you run the task again without changing any of its inputs:\n\n\nThe hash will be the same because the inputs haven't changed (e.g. 78awdk123)\nTurborepo will find the folder in its cache with the calculated hash (e.g. ./node_modules/.cache/turbo/78awdk123)\nInstead of running the task, Turborepo will replay the output - printing the saved logs to stdout and restoring the saved output files to their respective position in the filesystem.\n\nRestoring files and logs from the cache happens near-instantaneously. This can take your build times from minutes or hours down to seconds or milliseconds. Although specific results will vary depending on the shape and granularity of your codebase's dependency graph, most teams find that they can cut their overall monthly build time by around 40-85% with Turborepo's caching.","configuring-cache-outputs#Configuring Cache Outputs":"Using pipeline, you can configure cache conventions across your Turborepo.To override the default cache output behavior, pass an array of globs to a pipeline.<task>.outputs array. Any file that satisfies the glob patterns for a task will be treated as artifact.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\", \".next/**\"],\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [], // leave empty to only cache logs\n\"dependsOn\": [\"build\"]\n}\n}\n}\nIf your task does not emit any files (e.g. unit tests with Jest), set outputs to an empty array (i.e. []), and Turborepo will cache the logs for you.When you run turbo run build test, Turborepo will execute your build and test scripts,\nand cache their outputs in ./node_modules/.cache/turbo.\nPro Tip for caching ESLint: You can get a cacheable pretty terminal output\n(even for non-errors) by setting TIMING=1 variable before eslint. Learn\nmore over in the ESLint\ndocs.","configuring-cache-inputs#Configuring Cache Inputs":"A workspace is considered to have been updated when any of the files in that workspace have changed.\nHowever, for some tasks, we only want to rerun that task when relevant files have changed.\nSpecifying inputs lets us define which files are relevant for a particular task. For example, the\ntest configuration below declares that the test task only needs to execute if a .tsx or .ts file\nin the src/ and test/ subdirectories has changed since the last execution.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ... omitted for brevity\n\n\"test\": {\n// A workspace's `test` task depends on that workspace's\n// own `build` task being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [],\n// A workspace's `test` task should only be rerun when\n// either a `.tsx` or `.ts` file has changed.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\"]\n}\n}\n}","turn-off-caching#Turn off caching":"Sometimes you really don't need or want this cache behavior (e.g. when you're using next dev or react-scripts start for live reloading). To entirely disable caching, append --no-cache to any command:\n# Run `dev` npm script in all workspaces in parallel,\n# but don't cache the output\nturbo run dev --parallel --no-cache\nYou can also disable caching on specific tasks by setting the pipeline.<task>.cache configuration to false:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}","alter-caching-based-on-file-changes#Alter Caching Based on File Changes":"For some tasks, you may not want a cache miss if an irrelevant file has changed. For instance, updating README.md\nmight not need to trigger a cache miss for the test task. You can use inputs to restrict the set\nof files turbo considers for a particular task. In this case, only consider .ts and .tsx files relevant for\ndetermining a cache hit on the test task:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ...other tasks\n\"test\": {\n\"outputs\": [], // leave empty to only cache logs\n\"dependsOn\": [\"build\"],\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\"]\n}\n}\n}\n\npackage.json is always considered an input for tasks in the workspace it\nlives in. This is because the definition of the task itself lives in\npackage.json in the scripts key. If you change that, any cached output is\nconsidered invalid.\nIf you want all tasks to depend on certain files, you can declare this dependency in the\nglobalDependencies array.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n+  \"globalDependencies\": [\".env\"],\n\"pipeline\": {\n// ...other tasks\n\"test\": {\n\"outputs\": [], // leave empty to only cache logs\n\"dependsOn\": [\"build\"],\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\"]\n}\n}\n}\n\nturbo.json is always considered a global dependency. If you modify\nturbo.json, all caches are invalidated.","altering-caching-based-on-environment-variables#Altering Caching Based on Environment Variables":"When you use turbo with tools that inline environment variables at build time\n(e.g. Next.js or Create React App), it is important to tell turbo about it.\nOtherwise, you could ship a cached build with the wrong environment variables!You can control turbo's caching behavior based on\nthe values of environment variables:\nIncluding environment variables in the env key in your pipeline definition will impact the cache fingerprint on a per-task or per-workspace-task basis.\nThe value of any environment variable that includes THASH in its name will impact the cache fingerprint of all tasks.\n\n\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n// env vars will impact hashes of all \"build\" tasks\n\"env\": [\"SOME_ENV_VAR\"],\n\"outputs\": [\"dist/**\"]\n},\n\n// override settings for the \"build\" task for the \"web\" app\n\"web#build\": {\n\"dependsOn\": [\"^build\"],\n\"env\": [\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"STRIPE_SECRET_KEY\",\n\"NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"NEXT_PUBLIC_ANALYTICS_ID\"\n],\n\"outputs\": [\".next/**\"]\n}\n}\n}\n\nDeclaring environment variables in the dependsOn config with a $ prefix is\ndeprecated.\nTo alter the cache for all tasks, you can declare environment variables in the\nglobalEnv array:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n// env vars will impact hashes of all \"build\" tasks\n\"env\": [\"SOME_ENV_VAR\"],\n\"outputs\": [\"dist/**\"]\n},\n\n// override settings for the \"build\" task for the \"web\" app\n\"web#build\": {\n\"dependsOn\": [\"^build\"],\n\"env\": [\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"STRIPE_SECRET_KEY\",\n\"NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"NEXT_PUBLIC_ANALYTICS_ID\"\n],\n\"outputs\": [\".next/**\"],\n},\n},\n+  \"globalEnv\": [\n+    \"GITHUB_TOKEN\" // env var that will impact the hashes of all tasks,\n+  ]\n}","automatic-environment-variable-inclusion#Automatic environment variable inclusion":"To help ensure correct caching across environments, Turborepo automatically infers and includes public environment variables when calculating cache keys for apps built with detected frameworks. You can safely omit framework-specific public environment variables from turbo.json:\n{\n\"pipeline\": {\n\"build\": {\n\"env\": [\n-       \"NEXT_PUBLIC_EXAMPLE_ENV_VAR\"\n]\n}\n}\n}\nNote that this automatic detection and inclusion only works if Turborepo successfully infers the framework your apps are built with. The supported frameworks and the environment variables that Turborepo will detect and include in the cache keys:\nAstro: PUBLIC_*\nBlitz: NEXT_PUBLIC_*\nCreate React App: REACT_APP_*\nGatsby: GATSBY_*\nNext.js: NEXT_PUBLIC_*\nNuxt.js: NUXT_ENV_*\nRedwoodJS: REDWOOD_ENV_*\nSanity Studio: SANITY_STUDIO_*\nSolid: VITE_*\nSvelteKit: VITE_*\nVite: VITE_*\nVue: VUE_APP_*\n\n\nThere are some exceptions to the list above. For various reasons, CI systems (including Vercel)\nset environment variables that start with these prefixes even though they aren't part of your build\noutput. These can change unpredictably — even on every build! — invalidating Turborepo's\ncache. To workaround this, Turborepo uses a TURBO_CI_VENDOR_ENV_KEY variable to\nexclude environment variables from Turborepo's inference.For example, Vercel sets the NEXT_PUBLIC_VERCEL_GIT_COMMIT_SHA. This value changes on every build,\nso Vercel also sets TURBO_CI_VENDOR_ENV_KEY=\"NEXT_PUBLIC_VERCEL_\" to exclude these variables.Luckily, you only need to be aware of this on other build systems; you don't need to worry\nabout these edge cases when using Turborepo on Vercel.","a-note-on-monorepos#A note on monorepos":"The environment variables will only be included in the cache key for tasks in workspaces where that framework is used. In other words, environment variables inferred for Next.js apps will only be included in the cache key for workspaces detected as Next.js apps. Tasks in other workspaces in the monorepo will not be impacted.For example, consider a monorepo with three workspaces: a Next.js project, a Create React App project, and a TypeScript package. Each has a build script, and both apps depend on the TypeScript project. Let's say that this Turborepo has a standard turbo.json pipeline that builds them all in order:\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n}\n}\n}\nAs of 1.4, when you run turbo run build, Turborepo will not consider any build time environment variables relevant when building the TypeScript package. However, when building the Next.js app, Turborepo will infer that environment variables starting with NEXT_PUBLIC_ could alter the output of the .next folder and should thus be included when calculating the hash. Similarly, when calculating the hash of the Create React App's build script, all build time environment variables starting with REACT_APP_PUBLIC_ will be included.","eslint-config-turbo#eslint-config-turbo":"To further assist in detecting unseen dependencies creeping into your builds, and to help ensure that your Turborepo cache is correctly shared across every environment, use the eslint-config-turbo package. While automatic environment variable inclusion should cover most situations with most frameworks, this ESLint config will provide just-in-time feedback for teams using other build time inlined environment variables. This will also help support teams using in-house frameworks that we cannot detect automatically.To get started, extend from eslint-config-turbo in your root eslintrc file:\n{\n// Automatically flag env vars missing from turbo.json\n\"extends\": [\"turbo\"]\n}\nFor more control over the rules, you can install and configure the eslint-plugin-turbo plugin directly by first adding it to plugins and then configuring the desired rules:\n{\n\"plugins\": [\"turbo\"],\n\"rules\": {\n// Automatically flag env vars missing from turbo.json\n\"turbo/no-undeclared-env-vars\": \"error\"\n}\n}\nThe plugin will warn you if you are using non-framework-related environment variables in your code that have not been declared in your turbo.json.","invisible-environment-variables#Invisible Environment Variables":"Since Turborepo runs before your tasks, it is possible for your tasks to create or mutate environment variables after turbo has already calculated the hash for a particular task. For example, consider this package.json:\n{\n\"scripts\": {\n\"build\": \"NEXT_PUBLIC_GA_ID=UA-00000000-0 next build\",\n\"test\": \"node -r dotenv/config test.js\"\n}\n}\nturbo, having calculated a task hash prior to invoking the build script, will be unable to discover the NEXT_PUBLIC_GA_ID=UA-00000000-0 environment variable and thus unable to partition the cache based upon that, or any environment variable configured by dotenv.Be careful to ensure that all of your environment variables are configured prior to invoking turbo!","force-overwrite-cache#Force overwrite cache":"Conversely, if you want to force turbo to re-execute a previously cached task, add the --force flag:\n# Run `build` npm script in all workspaces,\n# ignoring cache hits.\nturbo run build --force","logs#Logs":"Not only does turbo cache the output of your tasks, it also records the terminal output (i.e. combined stdout and stderr) to (<package>/.turbo/run-<command>.log). When turbo encounters a cached task, it will replay the output as if it happened again, but instantly, with the package name slightly dimmed.","hashing#Hashing":"By now, you're probably wondering how turbo decides what constitutes a cache hit vs. miss for a given task. Good question!First, turbo constructs a hash of the current global state of the codebase:\nThe contents of any files that satisfy the glob patterns and any the values of environment variables listed in globalDependencies\nThe sorted list environment variable key-value pairs that include THASH anywhere in their names (e.g. STRIPE_PUBLIC_THASH_SECRET_KEY, but not STRIPE_PUBLIC_KEY)\n\nThen it adds more factors relevant to a given workspace's task:\nHash the contents of all version-controlled files in the workspace folder or the files matching the inputs globs, if present\nThe hashes of all internal dependencies\nThe outputs option specified in the pipeline\nThe set of resolved versions of all installed dependencies, devDependencies, and optionalDependencies specified in a workspace's package.json from the root lockfile\nThe workspace task's name\nThe sorted list of environment variable key-value pairs that correspond to the environment variable names listed in applicable pipeline.<task-or-package-task>.dependsOn list.\n\nOnce turbo encounters a given workspace's task in its execution, it checks the cache (both locally and remotely) for a matching hash. If it's a match, it skips executing that task, moves or downloads the cached output into place and replays the previously recorded logs instantly. If there isn't anything in the cache (either locally or remotely) that matches the calculated hash, turbo will execute the task locally and then cache the specified outputs using the hash as an index.The hash of a given task is injected at execution time as an environment variable TURBO_HASH. This value can be useful in stamping outputs or tagging Dockerfile etc.\nAs of turbo v0.6.10, turbo's hashing algorithm when using npm or pnpm\ndiffers slightly from the above. When using either of these package managers,\nturbo will include the hashed contents of the lockfile in its hash algorithm\nfor each workspace's task. It will not parse/figure out the resolved set of\nall dependencies like the current yarn implementation."}},"/repo/docs/core-concepts/monorepos":{"title":"Monorepos","data":{"":"","the-problem#The problem":"Monorepos have many advantages - but they struggle to scale. Each workspace has its own test suite, its own linting and its own build process. A single monorepo might have hundreds of tasks to execute.","the-solution#The solution":"Turborepo solves your monorepo's scaling problem. Our remote cache stores the result of all your tasks, meaning that your CI never needs to do the same work twice.Task scheduling can be difficult in a monorepo. Imagine yarn build needs to run before yarn test, across all your workspaces. Turborepo can schedule your tasks for maximum speed, across all available cores.Turborepo can be adopted incrementally. It uses the package.json scripts you've already written, the dependencies you've already declared, and a single turbo.json file. You can use it with any package manager, like npm, yarn or pnpm. You can add it to any monorepo in just a few minutes.","what-turborepo-is-not#What turborepo is not":"Turborepo doesn't handle package installation. Tools like npm, pnpm or yarn already do that brilliantly. But they run tasks inefficiently, meaning slow CI builds.We recommend that Turborepo runs your tasks, and your favorite package manager installs your packages."}},"/repo/docs/core-concepts/remote-caching":{"title":"Remote Caching","data":{"":"Turborepo's task cache can save a lot of time by never doing the same work twice.But there's an issue - the cache is local to your machine. When you're working with a CI, this can result in a lot of duplicated work:\n\nSince Turborepo only caches to the local filesystem by default, the same task (turbo run build) must be re-executed on each machine (by you, by your teammates, by your CI, by your PaaS, etc.) even when all of the task inputs are identical — which wastes time and resources.","a-single-shared-cache#A single, shared cache":"What if you could share a single Turborepo cache across your entire team (and even your CI)?\n\nBy working with providers like Vercel, Turborepo can securely communicate with a remote cache - a cloud server that stores the results of your tasks.This can save enormous amounts of time by preventing duplicated work across your entire organization.\nRemote Caching is a powerful feature of Turborepo, but with great power comes\ngreat responsibility. Make sure you are caching correctly first and double\ncheck handling of environment variables. Please also remember Turborepo treats\nlogs as artifacts, so be aware of what you are printing to the console.","vercel#Vercel":"","for-local-development#For Local Development":"If you want to link your local turborepo to your Remote Cache, first authenticate the Turborepo CLI with your Vercel account:\nnpx turbo login\nNext, link your Turborepo to your remote cache:\nnpx turbo link\nOnce enabled, make some changes to a workspace you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache.To verify, delete your local Turborepo cache with:\n\nsh rm -rf ./node_modules/.cache/turbo\n\n\nsh rd /s /q \"./node_modules/.cache/turbo\"\n\nThen run the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you.","remote-caching-on-vercel-builds#Remote Caching on Vercel Builds":"If you are building and hosting your apps on Vercel, Remote Caching will be automatically set up on your behalf once you use turbo. You need to update your build settings to build with turbo.Please refer to the Vercel documentation for instructions.","artifact-integrity-and-authenticity-verification#Artifact Integrity and Authenticity Verification":"You can enable Turborepo to sign artifacts with a secret key before uploading them to the Remote Cache. Turborepo uses HMAC-SHA256 signatures on artifacts using a secret key you provide.\nTurborepo will verify the remote cache artifacts' integrity and authenticity when they're downloaded.\nAny artifacts that fail to verify will be ignored and treated as a cache miss by Turborepo.To enable this feature, set the remoteCache options on your turbo.json config to include signature: true. Then specify your secret key by declaring the TURBO_REMOTE_CACHE_SIGNATURE_KEY environment variable.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"remoteCache\": {\n// Indicates if signature verification is enabled.\n\"signature\": true\n}\n}","custom-remote-caches#Custom Remote Caches":"You can self-host your own Remote Cache or use other remote caching service providers as long as they comply with Turborepo's Remote Caching Server API.You can set the remote caching domain by specifying the --api and --token flags, where --api is the hostname and --token is a bearer token.\nturbo run build --api=\"https://my-server.example.com\" --token=\"xxxxxxxxxxxxxxxxx\"\nYou can see the endpoints / requests needed here."}},"/repo/docs/core-concepts/monorepos/filtering":{"title":"Filtering Workspaces","data":{"":"A monorepo can contain hundreds, or thousands, of workspaces. By default, running turbo run test will execute the test task in all available workspaces.\n\nTurborepo supports a --filter flag that lets you select the workspaces you'd like to execute your task in.\n\nYou can use it to:\nFilter by workspace name\nFilter by workspace directory\nInclude dependents and dependencies of matched workspaces\nExecute tasks from the workspace root\nFilter by changes in git history\nExclude workspaces from selection\n\nTurborepo will run each task against each matched workspace, ensuring that any tasks which depend on it are run first, according to the pipeline specification in turbo.json.","filter-syntax#Filter Syntax":"","multiple-filters#Multiple filters":"You can specify more than one filter by passing multiple --filter flags to the command:\nturbo run build --filter=my-pkg --filter=my-app","filter-by-workspace-name#Filter by workspace name":"When you want to run a script in only one workspace, you can use a single filter: --filter=my-pkg.\n# Build 'my-pkg', letting `turbo` infer task dependencies\n# from the pipeline defined in turbo.json\nturbo run build --filter=my-pkg\n\n# Build '@acme/bar', letting `turbo` infer task dependencies\n# from the pipeline defined in turbo.json\nturbo run build --filter=@acme/bar\nIf you want to run tasks inside several workspaces with similar names, you can use glob syntax: --filter=*my-pkg*.\n# Build all workspaces that start with 'admin-', letting turbo infer task\n# dependencies from the pipeline defined in turbo.json\nturbo run build --filter=admin-*","scopes#Scopes":"Some monorepos prepend their workspace names with a scope, such as @acme/ui and @acme/app. As long as the scope (@acme) is unique across the codebase, you may omit it from filters.\n- turbo run build --filter=@acme/ui\n+ turbo run build --filter=ui","include-dependents-of-matched-workspaces#Include dependents of matched workspaces":"Sometimes, you'll want to ensure that your shared package isn't affecting any downstream dependencies. For that, you can use --filter=...my-lib.If my-app depends on my-lib, ...my-lib will select my-app and my-lib.Including a ^ (...^my-lib) will select all of my-lib's dependents, but not my-lib itself.\n# Test 'my-lib' and everything that depends on 'my-lib'\nturbo run test --filter=...my-lib\n\n# Test everything that depends on 'my-lib', but not 'my-lib' itself\nturbo run test --filter=...^my-lib","include-dependencies-of-matched-workspaces#Include dependencies of matched workspaces":"Sometimes, you'll want to make sure that build is run in all of the dependencies of the lib you're targeting. For that, you can use --filter=my-app....If my-app depends on my-lib, my-app... will select my-app and my-lib.Including a ^ (my-app^...) will select all of my-app's dependencies, but not my-app itself.\n# Build 'my-app' and its dependencies\nturbo run build --filter=my-app...\n\n# Build 'my-app's dependencies, but not 'my-app' itself\nturbo run build --filter=my-app^...","filter-by-directory#Filter by directory":"Useful for when you want to target a specific directory, not a workspace name. It supports:\nExact matches: --filter=./apps/docs\nGlobs: --filter=./apps/*\n\n\n# Build all of the workspaces in the 'apps' directory\nturbo run build --filter=./apps/*","combining-with-other-syntaxes#Combining with other syntaxes":"When combining directory filters with other syntaxes, enclose in {}. For example:\n# Build all of the workspaces in the 'libs' directory,\n# and all the workspaces that depends on them\nturbo run build --filter=...{./libs/*}","filter-by-changed-workspaces#Filter by changed workspaces":"You can run tasks on any workspaces which have changed since a certain commit. These need to be wrapped in [].For example, --filter=[HEAD^1] will select all workspaces that have changed in the most recent commit:\n# Test everything that changed in the last commit\nturbo run test --filter=[HEAD^1]","check-a-range-of-commits#Check a range of commits":"If you need to check a specific range of commits, rather than comparing to HEAD, you can set both ends of the comparison via [<from commit>...<to commit>].\n# Test each workspace that changed between 'main' and 'my-feature'\nturbo run test --filter=[main...my-feature]","ignoring-changed-files#Ignoring changed files":"You can use --ignore to specify changed files to be ignored in the calculation of which workspaces have changed.","combining-with-other-syntaxes-1#Combining with other syntaxes":"You can additionally prepend the commit reference with ... to match the dependencies of other components\nagainst the changed workspaces. For instance, to select foo if any of foo's dependencies have changed in the last commit,\nyou can pass --filter=foo...[HEAD^1].\n# Build everything that depends on changes in branch 'my-feature'\nturbo run build --filter=...[origin/my-feature]\n\n# Build '@foo/bar' if it or any of its dependencies\n# changed in the last commit\nturbo run build --filter=@foo/bar...[HEAD^1]\nYou can even combine [] and {} syntax together:\n# Test each workspace in the '@scope' scope that\n# is in the 'packages' directory, if it has\n# changed in the last commit\nturbo run test --filter=@scope/*{./packages/*}[HEAD^1]","the-workspace-root#The workspace root":"The monorepo's root can be selected using the token //.\n# Run the format script from the root \"package.json\" file:\nturbo run format --filter=//","excluding-workspaces#Excluding workspaces":"Prepend ! to the filter. Matched workspaces from the entire filter will be excluded from the set of targets.\nFor example, match everything except @foo/bar: --filter=!@foo/bar. Note that you may need to escape ! as appropriate for your shell (e.g. \\!).\n# Build everything except '@foo/bar'\nturbo run build --filter=!@foo/bar\n# Build all of the workspaces in the 'apps' directory, except the 'admin' workspace\nturbo run build --filter=./apps/* --filter=!admin\n\nTurborepo's Filter API design and docs were/are inspired by\npnpm"}},"/repo/docs/core-concepts/monorepos/running-tasks":{"title":"Running Tasks","data":{"":"Every monorepo has two main building blocks: workspaces and tasks. Let's imagine you have a monorepo containing three workspaces, each with three tasks:\n\nHere, both apps/web and apps/doc use code from packages/shared. In fact, when they're built (via build) they need packages/shared to be built first.","most-tools-dont-optimize-for-speed#Most tools don't optimize for speed":"Let's imagine we want to run all our tasks across all our workspaces. In a tool like yarn, you might run a script like this:\nyarn workspaces run lint\nyarn workspaces run test\nyarn workspaces run build\nThis would mean the tasks run like this:\n\nAs you can see, lint gets run in all the workspaces. Then, build gets run - with shared going first. Finally, test gets run.This is the slowest possible way to run these tasks. Each task needs to wait for the previous one to finish before it can start. To improve on this, we'll need a tool that can multitask.","turborepo-can-multitask#Turborepo can multitask":"Turborepo can schedule our tasks for maximum speed by understanding the dependencies between our tasks.First, we declare our tasks inside turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n// ^build means build must be run in dependencies\n// before it can be run in this workspace\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": []\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nNext, we can replace our yarn workspaces script with this:\n- yarn workspaces run lint\n- yarn workspaces run test\n- yarn workspaces run build\n+ turbo run lint test build\nWhen we run it, Turborepo will multitask as many tasks as possible over all available CPU's, meaning our tasks run like this:\n\nBoth lint and test run immediately, because they have no dependsOn specified in turbo.json.The build task inside shared completes first, then web and docs build afterwards.","defining-a-pipeline#Defining a pipeline":"The pipeline configuration declares which tasks depend on each other in your monorepo. Here's a kitchen sink example:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n+      // A workspace's `build` task depends on that workspace's\n+      // topological dependencies' and devDependencies'\n+      // `build` tasks  being completed first. The `^` symbol\n+      // indicates an upstream dependency.\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n+      // A workspace's `test` task depends on that workspace's\n+      // own `build` task being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [],\n+      // A workspace's `test` task should only be rerun when\n+      // either a `.tsx` or `.ts` file has changed.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\", \"test/**/*.tsx\"]\n},\n\"lint\": {\n+      // A workspace's `lint` task has no dependencies and\n+      // can be run whenever.\n\"outputs\": []\n},\n\"deploy\": {\n+      // A workspace's `deploy` task depends on the `build`,\n+      // `test`, and `lint` tasks of the same workspace\n+      // being completed.\n\"dependsOn\": [\"build\", \"test\", \"lint\"],\n\"outputs\": []\n}\n}\n}\nLet's walk through some common patterns you'll want to get to know before diving in to turbo.json.","dependencies-between-tasks#Dependencies between tasks":"","in-the-same-workspace#In the same workspace":"There might be tasks which need to run before other tasks. For instance, build might need to be run before deploy.If both tasks are in the same workspace, you can specify the relationship like this:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {},\n\"deploy\": {\n// A workspace's `deploy` task depends on the `build`,\n// task of the same workspace being completed.\n\"dependsOn\": [\"build\"],\n\"outputs\": []\n}\n}\n}\nThis means that whenever turbo run deploy is run, build will also be run inside the same workspace.","in-a-different-workspace#In a different workspace":"A common pattern in monorepos is to declare that a workspace's build task should only run once the build tasks of all the workspaces it depends on are complete.The ^ symbol explicitly declares that the task has a dependency on a task in a workspace it depends on.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n// \"A workspace's `build` command depends on its dependencies'\n// and devDependencies' `build` commands being completed first\"\n\"dependsOn\": [\"^build\"]\n}\n}\n}","no-dependencies#No dependencies":"An empty dependency list (dependsOn is either undefined or []) means that nothing needs to run before this task! After all, it has NO dependencies.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"lint\": {\n// A workspace's `lint` command has no dependencies and can be run\n// whenever.\n\"outputs\": []\n}\n}\n}","specific-workspace-tasks#Specific workspace-tasks":"Sometimes, you may want to create a workspace-task dependency on another workspace-task. This can be especially helpful for repos migrating from lerna or rush, where tasks are run in separate phases by default. Sometimes these configurations make assumptions that cannot be expressed in a simple pipeline configuration, as seen above. Or you may just want to express sequences of tasks between applications or microservices when using turbo in CI/CD.For these cases, you can express these relationships in your pipeline configuration using the <workspace>#<task> syntax.\nThe example below describes the deploy script of a frontend application that depends on the deploy and health-check scripts of backend, as well as the test script of a ui workspace:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// Standard configuration\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"deploy\": {\n\"dependsOn\": [\"test\", \"build\"],\n\"outputs\": []\n},\n\n// Explicit workspace-task to workspace-task dependency\n\"frontend#deploy\": {\n\"dependsOn\": [\"ui#test\", \"backend#deploy\", \"backend#health-check\"],\n\"outputs\": []\n}\n}\n}\nThis explicit configuration for frontend#deploy may seem to conflict with the test and deploy task configurations, but it does not. Since test and deploy do not have dependencies on other workspaces (e.g. ^<task>), they can execute any time after their workspace's build and test scripts have finished.\nNotes:\nAlthough this <workspace>#<task> syntax is a useful escape hatch, we generally recommend using it for deployment orchestration tasks such as health checks, rather than build-time dependencies, so that Turborepo can optimize these tasks more efficiently\nPackage-tasks do not inherit cache configuration. You must redeclare\noutputs at the moment.\n<workspace> must match the name key in the workspace's package.json or the task will be ignored.","running-tasks-from-the-root#Running tasks from the root":"turbo can run tasks that exist in the package.json file at the root of the monorepo.\nThese must be explicitly added to the pipeline configuration using the key syntax \"//#<task>\". This is\ntrue even for tasks that already have their own entry. For example, if your pipeline declares a \"build\" task,\nand you want to include the build script defined in the monorepo's root package.json file with\nturbo run build, you must opt the root into it by declaring \"//#build\": {...} in your configuration.\nConversely, you do not need to define a generic \"my-task\": {...} entry if all you need is \"//#my-task\": {...}.A sample pipeline that defines the root task format and opts the root into test might look like:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n// This will cause the \"test\" script to be included when\n// \"turbo run test\" is run\n\"//#test\": {\n\"dependsOn\": [],\n\"outputs\": []\n},\n// This will cause the \"format\" script in the root package.json\n// to be run when \"turbo run format\" is run. Since the general\n// \"format\" task is not defined, only the root's \"format\" script\n// will be run.\n\"//#format\": {\n\"dependsOn\": [],\n\"outputs\": [\"dist/**/*\"],\n\"inputs\": [\"version.txt\"]\n}\n}\n}\nA note on recursion: Scripts defined in the monorepo's root package.json often call turbo themselves.\nFor example, the build script might be turbo run build. In this situation, including //#build in\nturbo run build will cause infinite recursion. It is for this reason that tasks run from the monorepo's root must\nbe explicitly opted into via including //#<task> in the pipeline configuration. turbo includes\nsome best-effort checking to produce an error in the recursion situations, but it is up to you to to only\nopt in those tasks which don't themselves trigger a turbo run that would recurse.\nTurborepo's Pipeline API design and this page of documentation was inspired by\nMicrosoft's Lage\nproject.\nShoutout to Kenneth Chau for the idea of\nfanning out tasks in such a concise and elegant way.","tips#Tips":"","tasks-that-are-in-the-pipeline-but-not-in-some-packagejson#Tasks that are in the pipeline but not in SOME package.json":"Sometimes tasks declared in the pipeline are not present in all workspaces' package.json files. turbo will gracefully ignore those. No problem!","pipeline-tasks-are-the-only-ones-that-turbo-knows-about#pipeline tasks are the only ones that turbo knows about":"turbo will only account for tasks declared in the pipeline configuration. If it's not listed there, turbo will not know how to run them."}},"/repo/docs/getting-started/add-to-project":{"title":"Add to Existing Project","data":{"":"Turborepo can be used in any project to speed up the execution of scripts in your package.json.After you install turbo, you'll be able to run all your package.json tasks from turbo instead of your package manager.By configuring your turbo.json correctly, you'll notice how caching helps your tasks run a lot faster.","quickstart#Quickstart":"If you don't have one already, create a new application:\n\n\n\n\nnpx create-next-app@latest\n\n\n\nnpm create vite@latest\n\n\n\nInstall turbo:\n\n\n\n\nnpm install turbo --save-dev\n\n\n\nyarn add turbo --dev\n\n\n\npnpm install turbo --save-dev\n\n\n\nAdd a turbo.json file at the base of your new repository:\n\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nSome Vite starters ship with a package.json that looks like this:\n{\n\"scripts\": {\n\"build\": \"tsc && vite build\"\n}\n}\nWe recommend splitting these into a lint and build script.\n{\n\"scripts\": {\n\"build\": \"vite build\",\n\"lint\": \"tsc\"\n}\n}\nThis means that Turbo can schedule them separately.\n\n\nTry running build and lint with turbo:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nThis runs build and lint at the same time.\nWithout making any changes to the code, try running build and lint again:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nYou should see terminal output like this:\nTasks:    2 successful, 2 total\nCached:    2 cached, 2 total\nTime:    185ms >>> FULL TURBO\nCongratulations - you just completed a build and lint in under 200ms.To learn how this is possible, check out our core concepts docs.\nTry running dev with turbo:\n\n\n\n\nnpx turbo dev\n\n\n\nyarn turbo dev\n\n\n\npnpm turbo dev\n\n\nYou'll notice that your dev script starts up. You can use turbo to run any script in your package.json."}},"/repo/docs/getting-started/existing-monorepo":{"title":"Add to Existing Monorepo","data":{"":"turbo works with Yarn, npm, and pnpm on the following operating systems:\nmacOS darwin 64-bit (Intel), ARM 64-bit (Apple Silicon)\nLinux 32-bit, 64-bit, ARM, ARM 64-bit, MIPS 64-bit Little Endian, PowerPC 64-bit Little Endian, IBM Z 64-bit Big Endian\nWindows 32-bit, 64-bit, ARM 64-bit\nFreeBSD 64-bit, ARM 64-bit\nNetBSD AMD64\nAndroid ARM 64-bit","configure-workspaces#Configure workspaces":"turbo is built on top of Workspaces, a way of managing multiple packages from within a single monorepo package. Turborepo is compatible with the workspace implementations from all package managers. For more information on managing your Turborepo workspaces, see the Workspaces documentation.You can configure workspaces any way you want, but a common folder structure example is keeping applications in the /apps folder and packages in the /packages folder. The configuration of these folders is different for each package manager.\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your packages in pnpm-workspace.yaml.\npackages:\n- \"packages/*\"\n- \"apps/*\"\n\n\nAfter configuring your workspaces, re-run your package manager's install command.\nNote: Nested workspaces are not supported. As package names are required to be\nunique, moving each package to be a child of the monorepo's root package\nshould meet your needs.","install-turbo#Install turbo":"Add turbo as a development dependency at the root of your monorepo.\n\nbash npm install turbo -D\n\n\nbash yarn add turbo -DW\n\n\nbash pnpm add turbo -Dw\n\nThe turbo package is a shell script that will install the proper turbo-<os>-<arch> package for your operating system and architecture.\nNote: Linux builds of turbo link against glibc. For Alpine Docker environments, you will need to ensure libc6-compat is installed as well, via RUN apk add --no-cache libc6-compat","create-turbojson#Create turbo.json":"In the root of your monorepo, create an empty file named turbo.json. This will hold the configuration for Turborepo.\n{\n\"$schema\": \"https://turborepo.org/schema.json\"\n}","create-a-pipeline#Create a pipeline":"To define your monorepo's task dependency graph, use the pipeline key in the turbo.json configuration file at the root of monorepo. turbo interprets this configuration to optimally schedule, execute, and cache the outputs of each of the package.json scripts defined in your workspaces.Each key in the pipeline object is the name of a package.json script that can be executed by turbo run. You can specify its dependencies with the dependsOn key inside it as well as some other options related to caching. For more information on configuring your pipeline, see the Pipelines documentation.Workspaces that do not have the specified script defined in their package.json's list of scripts will be ignored by turbo.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n// A package's `build` script depends on that package's\n// dependencies and devDependencies\n// `build` tasks  being completed first\n// (the `^` symbol signifies `upstream`).\n\"dependsOn\": [\"^build\"],\n// note: output globs are relative to each package's `package.json`\n// (and not the monorepo root)\n\"outputs\": [\".next/**\"]\n},\n\"test\": {\n// A package's `test` script depends on that package's\n// own `build` script being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [],\n// A package's `test` script should only be rerun when\n// either a `.tsx` or `.ts` file has changed in `src` or `test` folders.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\", \"test/**/*.tsx\"]\n},\n\"lint\": {\n// A package's `lint` script has no dependencies and\n// can be run whenever. It also has no filesystem outputs.\n\"outputs\": []\n},\n\"deploy\": {\n// A package's `deploy` script depends on the `build`,\n// `test`, and `lint` scripts of the same package\n// being completed. It also has no filesystem outputs.\n\"dependsOn\": [\"build\", \"test\", \"lint\"],\n\"outputs\": []\n}\n}\n}\nThe rough execution order for a given package is based on the dependsOn keys:\nbuild once its upstream dependencies have run their build commands\ntest once its own build command is finished and has no filesystem outputs (just logs) within a package\nlint runs in an arbitrary order as it has no upstream dependencies\ndeploy once its own build, test, and lint commands have finished.\n\nAfter execution, the full pipline can run:\nnpx turbo run build test lint deploy\nturbo will then schedule the execution of each task(s) to optimize usage of the machine's resources.","edit-gitignore#Edit .gitignore":"Add .turbo to your .gitignore file. The CLI uses these folders for logs and certain task outputs.\n+ .turbo\nMake sure that your task artifacts, the files and folders you want cached, are also included in your .gitignore.\n+ build/**\n+ dist/**\n+ .next/**\nRe-run your npm client's install command to check your configuration.","create-packagejson-scripts#Create package.json scripts":"Add or update scripts in your monorepo's root package.json file and have them delegate to turbo.\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\",\n\"lint\": \"turbo run lint\",\n\"dev\": \"turbo run dev\"\n}\n}","build-your-monorepo#Build your monorepo":"sh npm run build\n\n\nsh yarn build\n\n\nsh pnpm build\n\nDepending on your monorepo setup, some artifacts might already be caching properly. In the next sections, we'll show how turbo works, how scope works, and then how to get caching working after that.","configure-remote-caching#Configure Remote Caching":"A major key 🔑 to Turborepo's speed is that it is both lazy and efficient—it does the least amount of work possible and it tries to never redo work that's already been done before.At the moment, Turborepo caches your tasks on your local filesystem (i.e. \"single-player mode,\" if you will). However, what if there was a way to take advantage of the computational work done by your teammates or your CI (i.e. \"co-op multiplayer mode\")? What if there was a way to teleport and share a single cache across machines? Almost like a \"Dropbox\" for your Turborepo cache.\nRemote Caching has entered the chat.\nTurborepo can use a technique known as Remote Caching to share cache artifacts across machines for an additional speed boost.\nRemote Caching is a powerful feature of Turborepo, but with great power comes\ngreat responsibility. Make sure you are caching correctly first and double\ncheck handling of environment variables. Please also remember Turborepo treats\nlogs as artifacts, so be aware of what you are printing to the console.","using-remote-caching-for-local-development#Using Remote Caching for Local development":"Turborepo uses Vercel as its default remote caching provider. If you want to link your local turborepo to your Remote Cache you can authenticate the Turborepo CLI with your Vercel account:\nnpx turbo login\nThen, link your turborepo to your remote cache:\nnpx turbo link\nOnce enabled, make some changes to a package or application you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache. To verify that this worked, delete your local Turborepo cache:\nrm -rf ./node_modules/.cache/turbo\nRun the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you.\nNote: When connecting to an sso-enabled Vercel team, you must provide your\nTeam slug as an argument to npx turbo login.\n\nnpx turbo login --sso-team=<team-slug>","next-steps#Next Steps":"You're now up and running with Turborepo, but there are still a few things to do:\nUnderstand how Turborepo caching works\nCorrectly handle environment variables\nLearn to orchestrate task running with pipelines\nEfficiently filter package tasks\nConfigure Turborepo with your CI provider"}},"/repo/docs/getting-started/create-new":{"title":"Create a New Monorepo","data":{"":"","quickstart#Quickstart":"To create a new monorepo, use our create-turbo npm package:\nnpx create-turbo@latest\nYou can also clone a Turborepo starter repository to get a head start on your monorepo. To see Turborepo examples and starters, see the Turborepo examples directory on GitHub.","full-tutorial#Full tutorial":"This tutorial will walk you through using the Turborepo basic example. By the end, you'll feel confident with using turbo, and know all the basic functionality.\nDuring this tutorial, some lines of code are omitted from the code samples. For instance, when showing a package.json we won't show all of the keys - only the ones that matter.","1-running-create-turbo#1. Running create-turbo":"First, run:\nnpx create-turbo@latest\nThis installs the create-turbo CLI, and runs it. You'll be asked several questions:","where-would-you-like-to-create-your-turborepo#Where would you like to create your turborepo?":"Choose anywhere you like. The default is ./my-turborepo.","which-package-manager-do-you-want-to-use#Which package manager do you want to use?":"Turborepo doesn't handle installing packages, so you'll need to choose either:\nnpm\npnpm\nyarn\n\nIf you're not sure, we recommend choosing pnpm. If you don't have it installed, cancel create-turbo (via ctrl-C) and take a look at the installation instructions.","installation#Installation":"Once you've picked a package manager, create-turbo will create a bunch of new files inside the folder name you picked. It'll also install all the dependencies that come with the basic example by default.","2-exploring-your-new-repo#2. Exploring your new repo":"You might have noticed something in the terminal. create-turbo gave you a description of all of the things it was adding.\n>>> Creating a new turborepo with the following:\n\n- apps/web: Next.js with TypeScript\n- apps/docs: Next.js with TypeScript\n- packages/ui: Shared React component library\n- packages/eslint-config-custom: Shared configuration (ESLint)\n- packages/tsconfig: Shared TypeScript `tsconfig.json`\nEach of these is a workspace - a folder containing a package.json. Each workspace can declare its own dependencies, run its own scripts, and export code for other workspaces to use.Open the root folder - ./my-turborepo - in your favourite code editor.","understanding-packagesui#Understanding packages/ui":"First, open ./packages/ui/package.json. You'll notice that the package's name is \"name\": \"ui\" - right at the top of the file.Next, open ./apps/web/package.json. You'll notice that this package's name is \"name\": \"web\". But also - take a look in its dependencies.You'll see that \"web\" depends on a package called \"ui\". If you're using pnpm, you'll see it's declared like this:\n{\n\"dependencies\": {\n\"ui\": \"workspace:*\"\n}\n}\nThis means that our web app depends on our local ui package.If you look inside apps/docs/package.json, you'll see the same thing. Both web and docs depend on ui - a shared component library.This pattern of sharing code across applications is extremely common in monorepos - and means that multiple apps can share a single design system.","understanding-imports-and-exports#Understanding imports and exports":"Take a look inside ./apps/docs/pages/index.tsx. Both docs and web are Next.js applications, and they both use the ui library in a similar way:\nimport { Button } from \"ui\";\n//       ^^^^^^         ^^\n\nexport default function Docs() {\nreturn (\n<div>\n<h1>Docs</h1>\n<Button />\n</div>\n);\n}\nThey're importing Button directly from a dependency called ui! How does that work? Where is Button coming from?Open packages/ui/package.json. You'll notice these two attributes:\n{\n\"main\": \"./index.tsx\",\n\"types\": \"./index.tsx\"\n}\nWhen workspaces import from ui, main tells them where to access the code they're importing. types tells them where the TypeScript types are located.So, let's look inside packages/ui/index.tsx:\nimport * as React from \"react\";\nexport * from \"./Button\";\nEverything inside this file will be able to be used by workspaces that depend on ui.index.tsx is exporting everything from a file called ./Button, so let's go there:\nimport * as React from \"react\";\n\nexport const Button = () => {\nreturn <button>Boop</button>;\n};\nWe've found our button! Any changes we make in this file will be shared across web and docs. Pretty cool!\nTry experimenting with exporting a different function from this file. Perhaps add(a, b) for adding two numbers together.This can then be imported by web and docs.","understanding-tsconfig#Understanding tsconfig":"We have two more workspaces to look at, tsconfig and eslint-config-custom. Each of these allow for shared configuration across the monorepo. Let's look in tsconfig:\n{\n\"name\": \"tsconfig\",\n\"files\": [\"base.json\", \"nextjs.json\", \"react-library.json\"]\n}\nHere, we specify three files to be exported, inside files. Packages which depend on tsconfig can then import them directly.For instance, packages/ui depends on tsconfig:\n{\n\"devDependencies\": {\n\"tsconfig\": \"workspace:*\"\n}\n}\nAnd inside its tsconfig.json file, it imports it using extends:\n{\n\"extends\": \"tsconfig/react-library.json\"\n}\nThis pattern allows for a monorepo to share a single tsconfig.json across all its workspaces, reducing code duplication.","understanding-eslint-config-custom#Understanding eslint-config-custom":"Our final workspace is eslint-config-custom.You'll notice that this is named slightly differently to the other workspaces. It's not as concise as ui or tsconfig. Let's take a look inside .eslintrc.js in the root of the monorepo to figure out why.\nmodule.exports = {\n// This tells ESLint to load the config from the workspace `eslint-config-custom`\nextends: [\"custom\"],\n};\nESLint resolves configuration files by looking for workspaces with the name eslint-config-*. This lets us write extends: ['custom'] and have ESLint find our local workspace.But why is this in the root of the monorepo?The way ESLint finds its configuration file is by looking at the closest .eslintrc.js. If it can't find one in the current directory, it'll look in the directory above until it finds one.So that means that if we're working on code inside packages/ui (which doesn't have a .eslintrc.js) it'll refer to the root instead.Apps that do have an .eslintrc.js can refer to custom in the same way. For instance, in docs:\nmodule.exports = {\nroot: true,\nextends: [\"custom\"],\n};\nJust like tsconfig, eslint-config-custom lets us share ESLint configs across our entire monorepo, keeping things consistent no matter what project you're working on.","summary#Summary":"It's important to understand the dependencies between these workspaces. Let's map them out:\nweb - depends on ui, tsconfig and eslint-config-custom\ndocs - depends on ui, tsconfig and eslint-config-custom\nui - depends on tsconfig and eslint-config-custom\ntsconfig - no dependencies\neslint-config-custom - no dependencies\n\nNote that the Turborepo CLI is not responsible for managing these dependencies. All of the things above are handled by the package manager you chose (npm, pnpm or yarn).","3-understanding-turbojson#3. Understanding turbo.json":"We now understand our repository and its dependencies. How does Turborepo help?Turborepo helps by making running tasks simpler and much more efficient.Let's take a look inside our root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev\",\n\"lint\": \"turbo run lint\"\n}\n}\nWe've got three tasks specified here in scripts which use turbo run. You'll notice that each of them is specified in turbo.json:\n{\n\"pipeline\": {\n\"build\": {\n//   ^^^^^\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\"dist/**\", \".next/**\"]\n},\n\"lint\": {\n//   ^^^^\n\"outputs\": []\n},\n\"dev\": {\n//   ^^^\n\"cache\": false\n}\n}\n}\nWhat we're seeing here is that we've registered three tasks with turbo - lint, dev and build. Every task that's registered inside turbo.json can be run with turbo run <task>.To see this in action, let's add a script to the root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev --parallel\",\n\"lint\": \"turbo run lint\",\n+   \"hello\": \"turbo run hello\"\n}\n}\nNow, let's run hello.\n\n\nnpm run hello\n\n\n\nyarn hello\n\n\n\npnpm run hello\n\n\nYou'll see this error in the console:\ntask `hello` not found in turbo `pipeline` in \"turbo.json\".\nAre you sure you added it?\nThat's worth remembering - in order for turbo to run a task, it must be in turbo.json.Let's investigate the scripts we already have in place.","4-linting-with-turborepo#4. Linting with Turborepo":"Try running our lint script:\n\n\nnpm run lint\n\n\n\nyarn lint\n\n\n\npnpm run lint\n\n\nYou'll notice several things happen in the terminal.\nSeveral scripts will be run at the same time, each prefixed with either docs:lint, ui:lint or web:lint.\nThey'll each succeed, and you'll see 3 successful in the terminal.\nYou'll also see 0 cached, 3 total. We'll cover what this means later.\n\nThe scripts that each run come from each workspace's package.json. Each workspace can optionally specify its own lint script:\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"eslint *.ts*\"\n}\n}\nWhen we run turbo run lint, Turborepo looks at each lint script in each workspace and runs it. For more details, see our pipelines docs.","using-the-cache#Using the cache":"Let's run our lint script one more time. You'll notice a few new things appear in the terminal:\ncache hit, replaying output appears for docs:lint, web:lint and ui:lint.\nYou'll see 3 cached, 3 total.\nThe total runtime should be under 100ms, and >>> FULL TURBO appears.\n\nSomething interesting just happened. Turborepo realised that our code hadn't changed since the last time we ran the lint script.It had saved the logs from the previous run, so it just replayed them.Let's try changing some code to see what happens. Make a change to a file inside apps/docs:\nimport { Button } from \"ui\";\n\nexport default function Docs() {\nreturn (\n<div>\n-     <h1>Docs</h1>\n+     <h1>My great docs</h1>\n<Button />\n</div>\n);\n}\nNow, run the lint script again. You'll notice that:\ndocs:lint has a comment saying cache miss, executing. This means that docs is running its linting.\n2 cached, 3 total appears at the bottom.\n\nThis means that the results of our previous tasks were still cached. Only the lint script inside docs actually ran - again, speeding things up. To learn more, check out our caching docs.","5-building-with-turborepo#5. Building with Turborepo":"Let's try running our build script:\n\n\nnpm run build\n\n\n\nyarn build\n\n\n\npnpm run build\n\n\nYou'll see similar outputs to when we ran our lint script. Only apps/docs and apps/web specify a build script in their package.json, so only those are run.Take a look inside build in turbo.json. There's some interesting config there.\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n}\n}\n}\nYou'll notice that some outputs have been specified. Declaring outputs will mean that when turbo finishes running your task, it'll save the output you specify in its cache.Both apps/docs and apps/web are Next.js apps, and they output builds to the ./.next folder.Let's try something. Delete the apps/docs/.next build folder.Run the build script again. You'll notice:\nWe hit FULL TURBO - the builds complete in under 100ms.\nThe .next folder re-appears!\n\nTurborepo cached the result of our previous build. When we ran the build command again, it restored the entire .next/** folder from the cache. To learn more, check out our docs on cache outputs.","6-running-dev-scripts#6. Running dev scripts":"Let's now try running dev.\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm run dev\n\n\nYou'll notice some information in the terminal:\nOnly two scripts will execute - docs:dev and web:dev. These are the only two workspaces which specify dev.\nBoth dev scripts are run simultaneously, starting your Next.js apps on ports 3000 and 3001.\nIn the terminal, you'll see cache bypass, force executing.\n\nTry quitting out of the script, and re-running it. You'll notice we don't go FULL TURBO. Why is that?Take a look at turbo.json:\n{\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}\nInside dev, we've specified \"cache\": false. This means we're telling Turborepo not to cache the results of the dev script. dev runs a persistent dev server and produces no outputs, so caching it makes no sense. Learn more about in our docs on turning off caching.","running-dev-on-only-one-workspace-at-a-time#Running dev on only one workspace at a time":"By default, turbo run dev will run dev on all workspaces at once. But sometimes, we might only want to choose one workspace.To handle this, we can add a --filter flag to our command. This --filter gets passed to the turbo CLI.\n\n\nnpm run dev -- --filter docs\n\n\n\nyarn dev --filter docs\n\n\n\npnpm run dev --filter docs\n\n\nYou'll notice that it now only runs docs:dev. Learn more about filtering workspaces from our docs.","summary-1#Summary":"Well done! You've learned all about your new monorepo, and how Turborepo makes handling your tasks easier.","next-steps#Next steps":"Need to add more tasks? Learn more about using pipelines\nWant to speed up your CI? Set up remote caching.\nWant some inspiration? Take a look at our directory of examples"}},"/repo/docs/handbook/building-your-app":{"title":"Building Your App","data":{"":"Unless your monorepo is only used for publishing packages to npm, it will likely contain at least one application. Coordinating your app's builds with Turborepo can lead to some extraordinary gains in speed.","setting-up-the-build#Setting up the build":"Turborepo works by keeping your workspace tasks where they belong - in each workspace's package.json. Let's imagine you have a monorepo that looks like this:\n├── apps\n│   └── web\n│       └── package.json\n├── package.json\n└── turbo.json\nYour apps/web/package.json should have a build script inside:\n\n\n{\n\"scripts\": {\n\"build\": \"next build\"\n}\n}\n\n\n\n{\n\"scripts\": {\n\"build\": \"vite build\"\n}\n}\n\n\nInside turbo.json, you can add build to the pipeline.\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n}\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n}\n}\n}\n\n\n\nWe configure the outputs so that we can enable caching - an extremely powerful feature of Turborepo that can skip tasks that have been done before.\nNow, add a script to your root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\"\n}\n}\nThis means that running build from root using your package manager will build all of the apps in the repository. Thanks to Turborepo's task cache, you can end up with extremely fast build times."}},"/repo/docs/handbook/deploying-with-docker":{"title":"Deploying with Docker","data":{"":"Building a Docker image is a common way to deploy all sorts of applications. However, doing so from a monorepo has several challenges.","the-problem#The problem":"TL;DR: In a monorepo, unrelated changes can make Docker do unnecessary work when deploying your app.Let's imagine you have a monorepo that looks like this:\n├── apps\n│   ├── docs\n│   │   ├── server.js\n│   │   └── package.json\n│   └── web\n│       └── package.json\n├── package.json\n└── package-lock.json\nYou want to deploy apps/docs using Docker, so you create a Dockerfile:\nFROM node:16\n\nWORKDIR /usr/src/app\n\n# Copy root package.json and lockfile\nCOPY package.json ./\nCOPY package-lock.json ./\n\n# Copy the docs package.json\nCOPY apps/docs/package.json ./apps/docs/package.json\n\nRUN npm install\n\n# Copy app source\nCOPY . .\n\nEXPOSE 8080\n\nCMD [ \"node\", \"apps/docs/server.js\" ]\nThis will copy the root package.json and the root lockfile to the docker image. Then, it'll install dependencies, copy the app source and start the app.You should also create a .dockerignore file to prevent node_modules from being copied in with the app's source.\nnode_modules\nnpm-debug.log","the-lockfile-changes-too-often#The lockfile changes too often":"Docker is pretty smart about how it deploys your apps. Just like Turbo, it tries to do as little work as possible.In our Dockerfile's case, it will only run npm install if the files it has in its image are different from the previous run. If not, it'll restore the node_modules directory it had before.This means that whenever package.json, apps/docs/package.json or package-lock.json change, the docker image will run npm install.This sounds great - until we realise something. The package-lock.json is global for the monorepo. That means that if we install a new package inside apps/web, we'll cause apps/docs to redeploy.In a large monorepo, this can result in a huge amount of lost time, as any change to a monorepo's lockfile cascades into tens or hundreds of deploys.","the-solution#The solution":"The solution is to prune the inputs to the Dockerfile to only what is strictly necessary. Turborepo provides a simple solution - turbo prune.\nturbo prune --scope=\"docs\" --docker\nRunning this command creates a pruned version of your monorepo inside an ./out directory. It only includes workspaces which docs depends on.Crucially, it also prunes the lockfile so that only the relevant node_modules will be downloaded.","the---docker-flag#The --docker flag":"By default, turbo prune puts all relevant files inside ./out. But to optimize caching with Docker, we ideally want to copy the files over in two stages.First, we want to copy over only what we need to install the packages. When running --docker, you'll find this inside ./out/json.\nout\n├── json\n│   └── apps\n│       └── docs\n│           └── package.json\n├── full\n│   └── apps\n│       └── docs\n│           ├── server.js\n│           └── package.json\n└── package-lock.json\nAfterwards, you can copy the files in ./out/full to add the source files.Splitting up dependencies and source files in this way lets us only run npm install when dependencies change - giving us a much larger speedup.\nWithout --docker, all pruned files are placed inside ./out.","example#Example":"Our detailed with-docker example goes into depth on how to utilise prune to its full potential. Here's the Dockerfile, copied over for convenience.\nFROM node:alpine AS builder\nRUN apk add --no-cache libc6-compat\nRUN apk update\n# Set working directory\nWORKDIR /app\nRUN yarn global add turbo\nCOPY . .\nRUN turbo prune --scope=web --docker\n\n# Add lockfile and package.json's of isolated subworkspace\nFROM node:alpine AS installer\nRUN apk add --no-cache libc6-compat\nRUN apk update\nWORKDIR /app\n\n# First install the dependencies (as they change less often)\nCOPY .gitignore .gitignore\nCOPY --from=builder /app/out/json/ .\nCOPY --from=builder /app/out/yarn.lock ./yarn.lock\nRUN yarn install\n\n# Build the project\nCOPY --from=builder /app/out/full/ .\nCOPY turbo.json turbo.json\nRUN yarn turbo run build --filter=web...\n\nFROM node:alpine AS runner\nWORKDIR /app\n\n# Don't run production as root\nRUN addgroup --system --gid 1001 nodejs\nRUN adduser --system --uid 1001 nextjs\nUSER nextjs\n\nCOPY --from=installer /app/apps/web/next.config.js .\nCOPY --from=installer /app/apps/web/package.json .\n\n# Automatically leverage output traces to reduce image size\n# https://nextjs.org/docs/advanced-features/output-file-tracing\nCOPY --from=installer --chown=nextjs:nodejs /app/apps/web/.next/standalone ./\nCOPY --from=installer --chown=nextjs:nodejs /app/apps/web/.next/static ./apps/web/.next/static\n\nCMD node apps/web/server.js"}},"/repo/docs/handbook/dev":{"title":"Development Tasks","data":{"":"The vast majority of development workflows look like this:\nOpen a repository\nRun a dev task while they develop\nAt the end of the day, shut down the dev task and close the repository.\n\ndev will likely be the most frequently run task in your repository, so getting it right is important.","types-of-dev-tasks#Types of dev tasks":"dev tasks come in many shapes and sizes:\nRunning a local development server for a web app\nRunning nodemon to re-run a backend process every time code changes\nRunning tests in --watch mode","setup-with-turborepo#Setup with Turborepo":"You should specify your dev task like this in your turbo.json.\n{\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}\nSince dev tasks don't produce outputs, outputs is empty. dev tasks are also unique in that you rarely want to cache them, so we set cache as false.","setting-up-packagejson#Setting up package.json":"You should also provide a dev task in your root package.json:\n{\n\"scripts\": {\n\"dev\": \"turbo run dev\"\n}\n}\nThis enables developers to run the task directly from their normal task runner.","running-tasks-before-dev#Running tasks before dev":"In some workflows, you'll want to run tasks before you run your dev task. For instance, generating code or running a db:migrate task.In these cases, use dependsOn to say that any codegen or db:migrate tasks should be run before dev is run.\n{\n\"pipeline\": {\n\"dev\": {\n\"dependsOn\": [\"codegen\", \"db:migrate\"],\n\"cache\": false,\n},\n\"codegen\": {\n\"outputs\": [\"./codegen-outputs/**\"]\n},\n\"db:migrate\": {\n\"cache\": false\n}\n}\n}\nThen, in your app's package.json:\n{\n\"scripts\": {\n// For example, starting the Next.js dev server\n\"dev\": \"next\",\n// For example, running a custom code generation task\n\"codegen\": \"node ./my-codegen-script.js\",\n// For example, using Prisma\n\"db:migrate\": \"prisma db push\"\n}\n}\nThis means that users of your dev task don't need to worry about codegen or migrating their database - it gets handled for them before their development server even starts.","running-dev-only-in-certain-workspaces#Running dev only in certain workspaces":"To run a dev task in only certain workspaces, you should use the --filter syntax. For example:\nturbo run dev --filter docs\nWill only run dev in the workspace named docs.","using-environment-variables#Using environment variables":"While developing, you'll often need to use environment variables. These let you customize the behavior of your program - for instance, pointing to a different DATABASE_URL in development and production.We recommend using a library called dotenv-cli to solve this problem.","tutorial#Tutorial":"Install dotenv-cli in your root workspace:\n\n\n\n\n# Installs dotenv-cli in the root workspace\nnpm add dotenv-cli\n\n\n\n# Installs dotenv-cli in the root workspace\nyarn add dotenv-cli --ignore-workspace-root-check\n\n\n\n# Installs dotenv-cli in the root workspace\npnpm add dotenv-cli --ignore-workspace-root-check\n\n\n\nAdd a .env file to your root workspace:\n\n\n├── apps/\n├── packages/\n+ ├── .env\n├── package.json\n└── turbo.json\nAdd any environment variables you need to inject:\nDATABASE_URL=my-database-url\n\nInside your root package.json, add a dev script. Prefix it with dotenv and the -- argument separator:\n\n\n{\n\"scripts\": {\n\"dev\": \"dotenv -- turbo run dev\"\n}\n}\nThis will extract the environment variables from .env before running turbo run dev.\nNow, you can run your dev script:\n\n\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm dev\n\n\nAnd your environment variables will be populated! In Node.js, these are available on process.env.DATABASE_URL.\nYou should also add your environment variables to your turbo.json if you're using them to build your app."}},"/repo/docs/handbook/linting":{"title":"Linting","data":{"":"Linting in a monorepo can be tricky. Most of your workspaces will likely contain code that needs to be linted - so working out the most efficient way to lint them is tough.In this guide, we'll propose a method that plays to Turborepo's strengths:\nRunning lint tasks inside the workspaces, not from root\nSharing as much config as possible between workspaces","running-tasks#Running tasks":"We recommend specifying a single lint task inside your turbo.json.\n{\n\"pipeline\": {\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nThen, inside each workspace that needs to be linted, add a lint script. We'll use TypeScript as an example:\n{\n\"scripts\": {\n\"lint\": \"tsc\"\n}\n}\nThis pattern has two benefits:\nParallelization: the lint tasks will be run concurrently, speeding them up\nCaching: lint tasks will only be re-run on workspaces that have changed\n\nThis means you can lint your entire repo using one command:\nturbo run lint","sharing-config-files#Sharing config files":"Sharing configuration across a monorepo helps keep the development experience consistent. Most linters will have a system for sharing config, or extending config across different files.So far, we've built guides for sharing config in:\nTypeScript\nESLint"}},"/repo/docs/handbook/migrating-to-a-monorepo":{"title":"Migrating to a Monorepo","data":{"":"Migrating from a multi-repo setup to a monorepo setup can bring enormous benefits for productivity, especially if:\nYou're finding it hard to share code between applications\nYou want a unified approach on how your team builds code\n\nIt can be daunting to move to a monorepo. But with careful planning, it can go pretty smoothly.","folder-structure#Folder structure":"Let's imagine your multi-repo setup looks like this:\nweb (repo 1)\n├─ package.json\n\ndocs (repo 2)\n├─ package.json\n\napp (repo 3)\n├─ package.json\nYou've got three repositories, web, docs and app. They don't have any shared dependencies, but you've noticed lots of duplicated code between them.The best way to organise them in a monorepo would be like so:\nmy-monorepo\n├─ apps\n│  ├─ app\n│  │  └─ package.json\n│  ├─ docs\n│  │  └─ package.json\n│  └─ web\n│     └─ package.json\n└─ package.json\nTo start sharing code, you could use the internal package pattern, resulting in a new packages folder:\nmy-monorepo\n├─ apps\n│  ├─ app\n│  │  └─ package.json\n│  ├─ docs\n│  │  └─ package.json\n│  └─ web\n│     └─ package.json\n├─ packages\n│  └─ shared\n│     └─ package.json\n└─ package.json\n\nIf you're planning to move to a monorepo, try sketching out the exact folder\nstructure you're aiming for.","setting-up-workspaces#Setting up workspaces":"Once your apps are in the right folder structure, you'll need to set up workspaces and install your dependencies. Our sections on setting up workspaces should help.","handling-tasks#Handling tasks":"Now your workspaces are set up, you'll need to figure out how you're going to run your tasks in your new monorepo. We've got sections on:\nHow to configure tasks with Turborepo.\nHow to set up your development tasks\nHow to set up linting\nHow to build your application\nHow to set up testing"}},"/repo/docs/handbook/package-installation":{"title":"Package Installation","data":{"":"A package manager (like npm) handles two things for you: managing workspaces and installing packages.Turborepo is compatible with four package managers:\nnpm\npnpm\nYarn 1\nYarn >=2 (docs coming soon)\n\nYou should use whichever you feel most comfortable with - but if you're a monorepo beginner, we recommend npm.If you're comfortable with monorepos, we recommend pnpm. It's faster and offers some useful CLI options like --filter.","installing-packages#Installing packages":"When you first clone or create your monorepo, you'll need to:\nMake sure you're in the root directory of your monorepo\nRun the install command:\n\n\n\nbash npm install\n\n\nbash yarn install\n\n\nbash pnpm install\n\nYou'll now see node_modules folders appear in the root of your repository, and in each workspace.","addingremovingupgrading-packages#Adding/removing/upgrading packages":"You can add, remove and upgrade packages from within your monorepo using your package manager's built-in commands:\n\nInstall a package in a workspace\nnpm install <package> --workspace=<workspace>\nExample:\nnpm install react --workspace=web\nRemove a package from a workspace\nnpm uninstall <package> --workspace=<workspace>\nExample:\nnpm uninstall react --workspace=web\nUpgrade a package in a workspace\nnpm update <package> --workspace=<workspace>\nExample:\nnpm update react --workspace=web\n\n\nInstall a package in a workspace\nyarn workspace <workspace> add <package>\nExample:\nyarn workspace web add react\nRemove a package from a workspace\nyarn workspace <workspace> remove <package>\nExample:\nyarn workspace web remove react\nUpgrade a package in a workspace\nyarn workspace <workspace> upgrade <package>\nExample:\nyarn workspace web upgrade react\n\n\nInstall a package in a workspace\npnpm add <package> --filter <workspace>\nExample:\npnpm add react --filter web\nRemove a package from a workspace\npnpm uninstall <package> --filter <workspace>\nExample:\npnpm uninstall react --filter web\nUpgrade a package in a workspace\npnpm update <package> --filter <workspace>\nExample:\npnpm update react --filter web"}},"/repo/docs/handbook/publishing-packages":{"title":"Publishing Packages","data":{"":"Publishing a package to npm from a monorepo can be an extremely satisfying and smooth experience, with the right tools.You should follow this setup if you want to publish some of your monorepo's workspaces to npm as packages. If you don't need to publish to npm, you should use an internal package instead. They're much easier to set up and use.","tools#Tools":"You'll need to set up a few tools to get it working:First, you'll need a bundler to turn your code into CommonJS, the most commonly used format on npm. You'll also need to set up a dev script so that you can work on the workspace in local development.Finally, you'll need a tool for publishing & versioning. This will handle both bumping your monorepo's package versions and publishing to npm."}},"/repo/docs/handbook/sharing-code":{"title":"Sharing Code","data":{"":"Monorepos let you share code across applications without friction. To do that, you'll be building packages to share code between your apps.","what-is-a-package#What is a package?":"The word 'package' has a double meaning when it comes to monorepos. It can refer to either of these:\nA set of files you download from a registry into your node_modules, via a package manager like npm.\nA workspace containing code that can be shared between applications - by convention usually inside /packages.\n\nThis dual meaning can be very confusing to folks new to the monorepo scene. You're likely very familiar with package installation, but not so familiar with workspaces.The fact is that they're very similar. A package is just a piece of shared code. Except that installed packages live in your node_modules, and local packages lives in a workspace - likely in your /packages folder.","anatomy-of-a-package#Anatomy of a package":"Each package contains a package.json. You're likely familiar with using these to manage dependencies and scripts in your applications.However, you may not have noticed the main and name fields before:\n{\n// The name of your package\n\"name\": \"my-lib\",\n\n// When this package is used, this file is actually\n// the thing that gets imported\n\"main\": \"./index.js\"\n}\nBoth of these fields are important for deciding how this package behaves when it's imported. For instance, if index.js has some exports:\nexport const myFunc = () => {\nconsole.log(\"Hello!\");\n};\nAnd we import this file into one of our apps:\nimport { myFunc } from \"my-lib\";\n\nmyFunc(); // Hello!\nThen we'll be able to use the code inside the my-lib folder inside our applications.To summarize, each package must have a name and a main declared inside its package.json.\nPackage resolution in package.json is a very complicated topic, and we can't do justice to it here. Other fields in your package.json may take precedence over main depending on how the package is being imported.Check the npm docs for a guide.For our purposes, using main will be good enough.","next-steps#Next steps":"We're going to introduce two styles of packages - internal packages and external packages:Internal packages are intended to only be used inside the monorepo where they're housed. They are relatively simple to set up, and if your project is closed source they will be the most useful to you.External packages are bundled and sent to a package registry. This is useful for design systems, shared utility libraries or any open source work. However, they introduce more complexity around bundling, versioning and publishing."}},"/repo/docs/handbook/testing":{"title":"Testing","data":{"":"Along with linting and building, testing is a crucial part of a production-ready monorepo. Whether you're using end-to-end tests or a unit test suite, integrating them with Turborepo will lead to enormous speed-ups.","working-with-test-runners#Working with test runners":"Let's say we have a monorepo that looks like this:\n├── apps\n│   └── web\n│       └── package.json\n└── packages\n└── shared\n└── package.json\nBoth apps/web and packages/shared have their own test suite. Their package.json files look like this:\n\n\n{\n\"scripts\": {\n\"test\": \"jest\"\n}\n}\n\n\n\n{\n\"scripts\": {\n\"test\": \"vitest run\"\n}\n}\n\n\nInside the root turbo.json, we recommend setting up a test task in your pipeline:\n{\n\"pipeline\": {\n\"test\": {\n\"outputs\": []\n}\n}\n}\nNow, inside your root package.json, add a test script:\n{\n\"scripts\": {\n\"test\": \"turbo run test\"\n}\n}\nNow, you can run test using your package manager and have Turborepo test the entire repository.Because of Turborepo's caching, this also means that only repositories that have changed files will be tested - resulting in a lot of time saved.","running-tests-in-watch-mode#Running tests in watch mode":"When you run your test suite normally, it completes and outputs to stdout. This means you can cache it with Turborepo.But when you run your tests in watched mode, the process never exits. This makes a watch task more like a development task.Because of this difference, we recommend specifying two separate Turborepo tasks: one for running your tests, and one for running them in watch mode.Here's an example:\n\n\n{\n\"scripts\": {\n\"test\": \"jest\",\n\"test:watch\": \"jest --watch\"\n}\n}\n\n\n\n{\n\"scripts\": {\n\"test\": \"vitest run\",\n\"test:watch\": \"vitest\"\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"test\": {\n\"outputs\": []\n},\n\"test:watch\": {\n\"cache\": false\n}\n}\n}\n\n{\n\"scripts\": {\n\"test\": \"turbo run test\",\n\"test:watch\": \"turbo run test:watch\"\n}\n}"}},"/repo/docs/handbook/troubleshooting":{"title":"Troubleshooting","data":{"":"","handling-mismatched-package-versions#Handling mismatched package versions":"As your monorepo grows, you may end up with different versions of packages in different workspaces.For instance, app may use react@18.0.0, but web may use react@17.0.0. This is especially true when you've just migrated from a multi-repo setup.Mis-matched dependencies in different repositories can mean that code runs unexpectedly. React, for instance, will error if there is more than one version installed.","manypkgcli#@manypkg/cli":"Our recommended method for handling this problem is with @manypkg/cli - a CLI which can ensure that your dependencies match across your repositories.Here's a quick example. At the root of your package.json, add a postinstall script.\n{\n\"scripts\": {\n// This will check your dependencies match\n// after each installation\n\"postinstall\": \"manypkg check\"\n},\n\"dependencies\": {\n// Make sure you install @manypkg/cli\n\"@manypkg/cli\": \"latest\"\n}\n}\nYou can also run manypkg fix to automatically update them throughout your repository."}},"/repo/docs/handbook/what-is-a-monorepo":{"title":"What is a Monorepo?","data":{"":"A monorepo is a collection of many different apps and packages in a single codebase.The alternative setup is called a polyrepo - multiple codebases which are published and versioned separately.","sharing-code#Sharing code":"","in-a-polyrepo#In a polyrepo":"In a polyrepo setup, the process for sharing code between applications is relatively lengthy.Imagine that you have three separate repositories - app, docs, and shared-utils. Both app and docs depend on shared-utils, which is published as a package on npm.Let's say a bug in shared-utils is causing a critical issue in both app and docs. You'll need to:\nMake a commit in shared-utils fixing the error\nRun a publish task inside shared-utils to publish it to npm\nMake a commit in app bumping the version of the shared-utils dependency\nMake a commit in docs bumping the version of the shared-utils dependency\napp and docs are now ready to be deployed.\n\nThe more apps you have that depend on shared-utils, the longer this process takes. It can be extremely arduous.","in-a-monorepo#In a monorepo":"In a monorepo setup, shared-utils would be in the same codebase as app and docs. This makes the process very simple:\nMake a commit in shared-utils fixing the error\napp and docs are now ready to be deployed.\n\nNo versioning is required, because app and docs don't depend on the version of shared-utils in npm - they depend on the version that's in the codebase.This makes it possible to create single commits which fix bugs in multiple apps and packages at once. This can be an enormous gain in speed for teams.","how-do-monorepos-work#How do monorepos work?":"The main building block of the monorepo is the workspace. Each application and package you build will be in its own workspace, with its own package.json. As you'll learn from our guide, workspaces can depend on each other, meaning your docs workspace can depend on shared-utils:\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"workspace:*\"\n}\n}\n\n\nWorkspaces are managed by the same CLI which installs your dependencies.","the-root-workspace#The root workspace":"You'll also have a root workspace - a package.json in the root folder of your codebase. This is a useful place for:\nSpecifying dependencies which are present across your entire monorepo\nAdding tasks that operate on the whole monorepo, not just individual workspaces\nAdding documentation on how to use the monorepo"}},"/repo/docs/handbook/workspaces":{"title":"Workspaces","data":{"":"Workspaces are the building blocks of your monorepo. Each app and package you add to your monorepo will be inside its own workspace.Workspaces are managed by your package manager, so make sure you've set that up first.","configuring-workspaces#Configuring workspaces":"To use workspaces, you must first declare their file system locations to your package manager.A common convention we recommend is having top-level apps/ and packages/ directories. This isn't a requirement - just a suggested directory structure.The apps folder should contain workspaces for launchable apps, such as a Next.js or Svelte app.The packages folder should contain workspaces for packages used by either an app or another package.\n\nAdd the folders you want to configure as workspaces to the workspaces field in your root package.json file. This field contains a list of workspace folders in the form of globs:\n{\n\"name\": \"my-monorepo\",\n\"version\": \"1.0.0\",\n\"workspaces\": [\n\"docs\",\n\"apps/*\",\n\"packages/*\"\n]\n}\n\n\nAdd the folders you want to configure as workspaces to the workspaces field in your root package.json file. This field contains a list of workspace folders in the form of globs:\n{\n\"name\": \"my-monorepo\",\n\"version\": \"1.0.0\",\n\"workspaces\": [\n\"docs\",\n\"apps/*\",\n\"packages/*\"\n]\n}\n\n\nAdd the folders you want to configure as workspaces to the pnpm-workspace.yaml file that exists in your root directory. This file contains a list of workspace folders in the form of globs:\npackages:\n- \"docs\"\n- \"apps/*\"\n- \"packages/*\"\n\n\n\nmy-monorepo\n├─ docs\n├─ apps\n│  ├─ api\n│  └─ mobile\n├─ packages\n│  ├─ tsconfig\n│  └─ shared-utils\n└─ sdk\nIn the example above, all directories inside my-monorepo/apps/ and my-monorepo/packages/ are workspaces, and the my-monorepo/docs directory itself is also a workspace. my-monorepo/sdk/ is not a workspace, as it is not included in the workspace configuration.","naming-workspaces#Naming workspaces":"Each workspace has a unique name, which is specified in its package.json:\n{\n\"name\": \"shared-utils\"\n}\nThis name is used to:\nSpecify which workspace a package should be installed to\nUse this workspace in other workspaces\nPublish packages: it'll be published on npm under the name you specify\n\nYou can use an npm organization or user scope to avoid collisions with existing packages on npm. For instance, you could use @mycompany/shared-utils.","workspaces-which-depend-on-each-other#Workspaces which depend on each other":"To use a workspace inside another workspace, you'll need to specify it as a dependency, using its name.For instance, if we want apps/docs to import packages/shared-utils, we'd need to add shared-utils as a dependency inside apps/docs/package.json:\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"shared-utils\": \"workspace:*\"\n}\n}\n\n\n\nThe * allows us to reference the latest version of the dependency. It\nsaves us from needing to bump the versions of our dependency if the versions\nof our packages change.\nJust like a normal package, we'd need to run install from root afterwards. Once installed, we can use the workspace as if it were any other package from node_modules. See our section on sharing code for more information.","managing-workspaces#Managing workspaces":"In a monorepo, when you run an install command from root, a few things happen:\nThe workspace dependencies you have installed are checked\nAny workspaces are symlinked into node_modules, meaning that you can import them like normal packages\nOther packages are downloaded and installed into node_modules\n\nThis means that whenever you add/remove workspaces, or change their locations on the filesystem, you'll need to re-run your install command from root to set up your workspaces again.\nYou don't need to re-install every time your source code changes inside a\npackage - only when you change the locations (or configuration) of your\nworkspaces in some way.\nIf you run into issues, you may have to delete each node_modules folder in your repository and re-run install to correct it."}},"/repo/docs/handbook/linting/eslint":{"title":"ESLint","data":{"":"","sharing-config#Sharing config":"Sharing an ESLint config across workspaces can be a boon to productivity by making all your workspaces more consistent.Let's imagine a monorepo like this:\napps\n├─ docs\n│  ├─ package.json\n│  └─ .eslintrc.js\n└─ web\n├─ package.json\n└─ .eslintrc.js\npackages\n└─ eslint-config-custom\n├─ index.js\n└─ package.json\nWe've got a package called eslint-config-custom, and two applications, each with their own .eslintrc.js.","our-eslint-config-custom-package#Our eslint-config-custom package":"Our eslint-config-custom file contains only a single file, index.js. It looks like this.\nmodule.exports = {\nextends: [\"next\", \"turbo\", \"prettier\"],\nrules: {\n\"@next/next/no-html-link-for-pages\": \"off\",\n\"react/jsx-key\": \"off\",\n},\n};\nIt's a typical ESLint config, nothing fancy.The package.json looks like this:\n{\n\"name\": \"eslint-config-custom\",\n\"main\": \"index.js\",\n\"dependencies\": {\n\"eslint\": \"latest\",\n\"eslint-config-next\": \"latest\",\n\"eslint-config-prettier\": \"latest\",\n\"eslint-plugin-react\": \"latest\",\n\"eslint-config-turbo\": \"latest\"\n}\n}\nTwo things are notable here. First, the main field points to index.js. This allows files to easily import this config.Secondly, the ESLint dependencies are all listed here. This is useful - it means we don't need to re-specify the dependencies inside the apps which import eslint-config-custom.","how-to-use-the-eslint-config-custom-package#How to use the eslint-config-custom package":"In our web app, we first need to add eslint-config-custom as a dependency.\n\n\n{\n\"dependencies\": {\n\"eslint-config-custom\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"eslint-config-custom\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"eslint-config-custom\": \"workspace:*\"\n}\n}\n\n\nWe can then import the config like this:\nmodule.exports = {\nroot: true,\nextends: [\"custom\"],\n};\nBy adding custom to our extends array, we're telling ESLint to look for a package called eslint-config-custom - and it finds our workspace.","summary#Summary":"This setup ships by default when you create a new monorepo with npx create-turbo@latest. You can also look at our basic example to see a working version.","setting-up-a-lint-task#Setting up a lint task":"We recommend following the setup in the basics section, with one alteration.Each package.json script should look like this:\n{\n\"scripts\": {\n\"lint\": \"eslint\"\n}\n}"}},"/repo/docs/handbook/linting/typescript":{"title":"TypeScript","data":{"":"You can use TypeScript in a monorepo in one of two ways - as a linter, or as a build tool.In this section, we'll discuss TypeScript's role as a linter. This is when you prevent TypeScript emitting files (with noEmit) and instead use it only to check your source code's types.","sharing-tsconfigjson#Sharing tsconfig.json":"We can share TypeScript config files across our repository with a clever solution. We can put our base tsconfig.json files in a single workspace, and extend them from the tsconfig.json files in our apps.Let's imagine a workspace like this:\napps\n├─ docs\n│  ├─ package.json\n│  ├─ tsconfig.json\n├─ web\n│  ├─ package.json\n│  ├─ tsconfig.json\npackages\n├─ tsconfig\n│  ├─ base.json\n│  ├─ nextjs.json\n│  ├─ package.json\n│  ├─ react-library.json","our-tsconfig-package#Our tsconfig package":"Inside packages/tsconfig, we have a few json files which represent different ways you might want to configure TypeScript. They each look like this:\n{\n\"$schema\": \"https://json.schemastore.org/tsconfig\",\n\"display\": \"Default\",\n\"compilerOptions\": {\n\"composite\": false,\n\"declaration\": true,\n\"declarationMap\": true,\n\"esModuleInterop\": true,\n\"forceConsistentCasingInFileNames\": true,\n\"inlineSources\": false,\n\"isolatedModules\": true,\n\"moduleResolution\": \"node\",\n\"noUnusedLocals\": false,\n\"noUnusedParameters\": false,\n\"preserveWatchOutput\": true,\n\"skipLibCheck\": true,\n\"strict\": true\n},\n\"exclude\": [\"node_modules\"]\n}\nInside package.json, we simply name our package:\n{\n\"name\": \"tsconfig\"\n}\nThe other json files in the repository can be accessed via a simple import:\nimport baseJson from \"tsconfig/base.json\";\nimport nextjsJson from \"tsconfig/nextjs.json\";\nimport reactLibraryJson from \"tsconfig/react-library.json\";\nThis lets us export different config settings for different types of projects.","how-to-use-the-tsconfig-package#How to use the tsconfig package":"Each app/package which uses our shared tsconfig must first specify it as a dependency:\n\n\n{\n\"dependencies\": {\n\"tsconfig\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"tsconfig\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"tsconfig\": \"workspace:*\"\n}\n}\n\n\nThen, they can extend it inside their own tsconfig.json:\n{\n// We extend it from here!\n\"extends\": \"tsconfig/nextjs.json\",\n\n// You can specify your own include/exclude\n\"include\": [\"next-env.d.ts\", \"**/*.ts\", \"**/*.tsx\"],\n\"exclude\": [\"node_modules\"]\n}","summary#Summary":"This setup ships by default when you create a new monorepo with npx create-turbo@latest. You can also look at our basic example to see a working version.","running-tasks#Running tasks":"We recommend following the setup in the basics section."}},"/repo/docs/handbook/publishing-packages/bundling":{"title":"Bundling","data":{"":"Unlike internal packages, external packages can be deployed to npm and used locally. In this guide, we'll be using a bundler to bundle a package to CommonJS, the most commonly used format used on npm.","setting-up-a-build-script#Setting up a build script":"Let's start with a package created using our internal packages tutorial.There, we created a math-helpers package which contained a few helper functions for adding and subtracting. We've decided that this package is good enough for npm, so we're going to bundle it.At the end of that tutorial, we had a package set up under /packages, which looked like this:\n├── apps\n│   └── web\n│       └── package.json\n├── packages\n│   └── math-helpers\n│       ├── src\n│       │   └── index.ts\n│       ├── tsconfig.json\n│       └── package.json\n├── package.json\n└── turbo.json\nWe're going to add a build script to math-helpers, using a bundler. If you're unsure which one to choose, we recommend tsup.\n\nFirst install, tsup inside packages/math-helpers using your package manager.\n{\n\"scripts\": {\n\"build\": \"tsup src/index.ts --format cjs --dts\"\n}\n}\ntsup outputs files to the dist directory by default, so you should:\nAdd dist to your .gitignore files to make sure they aren't committed by git.\nAdd dist to the outputs of build in your turbo.json.\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n}\n}\n}\nThat way, when tsup is run the outputs can be cached by Turborepo.Finally, we should change main to point at ./dist/index.js inside package.json. types can point at ./dist/index.d.ts:\n{\n\"main\": \"./dist/index.js\",\n\"types\": \"./dist/index.d.ts\"\n}\n\nIf you run into errors by using main and types, take a look at the tsup docs.Bundling is a complicated topic, and we don't have space here to cover everything!","building-our-package-before-our-app#Building our package before our app":"Before we can run turbo run build, there's one thing we need to consider. We've just added a task dependency into our monorepo. The build of packages/math-helpers needs to run before the build of apps/web.Fortunately, we can use dependsOn to easily configure this.\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\n// Run builds in workspaces I depend on first\n\"^build\"\n]\n}\n}\n}\nNow, we can run turbo run build, and it'll automatically build our packages before it builds our app.","setting-up-a-dev-script#Setting up a dev script":"There's a small issue with our setup. We are building our package just fine, but it's not working great in dev. Changes that we make to our math-helpers package aren't being reflected in our app.That's because we don't have a dev script to rebuild our packages while we're working. We can add one easily:\n\n\n{\n\"scripts\": {\n\"build\": \"tsup src/index.ts --format cjs --dts\",\n\"dev\": \"npm run build --watch\"\n}\n}\nThis passes the --watch flag to tsup, meaning it will watch for file changes.\n\nIf we've already set up dev scripts in our turbo.json, running turbo run dev will run our packages/math dev task in parallel with our apps/web dev task.","summary#Summary":"Our package is now in a spot where we can consider deploying to npm. In our versioning and publishing section, we'll do just that."}},"/repo/docs/handbook/publishing-packages/versioning-and-publishing":{"title":"Versioning and Publishing","data":{"":"Manually versioning and publishing packages in a monorepo can be extremely tiresome. Luckily, there's a tool that makes things easy - the Changesets CLI.We recommend Changesets because it's intuitive to use, and - just like Turborepo - fits with the monorepo tools you're already used to.Some alternatives are:\nintuit/auto - Generate releases based on semantic version labels on pull requests\nmicrosoft/beachball - The Sunniest Semantic Version Bumper","understanding-changesets#Understanding Changesets":"We recommend taking a look at the Changesets docs. Here's our recommended reading order:\nWhy use changesets? - an intro that takes you through the fundamentals.\nInstallation instructions\nIf you're using GitHub, consider using the Changeset GitHub bot - a bot to nudge you to add changesets to PR's.\nYou should also consider adding the Changesets GitHub action - a tool which makes publishing extremely easy.","using-changesets-with-turborepo#Using Changesets with Turborepo":"Once you've started using Changesets, you'll gain access to three useful commands:\n# Add a new changeset\nchangeset\n\n# Create new versions of packages\nchangeset version\n\n# Publish all changed packages to npm\nchangeset publish\nLinking your publishing flow into Turborepo can make organising your deploy a lot simpler and faster.Our recommendation is to add a publish-packages script into your root package.json:\n{\n\"scripts\": {\n// Include build, lint, test - all the things you need to run\n// before publishing\n\"publish-packages\": \"turbo run build lint test && changeset version && changeset publish\"\n}\n}\n\nWe recommend publish-packages so that it doesn't conflict with npm's\nbuilt-in publish script.\nThis means that when you run publish-packages, your monorepo gets built, linted, tested and published - and you benefit from all of Turborepo's speedups."}},"/repo/docs/handbook/sharing-code/internal-packages":{"title":"Internal Packages","data":{"":"Internal packages are packages which are only intended to be used inside your monorepo. They're extremely useful for sharing code between apps in closed-source monorepos.Internal packages are quick to create, and can be turned into external packages if you end up wanting to publish them to npm.","what-makes-a-package-internal#What makes a package internal?":"External packages run their files through a bundler before putting them on a package registry. This means they need a lot of tooling to handle.\nBundlers: to build the package\nVersioning: to help with versioning and releases\nPublishing: to publish the package\n\nIf you want to use those files locally, you'll also need:\nDev scripts: for bundling the package locally when files change\n\nBecause internal packages are not published, we can skip all of these steps. Instead of bundling our package ourselves, we're going to make the app which imports the package bundle it for us.This sounds complex, but it's extremely easy to set up.","our-first-internal-package#Our first internal package":"We're going to create a shared math-helpers package inside our monorepo.","1-create-your-monorepo#1. Create your monorepo":"If you don't have an existing monorepo, create one using our guide.","2-create-a-new-package#2. Create a new package":"Inside /packages, create a new folder called math-helpers.\nmkdir packages/math-helpers\nCreate a package.json:\n{\n\"name\": \"math-helpers\",\n\"dependencies\": {\n// Use whatever version of TypeScript you're using\n\"typescript\": \"latest\"\n}\n}\nCreate a src folder, and add a TypeScript file at packages/math-helpers/src/index.ts.\nexport const add = (a: number, b: number) => {\nreturn a + b;\n};\n\nexport const subtract = (a: number, b: number) => {\nreturn a - b;\n};\nYou'll also need to add a tsconfig.json at packages/math-helpers/tsconfig.json:\n{\n\"compilerOptions\": {\n\"esModuleInterop\": true,\n\"forceConsistentCasingInFileNames\": true,\n\"isolatedModules\": true,\n\"moduleResolution\": \"node\",\n\"preserveWatchOutput\": true,\n\"skipLibCheck\": true,\n\"noEmit\": true,\n\"strict\": true\n},\n\"exclude\": [\"node_modules\"]\n}\nGreat! We've now got all the files we need for our internal package.","3-import-the-package#3. Import the package":"We're now going to import the package and see what happens. Go into one of your apps, and add math-helpers into the dependencies of its package.json:\n\n\n{\n\"dependencies\": {\n\"math-helpers\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"math-helpers\": \"*\"\n}\n}\n\n\n\n{\n\"dependencies\": {\n\"math-helpers\": \"workspace:*\"\n}\n}\n\n\nInstall all packages from root to ensure that dependency works.Now add an import from math-helpers into one of your app's source files:\n+ import { add } from \"math-helpers\";\n\n+ add(1, 2);\nYou'll likely see an error!\nCannot find module 'math-helpers' or its corresponding type declarations.\nThat's because we've missed a step. We haven't told our math-helpers/package.json what the entry point to our package is.","4-fix-main-and-types#4. Fix main and types":"Go back to packages/math-helpers/package.json and add two fields, main and types:\n{\n\"name\": \"math-helpers\",\n\"main\": \"src/index.ts\",\n\"types\": \"src/index.ts\",\n\"dependencies\": {\n\"typescript\": \"latest\"\n}\n}\nNow, anything that imports our math-helpers module will be pointed directly towards the src/index.ts file - that's the file that they will import.Go back to apps/web/pages/index.tsx. The error should be gone!","5-try-running-the-app#5. Try running the app":"Now, try running that app's dev script. In the default turborepo, this will be as easy as:\n\nbash npm run dev\n\n\nbash yarn dev\n\n\nbash pnpm run dev\n\n\n\nWhen it starts running, you'll likely see an error in your web browser:\n../../packages/math-helpers/src/index.ts\nModule parse failed: Unexpected token (1:21)\nYou may need an appropriate loader to handle this file type,\ncurrently no loaders are configured to process this file.\nSee https://webpack.js.org/concepts#loaders\n\n> export const add = (a: number, b: number) => {\n|   return a + b;\n| };\nThis is what happens when you try and import an un-bundled file into a Next.js app.The fix is simple - we need to tell Next.js to bundle the files from certain packages it imports.\n\nBecause vite transpiles modules by default, there's no more setup needed! Skip to step 7.","6-configuring-your-app#6. Configuring your app":"We can do that using next-transpile-modules.Install next-transpile-modules to your app. For a refresher, see our package installation docs.Inside your app's next.config.js, add next-transpile-modules:\nconst withTM = require(\"next-transpile-modules\")([\n// Add \"math-helpers\" to this array:\n\"math-helpers\",\n]);\n\nmodule.exports = withTM({\n// Any additional config for next goes in here\n});\nRestart your dev script, and go to the browser.The error has disappeared!\n\nNo configuration is needed!","7-summary#7. Summary":"We are now able to add any amount of code into our math-helpers package, and use it in any app in our monorepo. We don't even need to build our package - it just works.This pattern is extremely powerful for creating pieces of code that can be easily shared between teams.","quick-reference#Quick Reference":"","quick-reference---creating-a-new-internal-package#Quick reference - creating a new internal package":"Create a new folder in packages/<folder>\nAdd a package.json, with name and types pointing at src/index.ts (or src/index.tsx)\nAdd src/index.tsx, with at least one named export\nInstall your packages from root","quick-reference---importing-an-internal-package#Quick reference - importing an internal package":"Ensure that you're importing it correctly\nEnsure that you've configured your app to transpile it"}},"/repo/docs/reference/codemods":{"title":"Codemods","data":{"":"Turborepo provides Codemod transformations and automatic migration scripts to help upgrade your Turborepo codebase when a feature is deprecated.Codemods are transformations that run on your codebase programmatically. This allows for a large amount of changes to be applied without having to manually go through every file.","usage#Usage":"npx @turbo/codemod <transform> <path>\n\ntransform - name of transform, see available transforms below.\npath - files or directory to transform\n--dry - Do a dry-run, no code will be edited\n--print - Prints the changed output for comparison","turborepo-1x#Turborepo 1.x":"","add-package-manager#add-package-manager":"Transforms the root package.json so that packageManager key as the detected package manager (yarn, npm, pnpm) and version (e.g. yarn@1.22.17). This key is now supported by Node.js and is used by Turborepo for faster package manager detection (vs. inferring from just the filesystem alone).For example, for Yarn v1:\n// Before\n{\n\"name\": \"turborepo-basic\",\n\"version\": \"0.0.0\",\n\"private\": true,\n\"workspaces\": [\"apps/*\", \"packages/*\"]\n// ...\n}\n\n{\n\"name\": \"turborepo-basic\",\n\"version\": \"0.0.0\",\n\"private\": true,\n+  \"packageManager\": \"yarn@1.22.17\",\n\"workspaces\": [\n\"apps/*\",\n\"packages/*\"\n]\n}","usage-1#Usage":"Go to your project:\ncd path-to-your-turborepo/\nRun the codemod:\nnpx @turbo/codemod add-package-manager","create-turbo-config#create-turbo-config":"Creates the turbo.json file at the root of your project based on the \"turbo\" key in package.json.\nThe \"turbo\" key is subsequently deleted from package.json.For example:\n// Before, package.json\n{\n\"name\": \"Monorepo root\",\n\"private\": true,\n\"turbo\": {\n\"pipeline\": {\n...\n}\n},\n...\n}\n\n// After, package.json\n{\n\"name\": \"Monorepo root\",\n\"private\": true,\n-  \"turbo\": {\n-    \"pipeline\": {\n-      ...\n-    }\n-  },\n...\n}\n\n// After, turbo.json\n+{\n+  \"$schema\": \"https://turborepo.org/schema.json\",\n+  \"pipeline\": {\n+    ...\n+  }\n+}","usage-2#Usage":"Go to your project:\ncd path-to-your-turborepo/\nRun the codemod:\nnpx @turbo/codemod create-turbo-config","migrate-env-var-dependencies#migrate-env-var-dependencies":"Migrates all environment variable dependencies in turbo.json from dependsOn and globalDependencies to env and globalEnv respectively.For example:\n// Before, turbo.json\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"globalDependencies\": [\".env\", \"$CI_ENV\"],\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\", \"$API_BASE\"],\n\"outputs\": [\".next/**\"]\n},\n\"lint\": {\n\"outputs\": []\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}\n\n// After, turbo.json\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n- \"globalDependencies\": [\".env\", \"$CI_ENV\"],\n+ \"globalDependencies\": [\".env\"],\n+ \"globalEnv\": [\"CI_ENV\"],\n\"pipeline\": {\n\"build\": {\n-     \"dependsOn\": [\"^build\", \"$API_BASE\"],\n+     \"dependsOn\": [\"^build\"],\n+     \"env\": [\"API_BASE\"],\n\"outputs\": [\".next/**\"],\n},\n\"lint\": {\n\"outputs\": []\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}\n\n#### Usage\n\nGo to your project:\n\n```sh\ncd path-to-your-turborepo/\nRun the codemod:\nnpx @turbo/codemod migrate-env-var-dependencies"}},"/repo/docs/reference/command-line-reference":{"title":"CLI Usage","data":{"":"After installing the turbo package (or cloning a starter), you can start using Turborepo's command line interface (CLI) turbo to do all kinds of awesomeness in your monorepo.","option-syntax#Option Syntax":"Options can be passed to turbo in different ways. Options that require a value can be passed with an equals sign:\n--opt=<value>\n--opt=\"<value with a space>\"\nThey can also be passed with a space between:\n--opt value\n--opt \"value with a space\"\nBoolean options can be enabled as follows:\n# To pass true\n--opt\n\n# To pass false\n--opt=false","global-arguments#Global Arguments":"The following flags apply to all commands.","--color#--color":"Forces the use of color even when the output stream is not considered to be a TTY terminal.\nThis can be used to enable turbo's color output for CI runners such as Github Actions which\nhave support for rendering color in their log output.\nturbo run build --color\nAlternatively, you can also enable color using the FORCE_COLOR environment variable (borrowed\nfrom the supports-color nodejs package). Note that\nthis may also enable additional colored output from the actual tasks themselves if\nthey use supports-color to determine whether or not to output with colored output.\ndeclare -x FORCE_COLOR=1\nturbo run build","--no-color#--no-color":"Suppresses the use of color in the output when running turbo in an interactive / TTY session.\nturbo run build --no-color\nAlternatively, you can also suppress color using the FORCE_COLOR environment variable (borrowed\nfrom the supports-color nodejs package).\ndeclare -x FORCE_COLOR=0\nturbo run build","turbo-run-task#turbo run <task>":"Run npm scripts across all workspaces in specified scope. Tasks must be specified in your pipeline configuration.turbo run <task1> <task2> [options] [-- <args passed to task1 and task2>]turbo can run multiple tasks, and any arguments following -- will be passed through\nto the tasks to be executed. Note that these additional arguments will not be passed to\nany additional tasks that are run due to dependencies from the pipeline configuration.","options#Options":"","--cache-dir#--cache-dir":"type: stringDefaults to ./node_modules/.cache/turbo. Specify local filesystem cache directory. Be sure to add this folder to your .gitignore if you change it from the default.\nturbo run build --cache-dir=\"./my-cache\"","--concurrency#--concurrency":"type: number | stringDefaults to 10. Set/limit the max concurrency of task execution. This must be an integer greater than or equal to 1 or a percentage value like 50%. Use 1 to force serial (i.e. one task at a time) execution. Use 100% to use all available logical processors. This option is ignored if the --parallel flag is also passed.\nturbo run build --concurrency=50%\nturbo run test --concurrency=1","--continue#--continue":"Defaults to false. This flag tells turbo whether or not to continue with execution in the presence of an error (i.e. non-zero exit code from a task).\nBy default, specifying the --parallel flag will automatically set --continue to true unless explicitly set to false.\nWhen --continue is true, turbo will exit with the highest exit code value encountered during execution.\nturbo run build --continue","--cwd#--cwd":"Set the working directory of the command.\nturbo run build --cwd=./somewhere/else","--deps#--deps":"--deps is deprecated in 1.2.x. Please use\n--filter\ninstead.\nDefaults to true. Include dependent workspace consumers in the execution.\nturbo run build --deps\nturbo run build --no-deps\nExampleLet's say you have workspaces A, B, C, and D where A depends on B and C depends on D. You run turbo run build for the first time and everything is built and cached. Then, you change a line of code in B. With the --deps flag on, running turbo run build will execute build in B and then A, but not in C and D because they are not impacted by the change. If you were to run turbo run build --no-deps instead, turbo will only run build in B.","--dry----dry-run#--dry / --dry-run":"Instead of executing tasks, display details about the affected workspaces and tasks that would be run.\nSpecify --dry=json to get the output in JSON format.Task details include:\ntask: The name of the task to be executed\npackage: The workspace in which to run the task\nhash: The hash of the task, used for caching\ndirectory: The directory where the task will be run\ncommand: The actual command used to run the task\noutputs: Location of outputs from the task that will cached\nlogFile: Location of the log file for the task run\ndependencies: Tasks that must run before this task\ndependents: Tasks that must be run after this task","--filter#--filter":"type: string[]Specify combinations of workspaces, directories, and git commits to act as entrypoints\nfor execution.Multiple filters can be combined to select distinct sets of targets. Additionally, filters\ncan also exclude targets. A target that matches any filter and is not explicitly excluded will\nbe in the final entrypoint selection.For more detailed information about the --filter flag and filtering, refer to the dedicated page in our documentation\nturbo run build --filter=my-pkg\nturbo run test --filter=...^@scope/my-lib\nturbo run build --filter=./apps/* --filter=!./apps/admin","--graph#--graph":"This command will generate an svg, png, jpg, pdf, json, html, or other supported output formats of the current task graph.\nThe output file format defaults to jpg, but can be controlled by specifying the filename's extension.If Graphviz is not installed, or no filename is provided, this command prints the dot graph to stdout.\nturbo run build --graph\nturbo run build test lint --graph=my-graph.svg\nturbo run build test lint --graph=my-json-graph.json\nturbo run build test lint --graph=my-graph.pdf\nturbo run build test lint --graph=my-graph.png\nturbo run build test lint --graph=my-graph.html\n\nKnown Bug: All possible pipeline task nodes will be added to the graph at\nthe moment, even if that pipeline task does not actually exist in a given\nworkspace. This has no impact on execution, it means that 1) the terminal\noutput may overstate the number of workspaces in which a task is running and\nyour dot viz graph may contain additional nodes that represents tasks that\ndo not exist.","--force#--force":"Ignore existing cached artifacts and forcibly re-execute all tasks (overwriting artifacts that overlap)\nturbo run build --force\nThe same behavior also be set via the TURBO_FORCE=true environment variable.","--global-deps#--global-deps":"Specify glob of global filesystem dependencies to be hashed. Useful for .env and files in the root directory that impact multiple packages/apps.\nCan be specified multiple times.\nturbo run build --global-deps=\".env.*\" --global-deps=\".eslintrc\" --global-deps=\"jest.config.js\"\nYou can also specify these in your turbo configuration as globalDependencies key.","--ignore#--ignore":"type: string[]Ignore files or directories from impacting scope. Uses glob patterns under the hood.\nturbo run build --ignore=\"apps/**/*\"\nturbo run build --ignore=\"packages/**/*\"\nturbo run build --ignore=\"packages/**/*\" --ignore=\"\\!/packages/not-this-one/**/*\"","how-multiple-patterns-work#How multiple patterns work":"Positive patterns (e.g. foo or *) add to the results, while negative patterns (e.g. !foo) subtract from the results.Therefore a lone negation (e.g. ['!foo']) will never match anything – use ['*', '!foo'] instead.","globbing-patterns#Globbing patterns":"Just a quick overview.\n* matches any number of characters, but not /\n? matches a single character, but not /\n** matches any number of characters, including /, as long as it's the only thing in a path part\n{} allows for a comma-separated list of \"or\" expressions\n! at the beginning of a pattern will negate the match","--include-dependencies#--include-dependencies":"--include-dependencies is deprecated in 1.2.x. Please use\n--filter\ninstead.\nDefault false. When true, turbo will add any workspaces that the workspaces in the current execution depend on (i.e. those declared in dependencies or devDependencies).This is useful when using --filter in CI as it guarantees that every dependency needed for the execution is actually executed.","--no-cache#--no-cache":"Default false. Do not cache results of the task. This is useful for watch commands like next dev or react-scripts start.\nturbo run build --no-cache\nturbo run dev --parallel --no-cache","--no-daemon#--no-daemon":"Default false. turbo can run a standalone process in some cases to precalculate values used for determining what work needs to be done.\nThis standalone process (daemon) is an optimization, and not required for proper functioning of turbo.\nPassing --no-daemon instructs turbo to avoid using or creating the standalone process.","--output-logs#--output-logs":"type: stringSet type of output logging. Defaults to \"outputMode\" for the task in turbo.json.\n\nExample\nturbo run build --output-logs=full\nturbo run build --output-logs=new-only","--only#--only":"Default false. Restricts execution to include specified tasks only. This is very similar to how lerna and pnpm run tasks by default.Given this pipeline in turbo.json:\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"^build\"]\n}\n}\n}\n\nturbo run test --only\nWill execute only the test tasks in each workspace. It will not build.","--parallel#--parallel":"Default false. Run commands in parallel across workspaces and ignore the dependency graph. This is useful for developing with live reloading.\nturbo run lint --parallel --no-cache\nturbo run dev --parallel --no-cache","--remote-only#--remote-only":"Default false. Ignore the local filesystem cache for all tasks. Only allow reading and caching artifacts using the remote cache.\nturbo run build --remote-only\nThe same behavior can also be set via the TURBO_REMOTE_ONLY=true environment variable.","--scope#--scope":"--scope is deprecated in 1.2.x. Please use\n--filter instead.\ntype: string[]Specify/filter workspaces to act as entry points for execution. Globs against package.json name field (and not the file system.)\nturbo run lint --scope=\"@example/**\"\nturbo run dev --parallel --scope=\"@example/a\" --scope=\"@example/b\" --no-cache --no-deps","--serial#--serial":"serial is deprecated in 0.5.3.Please use\n--concurrency=1 instead.\nExecutes all tasks serially (i.e. one-at-a-time).\nturbo run build --serial","--since#--since":"--since is deprecated in 1.2.x. Please use\n--filter\ninstead.\nFilter execution based on which workspaces have changed since a merge-base.\nturbo run build --since=origin/main\n\nImportant: This uses the git diff ${target_branch}... mechanism to\nidentify which workspaces have changed. There is an assumption that all the\ninput files for a workspace exist inside their respective workspace folders.","--token#--token":"A bearer token for remote caching. Useful for running in non-interactive shells (e.g. CI/CD) in combination with --team flags.\nturbo run build --team=my-team --token=xxxxxxxxxxxxxxxxx\nYou can also set the value of the current token by setting an environment variable named TURBO_TOKEN. The flag will take precedence over the environment variable if both are present.If you are using Remote Caching on Vercel and building your project on Vercel, this environment variable and flag are unnecessary because they are automatically set for you. Suppose you are using Remote Caching on Vercel but building in another CI provider like CircleCI or GitHub Actions. You can use a Vercel Personal Access Token as your --token or TURBO_TOKEN. If you are using a custom Remote Cache, this value will be used to send an HTTP Bearer token with requests to your custom Remote Cache.","--team#--team":"The slug of the remote cache team. Useful for running in non-interactive shells in combination with --token and --team flags.\nturbo run build --team=my-team\nturbo run build --team=my-team --token=xxxxxxxxxxxxxxxxx\nYou can also set the value of the current team by setting an environment variable named TURBO_TEAM. The flag will take precedence over the environment variable if both are present.","--preflight#--preflight":"Only applicable when remote artifact caching is configured. Enables sending a preflight request before every cache artifact and analytics request. The follow-up upload and download will follow redirects.\nturbo run build --preflight\nThe same behavior can also be set via the TURBO_PREFLIGHT=true environment variable.","--trace#--trace":"type: stringTo view CPU trace, outputs the trace to the given file, use go tool trace [file].\nImportant: The trace viewer doesn't work under Windows Subsystem for\nLinux.\n\nturbo run build --trace=\"<trace-file-name>\"","--heap#--heap":"type: stringTo view heap trace, outputs the trace to the given file, use go tool pprof [file] and type top. You can also drop it into speedscope and use the left heavy or sandwich view modes.\nturbo run build --heap=\"<heap-file-name>\"","--cpuprofile#--cpuprofile":"type: stringTo view CPU profile, outputs the profile to the given file, drop the file into speedscope.\nImportant: The CPU profiler doesn't work under Windows Subsystem for\nLinux. The profiler has to be built for native Windows and run using the\ncommand prompt instead.\n\nturbo run build --cpuprofile=\"<cpu-profile-file-name>\"","-v--vv--vvv#-v, -vv, -vvv":"To specify log level, use -v for Info, -vv for Debug and -vvv for Trace flags.\nturbo run build -v\nturbo run build -vv\nturbo run build -vvv","turbo-prune---scopetarget#turbo prune --scope=<target>":"Generate a sparse/partial monorepo with a pruned lockfile for a target workspace.\nThis command is not yet implemented for npm.\nThis command will generate folder called out with the following inside of it:\nThe full source code of all internal workspaces that are needed to build the target\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the workspaces in the pruned workspace.\nA copy of the root package.json\n\n\n.                                 # Folder full source code for all workspaces needed to build the target\n├── package.json                  # The root `package.json`\n├── packages\n│   ├── ui\n│   │   ├── package.json\n│   │   ├── src\n│   │   │   └── index.tsx\n│   │   └── tsconfig.json\n│   ├── shared\n│   │   ├── package.json\n│   │   ├── src\n│   │   │   ├── __tests__\n│   │   │   │   ├── sum.test.ts\n│   │   │   │   └── tsconfig.json\n│   │   │   ├── index.ts\n│   │   │   └── sum.ts\n│   │   └── tsconfig.json\n│   └── frontend\n│       ├── next-env.d.ts\n│       ├── next.config.js\n│       ├── package.json\n│       ├── src\n│       │   └── pages\n│       │       └── index.tsx\n│       └── tsconfig.json\n└── yarn.lock                            # The pruned lockfile for all targets in the subworkspace","options-1#Options":"","--docker#--docker":"type: booleanDefault to false. Passing this flag will alter the outputted folder with the pruned workspace to make it easier to use with Docker best practices / layer caching.With the --docker flag. The prune command will generate folder called out with the following inside of it:\nA folder json with the pruned workspace's package.jsons\nA folder full with the pruned workspace's full source code, but only including the internal packages that are needed to build the target.\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the packages in the pruned workspace.\n\n\n.\n├── full                                # Folder full source code for all package needed to build the target\n│   ├── package.json\n│   └── packages\n│       ├── ui\n│       │   ├── package.json\n│       │   ├── src\n│       │   │   └── index.tsx\n│       │   └── tsconfig.json\n│       ├── shared\n│       │   ├── package.json\n│       │   ├── src\n│       │   │   ├── __tests__\n│       │   │   │   ├── sum.test.ts\n│       │   │   │   └── tsconfig.json\n│       │   │   ├── index.ts\n│       │   │   └── sum.ts\n│       │   └── tsconfig.json\n│       └── frontend\n│           ├── next-env.d.ts\n│           ├── next.config.js\n│           ├── package.json\n│           ├── src\n│           │   └── pages\n│           │       └── index.tsx\n│           └── tsconfig.json\n├── json                                # Folder containing just package.jsons for all targets in the subworkspace\n│   ├── package.json\n│   └── packages\n│       ├── ui\n│       │   └── package.json\n│       ├── shared\n│       │   └── package.json\n│       └── frontend\n│           └── package.json\n└── yarn.lock                           # The pruned lockfile for all targets in the subworkspace","turbo-login#turbo login":"Connect machine to your Remote Cache provider. The default provider is Vercel.","options-2#Options":"","--url#--url":"type: stringDefaults to https://vercel.com.","--api#--api":"type: stringDefaults to https://vercel.com/api.","--sso-team#--sso-team":"type: stringConnect to an sso-enabled Vercel team by providing your Team slug.\nturbo login --sso-team=<team-slug>","turbo-logout#turbo logout":"Logs you out of your Vercel account.","turbo-link#turbo link":"Link the current directory to Remote Cache scope. The selected owner (either a user or and organization) will be able to share cache artifacts through Remote Caching.\nYou should run this command from the root of your monorepo.","options-3#Options":"","--api-1#--api":"type: stringDefaults to https://api.vercel.com","turbo-unlink#turbo unlink":"Unlink the current directory from the Remote Cache.","turbo-bin#turbo bin":"Get the path to the turbo binary."}},"/repo/docs/reference/configuration":{"title":"Configuration Options","data":{"":"You can configure the behavior of turbo by adding a turbo.json file in your monorepo's root (i.e. the same one you specify your workspaces key is set for Yarn and npm users).","globaldependencies#globalDependencies":"type: string[]A list of file globs for implicit global hash dependencies. The contents of these files will be included in the global hashing algorithm and affect the hashes of all tasks.\nThis is useful for busting the cache based on .env files (not in Git) or any root level file that impacts workspace tasks (but are not represented in the traditional dependency graph (e.g. a root tsconfig.json, jest.config.js, .eslintrc, etc.)).Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ... omitted for brevity\n},\n\n\"globalDependencies\": [\n\".env\", // contents will impact hashes of all tasks\n\"tsconfig.json\" // contents will impact hashes of all tasks\n]\n}","globalenv#globalEnv":"type: string[]A list of environment variables for implicit global hash dependencies. The contents of these environment variables will be included in the global hashing algorithm and affect the hashes of all tasks.Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ... omitted for brevity\n},\n\n\"globalEnv\": [\"GITHUB_TOKEN\"] // value will impact the hashes of all tasks\n}","pipeline#pipeline":"An object representing the task dependency graph of your project. turbo interprets these conventions to properly schedule, execute, and cache the outputs of tasks in your project.Each key in the pipeline object is the name of a task that can be executed by turbo run. If turbo finds a workspace with a package.json scripts object with a matching key, it will apply the pipeline task configuration to that npm script during execution. This allows you to use pipeline to set conventions across your entire Turborepo.\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"build\"],\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\"],\n\"outputMode\": \"full\"\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}","dependson#dependsOn":"type: string[]The list of tasks this task depends on.Prefixing an item in dependsOn with a ^ tells turbo that this pipeline task depends on the workspace's topological dependencies completing the task with the ^ prefix first (e.g. \"a workspace's build tasks should only run once all of its dependencies and devDependencies have completed their own build commands\").Items in dependsOn without ^ prefix, express the relationships between tasks at the workspace level (e.g. \"a workspace's test and lint commands depend on build being completed first\").Prefixing an item in dependsOn with a $ tells turbo that this pipeline task depends on the value of that environment variable.\nUsing $ to declare environment variables in the dependsOn config is\ndeprecated. Use the env key instead.\nExample\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n// \"A workspace's `build` command depends on its dependencies'\n// or devDependencies' `build` command being completed first\"\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// \"A workspace's `test` command depends on its own `lint` and\n// `build` commands first being completed\"\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"deploy\": {\n// \"A workspace's `deploy` command, depends on its own `build`\n// and `test` commands first being completed\"\n\"dependsOn\": [\"build\", \"test\"]\n},\n// A workspace's `lint` command has no dependencies\n\"lint\": {}\n}\n}","env#env":"type: string[]The list of environment variables a task depends on.Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"env\": [\"SOMETHING_ELSE\"], // value will impact the hashes of all build tasks\n\"outputs\": [\"dist/**\", \".next/**\"]\n},\n\"web#build\": {\n\"dependsOn\": [\"^build\"],\n\"env\": [\"STRIPE_SECRET_KEY\"], // value will impact hash of only web's build task\n\"outputs\": [\".next/**\"]\n}\n},\n\"globalEnv\": [\n\"GITHUB_TOKEN\" // value will impact the hashes of all tasks\n]\n}\n\nWhen Turborepo detects a common frontend framework in a workspace, it will\nautomatically depend on environment variables that are going to be inlined in\nyour build. For example, if the web workspace contains a Next.js project,\nyou do not need to specify any environment variables that start with\nNEXT_PUBLIC_\nin the dependsOn config. Turborepo already knows that the build output will\nchange when the value of these environment variables change, so it will depend\non them automatically. See more in the docs on\ncaching.","outputs#outputs":"type: string[]Defaults to [\"dist/**\", \"build/**\"]. The set of glob patterns of a task's cacheable filesystem outputs.Note: turbo automatically logs stderr/stdout to .turbo/run-<task>.log. This file is always treated as a cacheable artifact and never needs to be specified.Passing an empty array can be used to tell turbo that a task is a side-effect and thus doesn't emit any filesystem artifacts (e.g. like a linter), but you still want to cache its logs (and treat them like an artifact).Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n// \"Cache all files emitted to workspace's dist/** or .next\n// directories by a `build` task\"\n\"outputs\": [\"dist/**\", \".next/**\"],\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// \"Don't cache any artifacts of `test` tasks (aside from\n// logs)\"\n\"outputs\": [],\n\"dependsOn\": [\"build\"]\n},\n\"test:ci\": {\n// \"Cache the coverage report of a `test:ci` command\"\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"build\"]\n},\n\"dev\": {\n// Never cache anything (including logs) emitted by a\n// `dev` task\n\"cache\": false\n}\n}\n}","cache#cache":"type: booleanDefaults to true. Whether or not to cache the task outputs. Setting cache to false is useful for daemon or long-running \"watch\" or development mode tasks you don't want to cache.Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [],\n\"dependsOn\": [\"build\"]\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}","inputs#inputs":"type: string[]Defaults to []. Tells turbo the set of files to consider when determining if a workspace has changed for a particular task.\nSetting this to a list of globs will cause the task to only be rerun when files matching those globs have\nchanged. This can be helpful if you want to, for example, skip running tests unless a source file changed.Specifying [] will cause the task to be rerun when any file in the workspace changes.Example\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n// ... omitted for brevity\n\n\"test\": {\n// A workspace's `test` task depends on that workspace's\n// own `build` task being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [\"\"],\n// A workspace's `test` task should only be rerun when\n// either a `.tsx` or `.ts` file has changed.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\"]\n}\n}\n}\n\nNote: turbo.json is always considered an input. If you modify\nturbo.json, all caches are invalidated.","outputmode#outputMode":"type: \"full\" | \"hash-only\" | \"new-only\" | \"none\"Set type of output logging.\n\nExample\n{\n\"$schema\": \"https://turborepo.org/schema.json\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputMode\": \"new-only\"\n},\n\"test\": {\n\"outputs\": [],\n\"dependsOn\": [\"build\"]\n}\n}\n}"}}}